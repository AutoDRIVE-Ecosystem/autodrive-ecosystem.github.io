{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"ABOUT","text":""},{"location":"about/#project-overview","title":"Project Overview","text":"<p> AutoDRIVE is envisioned to be an integrated platform for autonomous driving research and education. It bridges the gap between software simulation and hardware deployment by providing the AutoDRIVE Simulator and AutoDRIVE Testbed, a well-suited duo for sim2real applications. It also offers AutoDRIVE Devkit, a developer's kit for rapid and flexible development of autonomy algorithms. Although the platform is primarily targeted towards autonomous driving, it also supports the development of smart-city solutions for managing the traffic flow. </p>"},{"location":"about/#autodrive-testbed","title":"AutoDRIVE Testbed","text":"Vehicle Infrastructure <p> AutoDRIVE Testbed is the hardware setup comprising of a scaled vehicle model (called Nigel) and a modular infrastructure development kit. The vehicle is equipped with a comprehensive sensor suite for redundant perception, a set of actuators for constrained motion control and a fully functional lighting system for illumination and signaling. It can be teleoperated (in manual mode) or self-driven (in autonomous mode). The infrastructure development kit comprises of various environment modules along with active and passive traffic elements. </p> <ul> <li>Source Branch: AutoDRIVE Testbed</li> <li>Latest Release: AutoDRIVE Testbed 0.2.0</li> <li>Upcoming Release: AutoDRIVE Testbed 0.3.0 is currently under development.</li> <li>Nigel (AS) Build Documentation: Assembly Guide, Assembly Animation and BOM</li> <li>Nigel (4WD4WS) Build Documentation: Assembly Guide, Assembly Animation and BOM</li> </ul>"},{"location":"about/#autodrive-simulator","title":"AutoDRIVE Simulator","text":"Vehicle Infrastructure <p> AutoDRIVE Simulator is the digital twin of the AutoDRIVE Testbed, which enables the users to virtually prototype their algorithms either due to hardware limitations or as a part of the reiterative development cycle. It is developed atop the Unity game engine and offers a WebSocket interface for bilateral communication with the autonomy algorithms developed independently using the AutoDRIVE Devkit. The standalone simulator application is targeted at Full HD resolution (1920x1080p) with cross-platform support (Windows, macOS and Linux). It is a light-weight software application that utilizes system resources wisely. This enables deployment of the simulator application and autonomy algorithms on a single machine; nonetheless, distributed computing is also supported. </p> <ul> <li>Source Branch: AutoDRIVE Simulator</li> <li>Latest Release: AutoDRIVE Simulator 0.3.0</li> <li>Upcoming Release: AutoDRIVE Simulator 0.4.0 is currently under development.</li> </ul>"},{"location":"about/#autodrive-devkit","title":"AutoDRIVE Devkit","text":"ADSS Toolkit SCSS Toolkit <p> AutoDRIVE Devkit is a developer's kit that enables the users to exploit AutoDRIVE Simulator or AutoDRIVE Testbed for rapid and flexible development of autonomy algorithms pertaining to autonomous driving (using ADSS Toolkit) as well as smart city management (using SCSS Toolkit). It supports local (decentralized) as well as distributed (centralized) computing and is compatible with Robot Operating System (ROS), while also offering a direct scripting support for Python and C++. </p> <ul> <li>Source Branch: AutoDRIVE Devkit</li> <li>Latest Release: AutoDRIVE Devkit 0.3.0</li> <li>Upcoming Release: AutoDRIVE Devkit 0.4.0 is currently under development.</li> </ul>"},{"location":"about/#awards-and-recognition","title":"Awards and Recognition","text":"<ul> <li>Finalist Award for project \"Nigel: A Mechatronically Redundant and Reconfigurable Scaled Autonomous Vehicle of AutoDRIVE Ecosystem\" at ASME Student Mechanism and Robot Design Competition (SMRDC) 2023</li> <li>Best Paper Award for paper \"AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education\" at CCRIS 2021</li> <li>Best Project Award for \"AutoDRIVE \u2013 An Integrated Platform for Autonomous Driving Research and Education\" at National Level IEEE Project Competition 2021</li> <li>Best Project Award for \"AutoDRIVE \u2013 An Integrated Platform for Autonomous Driving Research and Education\" at SRMIST Mechatronics Department 2021</li> <li>Gold Medal for paper \"AutoDRIVE \u2013 An Integrated Platform for Autonomous Driving Research and Education\" at SRMIST Research Day 2021</li> <li>Lightning Talk of \"AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education\" at ROS World 2020</li> <li>India Connect @ NTU Research Fellowship 2020 for \"AutoDRIVE Simulator\"</li> </ul>"},{"location":"about/#resources","title":"Resources","text":""},{"location":"about/#highlights","title":"Highlights","text":"<p>We encourage you to take a look at the following quick highlights to keep up with the recent advances in AutoDRIVE Ecosystem.</p> AutoDRIVE Ecosystem Pitch Video AutoDRIVE Simulator Pitch Video AutoDRIVE Testbed Pitch Video Nigel 4WD4WS Feature Video F1TENTH in AutoDRIVE Simulator OpenCAV in AutoDRIVE Simulator RZR in AutoDRIVE Simulator Parallel RL using AutoDRIVE Simulator Deformable Terrain in AutoDRIVE Simulator Variability Testing using Nigel Variability Testing using OpenCAV"},{"location":"about/#demonstrations","title":"Demonstrations","text":"<p>We encourage you to take a look at the following research projects developed using the AutoDRIVE Ecosystem.</p> Autonomous Parking Behavioural Cloning Intersection Traversal Smart City Management"},{"location":"about/#presentations","title":"Presentations","text":"<p>We encourage you to take a look at the following presentations to gain a better insight into the AutoDRIVE Ecosystem.</p> SRMIST UG Final Year Project Viva Voce CCRIS 2021 Virtual Presentation AutoDRIVE Technical Discussion @ ARMLab CU-ICAR Autoware COE Seminar AIM 2023 Video Presentation OpenCAV Technical Discussion @ ARMLab CU-ICAR OpenCAV CUICAR AuE Seminar SMRDC 2023 Finalist Pitch MECC 2023 Video Presentation IROS 2023 Presentation"},{"location":"about/#team","title":"Team","text":""},{"location":"about/#developers","title":"Developers","text":"Tanmay Vilas Samak Chinmay Vilas Samak"},{"location":"about/#contributors","title":"Contributors","text":"Rohit Ravikumar Parth Shinde Joey Binz Giovanni Martino"},{"location":"about/#mentors","title":"Mentors","text":"Dr. Venkat Krovi Dr. Sivanathan Kandhasamy Dr. Ming Xie"},{"location":"about/#institutions","title":"Institutions","text":"CU-ICAR SRM-IST NTU"},{"location":"blog/","title":"Blog","text":""},{"location":"competitions/","title":"COMPETITIONS","text":""},{"location":"competitions/f1tenth-sim-racing-cdc-2024/","title":"F1TENTH Sim Racing League @ CDC 2024","text":""},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#about","title":"About","text":"<p> F1TENTH Autonomous Racing is a semi-regular competition organized by an international community of researchers, engineers, and autonomous systems enthusiasts. The teams participating in the 22nd F1TENTH Autonomous Grand Prix at CDC 2024 will write software for a 1:10 scaled autonomous racecar to fulfill the objectives of the competition: drive fast but don\u2019t crash! </p> <p> This time, we are organizing the second F1TENTH Sim Racing League, which leverages AutoDRIVE Ecosystem to model and simulate the digital twin of an F1TENTH racecar within a virtual racetrack. Please see the accompanying video for a glimpse of the F1TENTH digital twins in action. </p> <p> The main focus of the Sim Racing League is a virtual competition with simulated cars and environments, which is accessible to everyone across the globe. For the CDC 2024 competition, each team will be provided with a standardized simulation setup (in the form of a digital twin of the F1TENTH vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. Additionally, teams will also be provided with a working implementation of the AutoDRIVE Devkit to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. </p> <p> The competition will take place in 2 stages: </p> <ul> <li>Qualification Race: Teams will demonstrate their ability to complete multiple laps around the practice track without colliding with the track bounds at run time.</li> <li>Time-Attack Race: Teams will compete against the clock, on a previously unseen racetrack, to secure a position on the leaderboard.</li> </ul> <p> Since the vehicle, the sensors, the simulator, and the devkit are standardized, teams must develop robust racing algorithms that can deal with the uncertainties of an unseen racetrack. </p> <p>Tip</p> <p>If you are interested in autonomously racing physical F1TENTH vehicles, please check out the website for 22<sup>nd</sup> F1TENTH Autonomous Grand Prix, which will be held in person at CDC 2024. You can always register and compete in both physical and virtual competitions!</p>"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#organizers","title":"Organizers","text":"Dr. Rahul Mangharam Dr. Venkat Krovi Dr. Johannes Betz Chinmay Samak Tanmay Samak Ahmad Amine Dr. Paolo Burgio Dr. Maria Prandini Dr. Martina Maggio Dr. Alessio Masola Dr. Filippo Muzzini Dr. Federico Gavioli Antonio Russo Enrico Mannocci"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#timeline","title":"Timeline","text":"<p>Warning</p> <p>Timeline is subject to change. Please keep checking this page for any updates.</p> DATE EVENT Aug 01, 2024 Registration Opens Oct 31, 2024 Registration Closes Nov 08, 2024 (5:30 \u2013 6:30 PM EST) Online Orientation 1 Nov 23, 2024 (1:00 \u2013 2:00 PM EST) Online Orientation 2 Nov 30 \u2013 Dec 01, 2024 Qualification Round Dec 02, 2024 Qualification Results Declared Dec 04, 2024 Competition Track Released Dec 07 \u2013 Dec 08, 2024 Final Race Dec 09, 2024 Competition Results Declared <p> Following is a brief summary of each event: </p> <ul> <li>Registration: Interested teams will register for the Sim Racing League.</li> <li>Online Orientation 1: Organizers will explain the competition rules and guidelines, and demonstrate how to use the simulation framework.</li> <li>Online Orientation 2: Organizers will check progress of the participating teams and help with any technical difficulties.</li> <li>Qualification Round: Teams will demonstrate successful completion of 10 laps around the practice track provided ahead of time.</li> <li>Qualification Results Declared: Standings of all the qualified teams will be released.</li> <li>Competition Track Released: Organizers will release the actual \"competition track\", which will be used for the final race. This track may be replicated in the physical race as well.</li> <li>Final Race: Organizers will collect containerized algorithms from each team and connect them with the containerized simulator. Performance metrics of each team will be recorded.</li> <li>Competition Results Declared: Standings of all the teams for the final race will be released.</li> </ul> <p>Info</p> <p>The F1TENTH Sim Racing League will be held approximately 1 week ahead of CDC 2024 and the performance metrics will be made available to the teams. We have also been able to organize a special session for F1TENTH Sim Racing League Celebration on Monday (Dec 16), 18:00-19:00 CET with the help of the CDC organizing committee. Join the celebration event to relive the nail-biting races, hear the top teams brag about their winning strategies (~5 min presentations), and start your engines for the physical competition.</p>"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#resources","title":"Resources","text":"<p> AutoDRIVE is envisioned to be an open, comprehensive, flexible and integrated cyber-physical ecosystem for enhancing autonomous driving research and education. It bridges the gap between software simulation and hardware deployment by providing the AutoDRIVE Simulator and AutoDRIVE Testbed, a well-suited duo for real2sim and sim2real transfer targeting vehicles and environments of varying scales and operational design domains. It also offers AutoDRIVE Devkit, a developer's kit for rapid and flexible development of autonomy algorithms using a variety of programming languages and software frameworks. For the Sim Racing League, teams will develop their autonomous racing algorithms using the AutoDRIVE Devkit to interface with the AutoDRIVE Simulator in real-time. </p> <p></p> <p> F1TENTH is an international community of researchers, engineers, and autonomous systems enthusiasts. It is centered around the idea of converting a 1:10 scale RC car into an autonomous vehicle for research and education; check out the documentation to build your own F1TENTH autonomous racecar. Additionally, if you are new to the field of autonomous racing, you can refer to the complete course material, which is open sourced. If you already have some experience with autonomous racing, feel free to delve deeper into the research enabled by F1TENTH. Lastly, you can also check out the physical F1TENTH races that are being organized all around the world. For the Sim Racing League, teams will not require a physical F1TENTH vehicle; however, the learning resources can certainly be useful to get your autonomous racing fundamentals right! </p> <p> We recommend all the teams interested in participating in the F1TENTH Sim Racing League to get accustomed with the competition. Following are a few resources to get you started: </p> <ul> <li> <p> Competition Documents</p> <p>Learn about the competition rules and technical aspects of the framework.</p> <p> Competition Rules</p> <p> Technical Guide</p> </li> <li> <p> Docker Containers</p> <p>Download base container images for the competition and start developing your algorithms.</p> <p> AutoDRIVE Simulator: <code>explore</code> | <code>practice</code> | <code>compete</code></p> <p> AutoDRIVE Devkit: <code>explore</code> | <code>practice</code> | <code>compete</code></p> </li> <li> <p> Local Resources</p> <p>Get started with the competition framework locally, and worry about containerization later. </p> <p>AutoDRIVE Simulator:</p> <p><code>explore</code>  Linux |  Windows |  macOS</p> <p><code>practice</code>  Linux |  Windows |  macOS</p> <p><code>compete</code>  Linux |  Windows |  macOS</p> <p>AutoDRIVE Devkit:</p> <p> ROS 2</p> </li> <li> <p> Orientation Resources</p> <p>Join the online orientation sessions or review what we covered there.</p> <p>Orientation 1:</p> <p>Meeting Link:  Zoom</p> <p>Review Links:  Recording |  Slides</p> <p>Orientation 2:</p> <p>Meeting Link:  Zoom</p> <p>Review Links:  Recording |  Slides</p> </li> </ul> <p>Question</p> <p>You can post general questions on the  AutoDRIVE Slack workspace; this is the preferred modality. Technical questions can be also posted as  GitHub Issues or  GitHub Discussions. For any other questions or concerns that cannot be posted publicly, please contact  Chinmay Samak or  Tanmay Samak.</p>"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#registration","title":"Registration","text":"<p> This competition is open to everyone around the world - students, researchers, hobbyists, professionals, or anyone else who is interested. A team can consist of multiple teammates. Teams with only one person are also allowed. </p>  Registration Form <p> Registration for the Sim Racing League is free of cost and separate from the Physical Racing League and the conference registrations themselves. The above form signs you up only for the Sim Racing League, and for its orientation and information sessions. Although you can participate in the Sim Racing League without attending the conference, we strongly encourage all competition participants to attend the conference in person. This will help you connect with the broader AutoDRIVE and F1TENTH communities, and you can also witness/participate in the physical F1TENTH autonomous racing competition! </p> <p> Registered teams are added to the following table: </p> SR. NO. TEAM NAME TEAM MEMBERS ORGANIZATION 01 Beryllium Ronnie Romman Personal 02 AERObotics Arif AnjumMuhammed Sharjil AEROBOTICS 03 Pharst Laps Olivia DryTian ZhaoYitian ChenAmir Ali Farzin Australian National University 04 SeDriCa-UMIC Kshitij VaidyaYash GuptaManav JainParth AgrawalSahil KukrejaJohan BijuPaawan NenwaniShivam Yadav Indian Institute of Technology, Bombay 05 Unimelb F1Tenth Racing Henry YapeterMatthew FreemanNathan RuslimHarry Tauber The University of Melbourne 06 Donatello Rahil Bhowal Personal 07 VAUL Tommy Bouchard-LebrunWilliam FecteauNicolas Lauzon Laval University 08 TUM Phoenix Dean MercerZara Zhotabayeva Technische Universit\u00e4t M\u00fcnchen 09 Autonomous Motorsports Purdue Manav GagvaniAlan KangSivamurugan VelmuruganRohan PottaSangeet Mohan Purdue University 10 Pegasus Zeyuan WangChao Wang Personal 11 ARCLab William AkuffoJoshua NtiReginald Andrew Sai-ObodaiBaron AfutuJoel Osei-Asamoah Ashesi University 12 YTU AESK Mahmut DemirAhmet \u00c7elik\u0130layda Sena \u015eahinFurkan Erdo\u011fanAlper Y\u0131lmazEnes Talha G\u00fcnayTaha \u0130lter AkarHilal Horasan Y\u0131ld\u0131z Technical University Alternative Energy Systems Society 13 MMS Autonomous Yousef AsalZaynap AhmadOmar AshrafOmar ElsharabasyAbdallah NabilAhmed ElShaboury Mansoura University 14 HUN-REN SZTAKI Csan\u00e1d BudaiTam\u00e1s Sz\u00e9les HUN-REN SZTAKI 15 bracaai Luis Bracamontes Personal 16 Velox Karun Ashok Kumar University of Twente 17 Exhausted Lion Mohamed Alaa Personal 18 Sahruday Patti Sahruday Patti Personal 19 Als F1Tenth Racing Auriol Ble Alpha Space Robotics Lab 20 SoloDriver Hana Nabhan Personal 21 Daniel's RL Experiment Daniel Mittelman Georgia Institute of Technology 22 TURTLEBOT Jit Ern Lim Personal 23 TractionX Ameya BagalAnanya DasAmizhthni PRK Indian Institute of Technology, Madras 24 Awareness Guodong Zhu Nanjing Forest University 25 Byte Benders Bhajneet Singh BediYaduraj Jagadeesan Personal 26 Eigenbots Shubham BargeAnshuman Jena Personal 27 __duronto__ Md. JesanMuhammad Fahim FaisalAbu Nafis Mohammod Noor RohanRakibul Islam Rakib BRAC University, Dhaka Residential Model College 28 MV33F110 Vishwanath R Personal 29 F1NESSE - Formula 1 Neuro-Enhanced System for Smart Execution Oscar Guerrero RosadoJoris KranzJan HoningWout Laracker Radboud University, ROC Nijmegen 30 Baby Driver Mason Notz Personal 31 Asturian Kingdom Team David MirandaLuc\u00eda S\u00e1nchezMiguel Santamar\u00eda University of Oviedo 32 AsTenth Martin Ajay Shankar Sriram UC Irvine 33 Ray C.E.R.S. Aditya JambhaleAkshat Tambi SRM Institute of Science and Technology 34 Neutrino Ahmed ElnelyAbdallah AtefMohamed AbdelmoneamNoran MohamedYasmin KhaledNouran Karam Egyptian Russian University 35 Zancle E-Drive Gaetano Pio PispisaGiovanni LombardoSimone Castorino University of Messina, Italy 36 sim_goes_brrrrrr_mha Marzanul MomenineMaidul IslamHironmoy Roy Rudra Personal 37 Inertia Mushfiqur RahmanAl Mahir AhmedSuhail Haque RafiAbrar Ahmed Personal 38 Assiut Motorsport Omar AbbasKareem SalahMohamed Abd-El-FattahAhmed ShehataDoaa IbrahemEslam MohamedArwa IbrahimMaotaz RefaatFajr MohamedAhmed Mohamed Assiut University 39 SELF Zhuo OuyangPengcheng YouChang LiuYingzhu LiuChengrui Qu Peking University 40 Triton AI Yen-Ru ChenWinston ChouKevin ShinSamuel LinSurya SettyAryan Palaskar University of California, San Diego 41 Escuderia Brasileira de Ve\u00edculos Aut\u00f4nomos Fernando Zolubas PretoAntonio Colombini NetoFelipe Gomes de Melo D'EliaCarlos Alberto Arronte DelgadoFrancisco Rodrigues MaraziaLuccas BarsottiCaio Victor Goveia Freitas Polytechnic School of the University of S\u00e3o Paulo - Brazil 42 Autonomous Ground Vehicle Shreyansh KansalSwaminathan S KYash SirviAditya SrivastavaAkshit GoyalAtul SinghRohan SinghTheyanesh E RSandip DasArham J BhansaliAnsh SharmaSamarth G Indian Institute of Technology, Kharagpur 43 SUST Autodrive Abul Bashar RazMd. Redwan HasanEhsanul Karim AslamMd. Tamzid Islam Babul Shahjalal University of Science and Technology 44 Sabeq Adham WaleedAbdulrahman AhmedNabil FoudaMostafa Samy Ain Shams University 45 RapidRabbits Aryan IyerSiddhant Diwaker Personal 46 Orion U Skanda AithalAryan AgarwalAditya GuptaAman KumarLakshmikanth Nageswar Personal 47 KOU-Mekatronom Mehmet Baha DursunMuvahhid K\u0131l\u0131\u00e7Can Ercan Personal 48 CLUTCH Emmanuel KorankyeAppenteng AdjepongSamuel AkwensivieKobena EnyamDesmond Hammond Personal 49 SimRacer Vinura Wanniarachchi Personal 50 WaterlooF110 Megnath RameshShaswat GargAvraiem IskanderPraneeth KVK University of Waterloo 51 AA LAB Taha KocyigitTaha Yigit Erdogan Bogazici University <p>Note</p> <p>The above table will be updated with newly registered teams within a few days of registration. Please contact  Chinmay Samak or  Tanmay Samak if you do not see your team entry for more than 7 days after registering.</p>"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#submission","title":"Submission","text":"<p> Use the secure form below to make your team's submission for Phase 1 (Qualification Round) of the F1TENTH Sim Racing League. Please fill in your team's name and add the link to your team's DockerHub repository containing the autonomous racing stack. If you are using a private repository, make sure to add autodriveecosystem as a collaborator to your repository. </p>  Phase 1 Submission Form <p>Warning</p> <p>Phase 1 submission window will close on Nov 30, 2024. Please contact  Chinmay Samak or  Tanmay Samak if you have any questions.</p> <p> Use the secure form below to make your team's submission for Phase 2 (Final Race) of the F1TENTH Sim Racing League. Please fill in your team's name and add the link to your team's DockerHub repository containing the autonomous racing stack. If you are using a private repository, make sure to add autodriveecosystem as a collaborator to your repository. </p>  Phase 2 Submission Form <p>Warning</p> <p>Phase 2 submission window will close on Dec 07, 2024. Please contact  Chinmay Samak or  Tanmay Samak if you have any questions.</p>"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#results","title":"Results","text":"<p>Phase 1: Qualification</p> <p> The following teams have qualified for the final time-attack race. Here are the official standings: </p> RANK TEAM NAME RACE TIME COLLISION COUNT ADJUSTED RACE TIME BEST LAP TIME VIDEO 01 \ud83d\udc4f VAUL 70.30 s 0 70.30 s 6.96 s  YouTube 02 \ud83d\udc4f Asturian Kingdom Team 75.27 s 0 75.27 s 7.52 s  YouTube 03 \ud83d\udc4f SoloDriver 82.97 s 0 82.97 s 8.27 s  YouTube 04 \ud83d\udc4f TURTLEBOT 90.33 s 0 90.33 s 8.98 s  YouTube 05 \ud83d\udc4f Byte Benders 85.61 s 1 95.61 s 8.29 s  YouTube 06 \ud83d\udc4f AsTenth Martin 92.44 s 1 102.44 s 9.08 s  YouTube 07 \ud83d\udc4f Pharst Laps 93.69 s 1 103.69 s 9.24 s  YouTube 08 \ud83d\udc4f Autonomous Ground Vehicle 111.94 s 1 121.94 s 10.55 s  YouTube 09 \ud83d\udc4f Autonomous Motorsports Purdue 122.34 s 0 122.34 s 12.22 s  YouTube 10 \ud83d\udc4f Escuderia Brasileira de Ve\u00edculos Aut\u00f4nomos 114.19 s 1 124.19 s 11.33 s  YouTube 11 \ud83d\udc4f YTU AESK 125.14 s 0 125.14 s 12.47 s  YouTube 12 \ud83d\udc4f Zancle E-Drive 126.79 s 0 126.79 s 12.65 s  YouTube 13 \ud83d\udc4f Baby Driver 122.66 s 1 132.66 s 12.19 s  YouTube 14 \ud83d\udc4f Pegasus 146.82 s 0 146.82 s 14.65 s  YouTube 15 \ud83d\udc4f MMS Autonomous 113.15 s 5 163.15 s 10.90 s  YouTube 16 \ud83d\udc4f WaterlooF110 190.31 s 0 190.31 s 18.78 s  YouTube 17 \ud83d\udc4f bracaai 201.09 s 0 201.09 s 19.68 s  YouTube 18 \ud83d\udc4f Assiut Motorsport 112.09 s 9 202.09 s 10.74 s  YouTube 19 \ud83d\udc4f SeDriCa-UMIC 185.18 s 2 205.18 s 18.34 s  YouTube 20 \ud83d\udc4f Sabeq 128.63 s 10 228.63 s 12.50 s  YouTube <p>Phase 2: Competition</p> <p> The following teams successfully finished the final time-attack race. Here are the official standings: </p> RANK TEAM NAME RACE TIME COLLISION COUNT ADJUSTED RACE TIME BEST LAP TIME VIDEO 01 \ud83e\udd47 VAUL 103.84 s 0 103.84 s 10.35 s  YouTube 02 \ud83e\udd48 Baby Driver 136.63 s 0 136.63 s 13.58 s  YouTube 03 \ud83e\udd49 TURTLEBOT 145.99 s 0 145.99 s 14.42 s  YouTube 04 \ud83d\udc4f Asturian Kingdom Team 150.76 s 1 160.76 s 14.91s  YouTube 05 \ud83d\udc4f Pharst Laps 151.37 s 3 181.37 s 14.79 s  YouTube 06 \ud83d\udc4f bracaai 167.15 s 2 187.15 s 16.34 s  YouTube 07 \ud83d\udc4f Byte Benders 195.76 s 2 215.76 s 18.99 s  YouTube 08 \ud83d\udc4f Autonomous Motorsports Purdue 211.76 s 1 221.76 s 20.48 s  YouTube 09 \ud83d\udc4f Escuderia Brasileira de Ve\u00edculos Aut\u00f4nomos 219.45 s 1 229.45 s 21.74 s  YouTube 10 \ud83d\udc4f Pegasus 227.29 s 1 237.29 s 21.72 s  YouTube 11 \ud83d\udc4f Zancle E-Drive 241.64 s 0 241.64 s 24.04 s  YouTube 12 \ud83d\udc4f MMS Autonomous 155.19 s 9 245.19 s 15.09 s  YouTube 13 \ud83d\udc4f SoloDriver 259.23 s 1 269.23 s 24.59 s  YouTube <p>Celebration Event @ CDC 2024</p> <p> \ud83c\udf89 Please join us (in-person or virtually) for the celebration event of the 2nd F1TENTH Sim Racing League @ CDC 2024 on Monday (Dec 16, 2024) between 18:00-19:00 CET! \ud83c\udfc1 </p> <p> \ud83c\udfa4 Agenda: </p> <ul> <li>Introduction &amp; Overview (15 min) \u2013 Dr. Krovi &amp; Dr. Mangharam</li> <li>Competition Insights (20 min) \u2013 Tanmay &amp; Chinmay</li> <li>Words from the Winners (15 min) \u2013 5 min for each team</li> <li>Concluding Remarks (10 min) \u2013 Dr. Krovi &amp; Dr. Mangharam</li> </ul> <p> \ud83d\udcbb Zoom: https://tinyurl.com/f1tenth-cdc24-virtual-race </p> <p> \ud83c\udfc6 Don't miss this chance to relive the thrill of the competition and hear from the champions themselves! </p> <ul> <li> <p> Celebration Event Recording</p> <p></p> </li> <li> <p> Words from the Winners!</p> <p></p> </li> <li> <p> Celebration Event Slides - Part 1</p> <p></p> </li> <li> <p> Celebration Event Slides - Part 2</p> <p></p> </li> </ul>"},{"location":"competitions/f1tenth-sim-racing-cdc-2024/#summary","title":"Summary","text":""},{"location":"competitions/f1tenth-sim-racing-guide/","title":"Technical Guide","text":"<p> This document describes the technical details of the competition framework for the F1TENTH Sim Racing League. It goes over the details pertaining to the simulator and devkit, as well as some important aspects of the submission system, process, and evaluation. </p> <p>Warning</p> <p>It expected that teams have sufficient background knowledge pertaining to autonomous racing (concepts, methods, and algorithms), programming languages (Python, C++, etc.) and frameworks (ROS 2), containerization (Docker) and version control (Git), etc. In order to be fair to all teams and keep the competition on schedule, extensive technical support/help cannot be provided by the organizers. However, legitimate requests may be entertained at the discretion of the organizers.</p> <p>Note</p> <p>Although AutoDRIVE Ecosystem supports various vehicles across different scales, configurations, and operational design domains (ODDs), the only vehicle allowed for this competition is the F1TENTH. Similarly, although AutoDRIVE Ecosystem supports multiple application programming interfaces (APIs), the only API allowed for this competition is ROS 2.</p> <p>Please see the accompanying video for a step-by-step tutorial of setting up and using the competition framework.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#1-autodrive-simulator","title":"1. AutoDRIVE Simulator","text":"<p> AutoDRIVE Simulator (part of the larger AutoDRIVE Ecosystem) is an autonomy oriented tool designed to model and simulate vehicle and environment digital twins. It equally prioritizes backend physics and frontend graphics to achieve high-fidelity simulation in real-time. From a computing perspective, the simulation framework is completely modular owing to its object-oriented programming (OOP) constructs. Additionally, the simulator can take advantage of CPU multi-threading as well as GPU instancing (if available) to efficiently parallelize various simulation objects and processes, with cross-platform support. </p> <p> For the F1TENTH Sim Racing League, each team will be provided with a standardized simulation setup (in the form of a digital twin of the F1TENTH vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. This would democratize autonomous racing and make this competition accessible to everyone across the globe. </p>"},{"location":"competitions/f1tenth-sim-racing-guide/#11-system-requirements","title":"1.1. System Requirements","text":"<p> Minimum Requirements: </p> <ul> <li>Platform: Ubuntu 20.04+, Windows 10+, macOS 10.14+ (simulator has cross-platform compatibility)</li> <li>Processor: Quad-core CPU (e.g., Intel Core i5 or AMD Ryzen 5)</li> <li>Memory: 8 GB RAM</li> <li>Graphics: Integrated graphics (e.g., Intel HD Graphics) or a low-end discrete GPU (e.g., NVIDIA GeForce GTX 1050) with at least 2 GB of VRAM</li> <li>Storage: 10 GB of free disk space (for storing Docker images, simulator application and data)</li> <li>Display: 1280x720 px resolution with 60 Hz refresh rate</li> <li>Network: Stable internet connection (1 Mbps) for pulling/pushing Docker images, and downloading updates on demand</li> </ul> <p> Recommended Requirements: </p> <ul> <li>Platform: Ubuntu 20.04/22.04, Windows 10/11 (simulator has been extensively tested on these platforms)</li> <li>Processor: Octa-core CPU (e.g., Intel Core i7 or AMD Ryzen 7)</li> <li>Memory: 16 GB RAM</li> <li>Graphics: Mid-range discrete GPU (e.g., NVIDIA GeForce GTX 1660 or RTX 2060) with 4+ GB of VRAM</li> <li>Storage: 20 GB of free disk space (to accommodate multiple Docker images, additional data, and logs)</li> <li>Display: 1920x1080 px resolution with 144 Hz refresh rate</li> <li>Network: Fast internet connection (10 Mbps) for pulling/pushing Docker images, and downloading updates on the fly</li> </ul> <p>Info</p> <p>Note that the organizers will execute the competition framework on a workstation incorporating Intel Core i9 14<sup>th</sup> Gen 14900K CPU, NVIDIA GeForce RTX 4090 GPU, and 64 GB RAM (or a similar configuration). This machine will be simultaneously running the simulator container, devkit container, screen recorder and data logger. Kindly develop your algorithms while considering these computational requirements.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#12-user-interface","title":"1.2. User Interface","text":"<p> AutoDRIVE Simulator's graphical user interface (GUI) consists of a toolbar encompassing two panels for observing and interacting with key aspects of the simulator in real-time, namely Menu and Heads-Up Display (HUD). Both the panels can be enabled or disabled using the burger icons provided on the toolbar; the figure above illustrates both the GUI panels being enabled. The menu panel on the left-hand side helps configure and control some important aspects of the simulation with just a few clicks. The HUD panel on the right-hand side helps visualize prominent simulation parameters along with vehicle status and sensory data, while hosting a time-synchronized data recording functionality that can be used to export simulation data for a specific run. </p>"},{"location":"competitions/f1tenth-sim-racing-guide/#121-menu-panel","title":"1.2.1. Menu Panel","text":"<ul> <li>IP Address Field: Input field to specify IP address for the machine running the devkit (default is 127.0.0.1, i.e., standard address for IPv4 loopback traffic).   <li>Port Number Field: Input field to specify port number for the machine running the devkit (default is 4567, observed to be usually unoccupied).   <li>Connection Button: Button to establish connection with the devkit, which acts as the server with the simulator being the client (the button is disabled once the connection is established). The status of bridge connection (i.e., Connected or Disconnected) is displayed besides this button.   <li>Driving Mode Button: Button to toggle the driving mode of the vehicle between Manual and Autonomous (default is Manual). The selected driving mode is displayed besides this button.   <li>Camera View Button: Button to toggle the scene camera view between Driver\u2019s Eye, Bird\u2019s Eye and God\u2019s Eye (default is Driver\u2019s Eye). The selected view is displayed besides this button.   <li>Graphics Quality Button: Button to toggle the graphics quality view between Low, High, and Ultra (default is Low). The selected quality is displayed besides this button.   <li>Scene Light Button: Button to enable/disable the environmental lighting (default is enabled).   <li>Reset Button: Button to reset the simulator to initial conditions.   <li>Quit Button: Button to quit the simulator application."},{"location":"competitions/f1tenth-sim-racing-guide/#122-hud-panel","title":"1.2.2. HUD Panel","text":"<ul> <li>Simulation Time: The time (HH:MM:SS) since start of the simulation. Reset button resets the simulation time.   <li>Frame Rate: Running average of the FPS value (Hz).   <li>Driving Mode: Driving mode of the ego-vehicle (Manual or Autonomous).   <li>Gear: Driving gear of the vehicle, either Drive (D) or Reverse (R).   <li>Speed: Magnitude of forward velocity of the vehicle (m/s).   <li>Throttle: Instantaneous throttle input of the vehicle (%).   <li>Steering: Instantaneous steering angle of the vehicle (rad).   <li>Encoder Ticks: Ticks (counts) of the rear-left and rear-right incremental encoders of the vehicle represented using a 1D array of 2 elements [left_ticks, right_ticks].   <li>IPS Data: Position (m) of the vehicle within the environment represented using a 1D vector [x, y, z].   <li>IMU Data: Orientation [x, y, z] rad, angular velocity [x, y, z] rad/s, and linear acceleration [x, y, z] m/s<sup>2</sup> of the ego-vehicle w.r.t. body frame of reference.   <li>LIDAR Measurement: Instantaneous ranging measurement (m) of the 270\u00b0 FOV 2D LIDAR on the vehicle.   <li>Camera Preview: Instantaneous raw image from the front camera of the vehicle.   <li>Race Telemetry: Current elapsed lap time (s), last lap time (s), overall best lap time (s) as well as total lap count data.   <li>Data Recorder: Save time-synchronized simulation data for a specific simulation run."},{"location":"competitions/f1tenth-sim-racing-guide/#123-data-recorder","title":"1.2.3. Data Recorder","text":"<p>AutoDRIVE Simulator hosts a time-synchronized data recording functionality that can be used to export simulation data at 30 Hz. The data is saved in <code>CSV</code> format and the raw camera frames are exported as timestamped <code>JPG</code> files. The <code>CSV</code> file hosts the following data entries per timestamp:</p> DATA timestamp throttle steering leftTicks rightTicks posX posY posZ roll pitch yaw speed angX angY angZ accX accY accZ camera lidar UNIT yyyy_MM_dd_HH_mm_ss_fff norm% rad count count m m m rad rad rad m/s rad/s rad/s rad/s m/s^2 m/s^2 m/s^2 img_path array(float) <p>The data recorder can be triggered by clicking on the red <code>Record Data</code> button in the HUD panel, or using the <code>R</code> hotkey. The first time, the data recorder will prompt the user to specify the directory path to store the data. The second trigger will start recording the data, which can be verified by checking the status of the red button change from <code>Record Data</code> to <code>Recording Data</code>. Finally, the third trigger will stop data recording, which can be verified by checking the status of the red button change from <code>Recording Data</code> to <code>Saving Data</code> with the save percentage being displayed.</p> <p>Info</p> <p>When specifying the directory path to store the data, just select the directory where you want the data to be saved with a single click, do not enter that directory by double-clicking onto it.</p> <p>Warning</p> <p>Although the data is meant to be recorded at 30 Hz, the actual rate depends on the compute power and the OS schedular, and may therefore fluctuate a bit. However, the data will still be time-synchronized.</p> <p>Note</p> <p>If you try to record data two (or more) times in a row, without resetting or restarting the simulator, the new data will be appended to the same <code>CSV</code> file and the new camera frames will be added to the same <code>Camera Frames</code> directory. The old data will not be overwritten for user convenience and one can differentiate between the old and new datasets using the <code>timestamp</code> variable. However, if this is not intended, please consider resetting or restarting the simulator and specifying a different directory to store the new data.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#13-vehicle","title":"1.3. Vehicle","text":"<p>Simulated vehicles can be developed using AutoDRIVE's modular scripts, or imported from third-party tools and open standards. Specifically, the F1TENTH vehicle was reverse-engineered and visually recreated using a third-party 3D modeling software, and was imported and post-processed within AutoDRIVE Simulator to make it physically and graphically \"sim-ready\".</p> <p>These vehicles are simulated as a combination of rigid body and sprung mass representations with adequate attention to rigid body dynamics, suspension dynamics, actuator dynamics, and tire dynamics. Additionally, the simulator detects mesh-mesh interference and computes contact forces, frictional forces, momentum transfer, as well as linear and angular drag acting on the vehicle. Finally, being an autonomy-oriented digital twin, the simulator offers physically-based sensor simulation for proprioceptive as well as exteroceptive sensors on-board the virtual vehicle.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#131-transforms","title":"1.3.1. Transforms","text":"<p>Note</p> <p>All right-handed coordinate frames depicted above are defined such that red represents x-axis, green represents y-axis, and blue represents z-axis.</p>  FRAME x y z R P Y <code>left_encoder</code> 0.0 0.118 0.0 0.0 0.0 <code>right_encoder</code> 0.0 -0.118 0.0 0.0 0.0 <code>ips</code> 0.08 0.0 0.055 0.0 0.0 0.0 <code>imu</code> 0.08 0.0 0.055 0.0 0.0 0.0 <code>lidar</code> 0.2733 0.0 0.096 0.0 0.0 0.0 <code>front_camera</code> -0.015 0.0 0.15 0.0 10.0 0.0 <code>front_left_wheel</code> 0.33 0.118 0.0 0.0 0.0 <code>front_right_wheel</code> 0.33 -0.118 0.0 0.0 0.0 <code>rear_left_wheel</code> 0.0 0.118 0.0 0.0 0.0 <code>rear_right_wheel</code> 0.0 -0.118 0.0 0.0 0.0 <p>Note</p> <p>All frame transforms mentioned above are defined w.r.t. the vehicle (local) frame of reference  <code>f1tenth_1</code> located at the center of rear axle with x-axis pointing forward, y-axis pointing left, and z-axis pointing upwards. Columns x, y, and z denote translations in meters (m), while R, P, and Y denote rotations in degrees (deg).  denotes variable quantities.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#132-vehicle-dynamics","title":"1.3.2. Vehicle Dynamics","text":"<p>The vehicle model is a combination of a rigid body and a collection of sprung masses \\(^iM\\), where the total mass of the rigid body is defined as \\(M=\\sum{^iM}\\). The rigid body's center of mass, \\(X_{COM} = \\frac{\\sum{{^iM}*{^iX}}}{\\sum{^iM}}\\), connects these representations, with \\(^iX\\) representing the coordinates of the sprung masses.</p> <p>The suspension force acting on each sprung mass is computed as \\({^iM} * {^i{\\ddot{Z}}} + {^iB} * ({^i{\\dot{Z}}}-{^i{\\dot{z}}}) + {^iK} * ({^i{Z}}-{^i{z}})\\), where \\(^iZ\\) and \\(^iz\\) are the displacements of sprung and unsprung masses, and \\(^iB\\) and \\(^iK\\) are the damping and spring coefficients of the \\(i\\)-th suspension, respectively. The unsprung mass \\(m\\) is also subject to gravitational and suspension forces: \\({^im} * {^i{\\ddot{z}}} + {^iB} * ({^i{\\dot{z}}}-{^i{\\dot{Z}}}) + {^iK} * ({^i{z}}-{^i{Z}})\\).</p> <p>Tire forces are computed based on the friction curve for each tire, represented as \\(\\left\\{\\begin{matrix} {^iF_{t_x}} = F(^iS_x) \\\\{^iF_{t_y}} = F(^iS_y) \\\\ \\end{matrix}\\right.\\), where \\(^iS_x\\) and \\(^iS_y\\) are the longitudinal and lateral slips of the \\(i\\)-th tire, respectively. The friction curve is approximated using a two-piece cubic spline, defined as \\(F(S) = \\left\\{\\begin{matrix} f_0(S); \\;\\; S_0 \\leq S &lt; S_e \\\\ f_1(S); \\;\\; S_e \\leq S &lt; S_a \\\\ \\end{matrix}\\right.\\), where \\(f_k(S) = a_k*S^3+b_k*S^2+c_k*S+d_k\\) is a cubic polynomial function. The first segment of the spline ranges from zero \\((S_0,F_0)\\) to an extremum point \\((S_e,F_e)\\), while the second segment ranges from the extremum point \\((S_e, F_e)\\) to an asymptote point \\((S_a, F_a)\\).</p> <p>The tire slip is influenced by factors including tire stiffness \\(^iC_\\alpha\\), steering angle \\(\\delta\\), wheel speeds \\(^i\\omega\\), suspension forces \\(^iF_s\\), and rigid-body momentum \\(^iP\\). These factors impact the longitudinal and lateral components of the vehicle's linear velocity. The longitudinal slip \\(^iS_x\\) of \\(i\\)-th tire is calculated by comparing the longitudinal components of the surface velocity of the \\(i\\)-th wheel \\(v_x\\) with the angular velocity \\(^i\\omega\\) of the \\(i\\)-th wheel: \\({^iS_x} = \\frac{{^ir}*{^i\\omega}-v_x}{v_x}\\). The lateral slip \\(^iS_y\\) depends on the tire's slip angle \\(\\alpha\\) and is determined by comparing the longitudinal \\(v_x\\) and lateral \\(v_y\\) components of the vehicle's linear velocity: \\({^iS_y} = \\tan(\\alpha) = \\frac{v_y}{\\left| v_x \\right|}\\).</p>  VEHICLE PARAMETERS Car Length 0.5000 m Car Width 0.2700 m Wheelbase 0.3240 m Track Width 0.2360 m Front Overhang 0.0900 m Rear Overhang 0.0800 m Wheel Radius 0.0590 m Wheel Width 0.0450 m Total Mass 3.906 kg Sprung Mass 3.470 kg Unsprung Mass 0.436 kg Center of Mass X: 0.15532 mY: 0.00000 mZ: 0.01434 m Suspension Spring 500 N/m Suspension Damper 100 Ns/m Longitudinal Tire Limits (Slip, Force) Extremum: (0.15, 0.72)Asymptote: (0.25, 0.464) Lateral Tire Limits (Slip, Force) Extremum: (0.01, 1.00)Asymptote: (0.10, 0.500)"},{"location":"competitions/f1tenth-sim-racing-guide/#133-actuator-dynamics","title":"1.3.3. Actuator Dynamics","text":"<p>The driving actuators apply torque to the wheels: \\({^i\\tau_{drive}} = {^iI_w}*{^i\\dot{\\omega}_w}\\), where \\({^iI_w} = \\frac{1}{2}*{^im_w}*{^i{r_w}^2}\\) represents the moment of inertia, \\(^i\\dot{\\omega}_w\\) is the angular acceleration, \\(^im_w\\) is the mass, and \\(^ir_w\\) is the radius of the \\(i\\)-th wheel. Additionally, the driving actuators simulate idle torque by applying an equivalent braking torque, i.e., \\({^i\\tau_{idle}} = {^i\\tau_{brake}}\\).</p>  DRIVING ACTUATOR Drive Type All wheel drive Throttle Limits [-1,1] Motor Torque 428 Nm Vehicle Top Speed 22.88 m/s <p>The front wheels are steered at the commanded steering angle \\(\\delta\\) using a steering actuator. The individual turning angles, \\(\\delta_l\\) and \\(\\delta_r\\), for the left and right wheels, respectively, are computed based on the Ackermann steering geometry defined by the wheelbase \\(l\\) and track width \\(w\\), as follows: \\(\\left\\{\\begin{matrix} \\delta_l = \\textup{tan}^{-1}\\left(\\frac{2*l*\\textup{tan}(\\delta)}{2*l+w*\\textup{tan}(\\delta)}\\right) \\\\ \\delta_r = \\textup{tan}^{-1}\\left(\\frac{2*l*\\textup{tan}(\\delta)}{2*l-w*\\textup{tan}(\\delta)}\\right) \\end{matrix}\\right.\\)</p>  STEERING ACTUATOR Steer Type Ackermann steering Steering Limits [-1,1] Steering Angle Limits [-0.5236,0.5236] rad Steering Rate 3.2 rad/s"},{"location":"competitions/f1tenth-sim-racing-guide/#134-sensor-physics","title":"1.3.4. Sensor Physics","text":"<p>Throttle (\\(\\tau\\)) and steering (\\(\\delta\\)) sensors are simulated using an instantaneous feedback loop. Incremental encoders are simulated by measuring the rotation of the rear wheels: \\(^iN_{ticks} = {^iPPR} * {^iCR} * {^iN_{rev}}\\), where \\(^iN_{ticks}\\) and \\(^iPPR\\) respectively represent the measured ticks and base resolution (pulses per revolution) of the \\(i\\)-th encoder, while \\(^iCR\\) and \\(^iN_{rev}\\) respectively represent the conversion ratio and output shaft revolutions of the \\(i\\)-th motor.</p>  THROTTLE SENSOR Type Virtual Sensor Class Actuator Feedback Supported Outputs [-1, 1]  STEERING SENSOR Type Virtual Sensor Class Actuator Feedback Supported Outputs [-1, 1]  ENCODERS Type Simulated Sensor Class Proprioceptive Pulses Per Revolution 16 Conversion Ratio 120 Supported Outputs TicksAngles <p>The indoor positioning system (IPS) and inertial measurement unit (IMU) are simulated based on temporally-coherent rigid-body transform updates of the vehicle \\(\\{v\\}\\) w.r.t. the world \\(\\{w\\}\\): \\({^w\\mathbf{T}_v} = \\left[\\begin{array}{c | c} \\mathbf{R}_{3 \\times 3} &amp; \\mathbf{t}_{3 \\times 1} \\\\ \\hline \\mathbf{0}_{1 \\times 3} &amp; 1 \\end{array}\\right] \\in SE(3)\\). IPS provides 3-DOF positional coordinates \\(\\{x,y,z\\}\\) of the vehicle, while IMU supplies linear accelerations \\(\\{a_x,a_y,a_z\\}\\), angular velocities \\(\\{\\omega_x,\\omega_y,\\omega_z\\}\\), and 3-DOF orientation of the vehicle as Euler angles \\(\\{\\phi_x,\\theta_y,\\psi_z\\}\\) or quaternion \\(\\{q_0,q_1,q_2,q_3\\}\\).</p>  IPS Type Simulated Sensor Class Proprioceptive Supported Outputs Position Vector [x, y, z] m  IMU Type Simulated Sensor Class Proprioceptive Supported Outputs Orientation Quaternion [x, y, z, w]Orientation Euler Angles [x, y, z] radAngular Velocity Vector [x, y, z] rad/sLinear Acceleration Vector [x, y, z] m/s2 <p>LIDAR simulation employs iterative ray-casting \\(\\texttt{raycast}\\){\\(^w\\mathbf{T}_l\\), \\(\\vec{\\mathbf{R}}\\), \\(r_{max}\\)} for each angle \\(\\theta \\in \\left [ \\theta_{min}:\\theta_{res}:\\theta_{max} \\right ]\\) at a specified update rate. Here, \\({^w\\mathbf{T}_l} = {^w\\mathbf{T}_v} \\times {^v\\mathbf{T}_l} \\in SE(3)\\) represents the relative transformation of the LIDAR {\\(l\\)} w.r.t the vehicle {\\(v\\)} and the world {\\(w\\)}, \\(\\vec{\\mathbf{R}} = \\left [\\cos(\\theta) \\;\\; \\sin(\\theta) \\;\\; 0 \\right ]^T\\) defines the direction vector of each ray-cast, \\(r_{min}\\), \\(r_{max}\\), \\(\\theta_{min}\\) and \\(\\theta_{max}\\) denote the minimum and maximum linear and angular ranges, and \\(\\theta_{res}\\) represents the angular resolution of the LIDAR. The laser scan ranges are determined by checking ray-cast hits and then applying a threshold to the minimum linear range of the LIDAR, calculated as \\(\\texttt{ranges[i]}=\\begin{cases} d_\\text{hit} &amp; \\text{ if } \\texttt{ray[i].hit} \\text{ and } d_\\text{hit} \\geq r_{\\text{min}} \\\\ \\infty &amp; \\text{ otherwise} \\end{cases}\\), where \\(\\texttt{ray.hit}\\) is a Boolean flag indicating whether a ray-cast hits any colliders in the scene, and \\(d_\\text{hit}=\\sqrt{(x_{\\text{hit}}-x_{\\text{ray}})^2 + (y_{\\text{hit}}-y_{\\text{ray}})^2 + (z_{\\text{hit}}-z_{\\text{ray}})^2}\\) calculates the Euclidean distance from the ray-cast source \\(\\{x_{ray}, y_{ray}, z_{ray}\\}\\) to the hit point \\(\\{x_{hit}, y_{hit}, z_{hit}\\}\\).</p>  LIDAR Type Simulated Sensor Class Exteroceptive Scan Rate 40 Hz Angular Resolution 0.25 deg Measurements Per Scan 1080 Minimum Linear Range 0.06 m Maximum Linear Range 10.0 m Minimum Angular Range -135 deg Maximum Angular Range +135 deg Supported Outputs Range Array (m)Intensity Array <p>Simulated cameras are parameterized by their focal length \\(f\\), sensor size \\(\\{s_x, s_y\\}\\), target resolution, as well as the distances to the near \\(N\\) and far \\(F\\) clipping planes. The viewport rendering pipeline for the simulated cameras operates in three stages. First, the camera view matrix \\(\\mathbf{V} \\in SE(3)\\) is computed by obtaining the relative homogeneous transform of the camera \\(\\{c\\}\\) with respect to the world \\(\\{w\\}\\): \\(\\mathbf{V} = \\begin{bmatrix} r_{00} &amp; r_{01} &amp; r_{02} &amp; t_{0} \\\\ r_{10} &amp; r_{11} &amp; r_{12} &amp; t_{1} \\\\ r_{20} &amp; r_{21} &amp; r_{22} &amp; t_{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix}\\), where \\(r_{ij}\\) and \\(t_i\\) denote the rotational and translational components, respectively. Next, the camera projection matrix \\(\\mathbf{P} \\in \\mathbb{R}^{4 \\times 4}\\) is calculated to project world coordinates into image space coordinates: \\(\\mathbf{P} = \\begin{bmatrix} \\frac{2*N}{R-L} &amp; 0 &amp; \\frac{R+L}{R-L} &amp; 0 \\\\ 0 &amp; \\frac{2*N}{T-B} &amp; \\frac{T+B}{T-B} &amp; 0 \\\\ 0 &amp; 0 &amp; -\\frac{F+N}{F-N} &amp; -\\frac{2*F*N}{F-N} \\\\ 0 &amp; 0 &amp; -1 &amp; 0 \\\\ \\end{bmatrix}\\), where \\(L\\), \\(R\\), \\(T\\), and \\(B\\) denote the left, right, top, and bottom offsets of the sensor. The camera parameters \\(\\{f,s_x,s_y\\}\\) are related to the terms of the projection matrix as follows: \\(f = \\frac{2*N}{R-L}\\), \\(a = \\frac{s_y}{s_x}\\), and \\(\\frac{f}{a} = \\frac{2*N}{T-B}\\). The perspective projection from the simulated camera's viewport is given as \\(\\mathbf{C} = \\mathbf{P}*\\mathbf{V}*\\mathbf{W}\\), where \\(\\mathbf{C} = \\left [x_c\\;\\;y_c\\;\\;z_c\\;\\;w_c \\right ]^T\\) represents image space coordinates, and \\(\\mathbf{W} = \\left [x_w\\;\\;y_w\\;\\;z_w\\;\\;w_w \\right ]^T\\) represents world coordinates. Finally, this camera projection is transformed into normalized device coordinates (NDC) by performing perspective division (i.e., dividing throughout by \\(w_c\\)), leading to a viewport projection achieved by scaling and shifting the result and then utilizing the rasterization process of the graphics API (e.g., DirectX for Windows, Metal for macOS, and Vulkan for Linux). Additionally, a post-processing step simulates non-linear lens and film effects, such as lens distortion, depth of field, exposure, ambient occlusion, contact shadows, bloom, motion blur, film grain, chromatic aberration, etc.</p>  CAMERA Type Simulated Sensor Class Exteroceptive Field of View 48.8311 deg Sensor Size X: 3.68 mmY: 2.76 mm Shutter Speed 0.005 s Focal Length 3.04 m Aperture f/16 Target Image 16:9 (75% JPG Compression) Supported Outputs RGB Image"},{"location":"competitions/f1tenth-sim-racing-guide/#14-environment","title":"1.4. Environment","text":"<p>Simulated environments can be developed using AutoDRIVE's modular infrastructure development kit (IDK), or imported from third-party tools and open standards. Specifically, the autonomous racing scenario was created based on the binary occupancy grid map of a real-world F1TENTH racetrack, called \"Porto\", using a third-party 3D modeling software, and was imported and post-processed within AutoDRIVE Simulator to make it physically and graphically \"sim-ready\".</p> <p>These environments are simulated by conducting mesh-mesh interference detection and computing contact forces, frictional forces, momentum transfer, as well as linear and angular drag acting on all rigid bodies in the scenario.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#141-transforms","title":"1.4.1. Transforms","text":"<p>Note</p> <p>All right-handed coordinate frames depicted above are defined such that red represents x-axis, green represents y-axis, and blue represents z-axis.</p>  FRAME x y z R P Y <code>world</code> 0.0 0.0 0.0 0.0 0.0 0.0 <code>f1tenth_1</code> <p>Note</p> <p>All frame transforms mentioned above are defined w.r.t. the global frame of reference  <code>world</code>, which serves as a static frame of reference for the simulation environment. Columns x, y, and z denote translations in meters (m), while R, P, and Y denote rotations in degrees (deg).  denotes variable quantities, which in this case define the ground-truth pose of the vehicle within the simulated racetrack.</p> <p>Warning</p> <p>Since the racetrack is subject to change during different phases and iterations of the competition, the location of the fixed environmental frame of reference may be different depending on the racetrack.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#142-size-and-structure","title":"1.4.2. Size and Structure","text":"<ul> <li> <p>The simulated racetrack will be designed in accordance with the physical F1TENTH racetracks, using similar materials and spanning similar dimensions.</p> </li> <li> <p>The entire racetrack will be designed to fit within an area of around 30\\(\\times\\)10 m<sup>2</sup>, much like the physical F1TENTH racetracks.</p> </li> <li> <p>The racetrack border will be constructed from air ducts of about 33 cm in diameter, making sure that it is perceivable to exteroceptive sensors.</p> </li> <li> <p>The racetrack will be at least 3 car widths (90 cm) wide throughout to allow safe vehicle traversal, while giving an opportunity to optimize the raceline.</p> </li> </ul>"},{"location":"competitions/f1tenth-sim-racing-guide/#143-design-and-features","title":"1.4.3. Design and Features","text":"<ul> <li> <p>The road surface will be simulated with properties of polished concrete, which is flat and reflective. Therefore, exteroceptive perception may become challenging at times, much like in the real world.</p> </li> <li> <p>There may be a gap(s) between the ducts through which the LiDAR beams can pass, making it appear as an obstacle-free space. Therefore, motion planning may become challenging at times, much like in the real world.</p> </li> <li> <p>The racetrack may consist of variabilities such as straight stretch, chicane, bifurcation, obstacles, etc. to make the course challenging.</p> </li> </ul> <p>Warning</p> <p>The racetrack is subject to change across different phases (e.g., practice, qualification, race, etc.) and iterations (e.g., IROS 2024, CDC 2024, etc.) of the competition. Participants will be informed about any track changes in advance.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#2-autodrive-devkit","title":"2. AutoDRIVE Devkit","text":"<p> AutoDRIVE Devkit (part of the larger AutoDRIVE Ecosystem) is a collection of application programming interfaces (APIs), human-machine interfaces (HMIs), programming languages, libraries, frameworks, packages and tools, which enables the flexible development of on-road and off-road autonomous driving algorithms, as well as smart city traffic management algorithms. It allows targeting the devised algorithms to the simulator as well as the testbed, seamlessly. It supports both local as well as distributed computing, thereby facilitating the development of both centralized and decentralized autonomy algorithms. </p> <p> For the F1TENTH Sim Racing League, each team will be provided with a standardized working implementation of the AutoDRIVE Devkit (in the form of ROS 2 API for the F1TENTH digital twin within AutoDRIVE Simulator) to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. Since the vehicle, the sensors, the simulator, and the devkit are standardized, teams must develop robust racing algorithms that can deal with the uncertainties of an unseen racetrack. </p>"},{"location":"competitions/f1tenth-sim-racing-guide/#21-system-requirements","title":"2.1. System Requirements","text":"<p> Minimum Requirements: </p> <ul> <li>Platform: Ubuntu 20.04, Windows 10 (VS 2019), macOS 10.14</li> <li>Processor: Dual-core CPU (e.g., Intel Core i3 or AMD Ryzen 3)</li> <li>Memory: 4 GB RAM</li> <li>Graphics: Integrated graphics (e.g., Intel HD Graphics)</li> <li>Storage: 5 GB free disk space (for storing Docker images, API files, and temporary data)</li> <li>Display: 1280x720 px resolution with 60 Hz refresh rate</li> <li>Network: Stable internet connection (1 Mbps) for pulling/pushing Docker images, and downloading updates on demand</li> </ul> <p> Recommended Requirements: </p> <ul> <li>Platform: Ubuntu 20.04 (devkit has been extensively tested on this platform)</li> <li>Processor: Quad-core CPU (e.g., Intel Core i5 or AMD Ryzen 5)</li> <li>Memory: 8 GB RAM</li> <li>Graphics: Low-end discrete GPU (e.g., NVIDIA GeForce GT 1030)</li> <li>Storage: 10 GB free disk space (to accommodate multiple Docker images, additional data, and logs)</li> <li>Display: 1920x1080 px resolution with 60 Hz refresh rate</li> <li>Network: Fast internet connection (10 Mbps) for pulling/pushing Docker images, and downloading updates on the fly</li> </ul> <p>Info</p> <p>Note that the organizers will execute the competition framework on a workstation incorporating Intel Core i9 14<sup>th</sup> Gen 14900K CPU, NVIDIA GeForce RTX 4090 GPU, and 64 GB RAM (or a similar configuration). This machine will be simultaneously running the simulator container, devkit container, screen recorder and data logger. Kindly develop your algorithms while considering these computational requirements.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#22-package-structure","title":"2.2. Package Structure","text":"<p> The following tree describes the ROS 2 package structure of the AutoDRIVE Devkit used for the competition framework. </p> <pre><code>autodrive_devkit\n\u251c\u2500\u2500\u2500package.xml\n\u251c\u2500\u2500\u2500setup.cfg\n\u251c\u2500\u2500\u2500setup.py\n\u2502\n\u251c\u2500\u2500\u2500autodrive_f1tenth\n\u2502   \u2514\u2500\u2500\u2500autodrive_bridge.py\n\u2502   \u2514\u2500\u2500\u2500config.py\n\u2502   \u2514\u2500\u2500\u2500teleop_keyboard.py\n\u2502   \u2514\u2500\u2500\u2500__init__.py\n\u2502\n\u251c\u2500\u2500\u2500launch\n\u2502   \u2514\u2500\u2500\u2500simulator_bringup_headless.launch.py\n\u2502   \u2514\u2500\u2500\u2500simulator_bringup_rviz.launch.py\n\u2502\n\u251c\u2500\u2500\u2500resource\n\u2502   \u2514\u2500\u2500\u2500autodrive_f1tenth\n\u2502\n\u251c\u2500\u2500\u2500rviz\n\u2502   \u2514\u2500\u2500\u2500simulator.rviz\n\u2502\n\u2514\u2500\u2500\u2500test\n\u2502   \u2514\u2500\u2500\u2500test_copyright.py\n\u2502   \u2514\u2500\u2500\u2500test_flake8.py\n\u2502   \u2514\u2500\u2500\u2500test_pep257.py\n</code></pre> <p>Warning</p> <p>Modifying the <code>autodrive_f1tenth</code> package is not permitted. Participants will have to create their own separate package(s) to implement their autonomous racing algorithms.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#23-data-streams","title":"2.3. Data Streams","text":"<p> The following table describes various data streams of the competition framework. These data streams are exposed as ROS 2 topics using AutoDRIVE Devkit. </p> TOPIC TYPE MESSAGE ACCESS <code>/autodrive/f1tenth_1/best_lap_time</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/f1tenth_1/collision_count</code>  Debugging <code>std_msgs/msg/Int32</code>  Restricted <code>/autodrive/f1tenth_1/front_camera</code>  Sensor <code>sensor_msgs/msg/Image</code>  Input <code>/autodrive/f1tenth_1/imu</code>  Sensor <code>sensor_msgs/msg/Imu</code>  Input <code>/autodrive/f1tenth_1/ips</code>  Sensor <code>geometry_msgs/msg/Point</code>  Restricted <code>/autodrive/f1tenth_1/lap_count</code>  Debugging <code>std_msgs/msg/Int32</code>  Restricted <code>/autodrive/f1tenth_1/lap_time</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/f1tenth_1/last_lap_time</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/f1tenth_1/left_encoder</code>  Sensor <code>sensor_msgs/msg/JointState</code>  Input <code>/autodrive/f1tenth_1/lidar</code>  Sensor <code>sensor_msgs/msg/LaserScan</code>  Input <code>/autodrive/f1tenth_1/right_encoder</code>  Sensor <code>sensor_msgs/msg/JointState</code>  Input <code>/autodrive/f1tenth_1/speed</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/f1tenth_1/steering</code>  Sensor <code>std_msgs/msg/Float32</code>  Input <code>/autodrive/f1tenth_1/steering_command</code>  Actuator <code>std_msgs/msg/Float32</code>  Output <code>/autodrive/f1tenth_1/throttle</code>  Sensor <code>std_msgs/msg/Float32</code>  Input <code>/autodrive/f1tenth_1/throttle_command</code>  Actuator <code>std_msgs/msg/Float32</code>  Output <code>/autodrive/reset_command</code>  Debugging <code>std_msgs/msg/Bool</code>  Restricted <code>/tf</code>  Debugging <code>tf2_msgs/msg/TFMessage</code>  Restricted <p>Warning</p> <p>You may use the restricted topics for debugging, training AI models, etc. However, these topics should not be used while autonomously racing at run-time (e.g., during the deployment/inference stage of the algorithm).</p> <p>Info</p> <p>Warning</p> <p>You can reset the simulation by publishing a <code>std_msgs/msg/Bool</code> message with <code>True</code> value on the <code>/autodrive/reset_command</code> topic. However, do not forget to set it to <code>False</code> again, or else the simulation will keep resetting!</p> <p>Please check out the video below to see the functionality of resetting the simulator via API in action, using the <code>teleop_keyboard</code> node. This would be a good way of understanding the working and implementation of this functionality for writing your custom nodes that can exploit this feature.</p> <p> </p>"},{"location":"competitions/f1tenth-sim-racing-guide/#3-competition-submission","title":"3. Competition Submission","text":"<p> F1TENTH Sim Racing League is a virtual competition, which aims to make autonomous racing accessible to everyone across the globe. This competition adopts a containerization workflow to evaluate the submissions in a reproducible manner. Containerization provides a lightweight and portable environment, allowing applications to be easily packaged along with their dependencies, configurations, and libraries. </p> <p> Particularly, each team is expected to submit a containerized version of their autonomous racing software stack. Submissions for each phase of the competition will be done separately. </p>"},{"location":"competitions/f1tenth-sim-racing-guide/#31-container-setup","title":"3.1. Container Setup","text":"<ol> <li>Install Docker.</li> <li>Since the Docker container is to take advantage of an NVIDIA GPU, the host machine has to be properly configured by installing the necessary NVIDIA GPU Drivers and the NVIDIA Container Toolkit.</li> <li>Pull AutoDRIVE Simulator docker image from DockerHub.    <pre><code>docker pull autodriveecosystem/autodrive_f1tenth_sim:&lt;TAG&gt;\n</code></pre></li> <li>Pull AutoDRIVE Devkit docker image from DockerHub.    <pre><code>docker pull autodriveecosystem/autodrive_f1tenth_api:&lt;TAG&gt;\n</code></pre></li> </ol> <p>Note</p> <p>Pay close attention to the <code>&lt;TAG&gt;</code> (i.e., tag name) of the container image you are pulling. This could be <code>explore</code> for exploring the framework, <code>practice</code> for practicing and qualification, or <code>compete</code> for competing in the final race. The tag naming convention is set to <code>&lt;YEAR&gt;-&lt;EVENT&gt;-&lt;PHASE&gt;</code> for convenience and avoiding any repetition.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#32-container-execution","title":"3.2. Container Execution","text":"<ol> <li>Enable display forwarding for simulator:     <pre><code>xhost local:root\n</code></pre></li> <li>Run the simulator container at <code>entrypoint</code>:     <pre><code>docker run --name autodrive_f1tenth_sim --rm -it --entrypoint /bin/bash --network=host --ipc=host -v /tmp/.X11-unix:/tmp.X11-umix:rw --env DISPLAY --privileged --gpus all autodriveecosystem/autodrive_f1tenth_sim:&lt;TAG&gt;\n</code></pre></li> <li>[OPTIONAL] Start additional bash session(s) within the simulator container (each in a new terminal window):     <pre><code>docker exec -it autodrive_f1tenth_sim bash\n</code></pre></li> <li>Enable display forwarding for devkit:     <pre><code>xhost local:root\n</code></pre></li> <li>Run the devkit container at <code>entrypoint</code>:     <pre><code>docker run --name autodrive_f1tenth_api --rm -it --entrypoint /bin/bash --network=host --ipc=host -v /tmp/.X11-unix:/tmp.X11-umix:rw --env DISPLAY --privileged --gpus all autodriveecosystem/autodrive_f1tenth_api:&lt;TAG&gt;\n</code></pre></li> <li>[OPTIONAL] Start additional bash session(s) within the devkit container (each in a new terminal window):     <pre><code>docker exec -it autodrive_f1tenth_api bash\n</code></pre></li> </ol>"},{"location":"competitions/f1tenth-sim-racing-guide/#321-gui-mode-operations","title":"3.2.1. GUI Mode Operations:","text":"<ol> <li>Launch AutoDRIVE Simulator in <code>graphics</code> mode (camera rendering will be enabled):     <pre><code>./AutoDRIVE\\ Simulator.x86_64\n</code></pre></li> <li>Launch AutoDRIVE Devkit in <code>graphics</code> mode (RViz rendering will be enabled):     <pre><code>ros2 launch autodrive_f1tenth simulator_bringup_rviz.launch.py\n</code></pre></li> <li> <p>Using the simulator GUI menu panel, configure the following:</p> <p>3.1. Enter the IP address of the machine running the devkit. If both containers are running on the same machine, leave the default loopback IP.</p> <p>3.2. Hit the <code>Connection</code> button and note the status next to it (also note that the devkit echoes <code>Connected!</code> message).</p> <p>3.3. Once the connection has been established, hit the <code>Driving Mode</code> to toggle the vehicle between <code>Manual</code> and <code>Autonomous</code> driving modes.</p> </li> </ol>"},{"location":"competitions/f1tenth-sim-racing-guide/#322-headless-mode-operations","title":"3.2.2. Headless Mode Operations:","text":"<ol> <li>Launch AutoDRIVE Simulator in <code>no-graphics</code> mode (all rendering including vehicle camera will be disabled) by passing the IP address of the machine running the devkit as AutoDRIVE CLI arguments:     <pre><code>./AutoDRIVE\\ Simulator.x86_64 -batchmode -nographics -ip 127.0.0.1 -port 4567\n</code></pre></li> <li>Launch AutoDRIVE Simulator in <code>headless</code> mode (all rendering except vehicle camera rendering will be disabled) by passing the IP address of the machine running the devkit as AutoDRIVE CLI arguments:     <pre><code>xvfb-run ./AutoDRIVE\\ Simulator.x86_64 -ip 127.0.0.1 -port 4567\n</code></pre></li> <li>Launch AutoDRIVE Devkit in <code>headless</code> mode (RViz rendering will be disabled):     <pre><code>ros2 launch autodrive_f1tenth simulator_bringup_headless.launch.py\n</code></pre></li> </ol> <p>Info</p> <p>It is possible to run either the simulator, devkit, or both selectively in either <code>graphics</code> or <code>headless/no-graphics</code> mode.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#323-distributed-computing-mode","title":"3.2.3. Distributed Computing Mode:","text":"<p> It is possible to run the simulator and devkit on two separate computing nodes (e.g. two different PCs) connected via a common network. The benefit of this approach is workload distribution by isolating the two computing processes, thereby gaining higher performance. It is further possible to run the devkit on a physical F1TENTH vehicle (using the Jetson SBC onboard) and connect it to the PC running AutoDRIVE Simulator as a hardware-in-the-loop (HIL) setup. </p> <p>Tip</p> <p>In certain cases, GPUs and Docker do not work very well and can cause problems in running the simulator container. In such cases, you can download and run the simulator locally (it should be easier to access the GPU this way). You can then run only the devkit within a container. Everything else will work just fine, only that the simulator will not be running inside a container. This shouldn not matter, since you will have to submit only the container for your algorithms (i.e., devkit) and not the simulator. We will run the containerized simulator on our side for the evaluation of all submissions.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#33-container-troubleshooting","title":"3.3. Container Troubleshooting","text":"<ol> <li>To access the container while it is running, execute the following command in a new terminal window to start a new bash session inside the container: <pre><code>docker exec -it &lt;CONTAINER NAME&gt; bash\n</code></pre></li> <li>To exit the bash session(s), simply execute: <pre><code>exit\n</code></pre></li> <li>To kill the container, execute the following command: <pre><code>docker kill &lt;CONTAINER NAME&gt;\n</code></pre></li> <li>To remove the container, simply execute: <pre><code>docker rm &lt;CONTAINER NAME&gt;\n</code></pre></li> <li>Running or caching multiple docker images, containers, volumes, and networks can quickly consume a lot of disk space. Hence, it is always a good idea to frequently check Docker disk utilization: <pre><code>docker system df\n</code></pre></li> <li>To avoid utilizing a lot of disk space, it is a good idea to frequently purge docker resources such as images, containers, volumes, and networks that are unused or dangling (i.e. not tagged or associated with a container). There are several ways with many options to achieve this, please refer to appropriate documentation. The easiest way (but a potentially dangerous one) is to use a single command to clean up all the docker resources (dangling or otherwise): <pre><code>docker system prune -a\n</code></pre></li> <li>After Docker Desktop is installed, Docker CLI commands are by default forwarded to Docker Desktop instead of Docker Engine, and hence you cannot connect to the Docker daemon without running Docker Desktop. In order to avoid this, just switch to the <code>default</code> Docker context: <pre><code>docker context ls\ndocker context use default\n</code></pre></li> </ol> <p>Warning</p> <p>It is not recommended to use Docker Desktop on the Linux operating system. This is because Docker Desktop creates a virtual machine based on Linux, which is first of all not needed for native (host) Linux OS, and secondly, it sometimes does not expose the necessary access ports for the containers (e.g., trouble with GPU access).</p> <p>Info</p> <p>For additional help on containerization, visit docker.com. Specifically, the documentation and get started pages would be of significant help for the beginners. Also, this cheatsheet could be a very handy reference for all important Docker CLI commands.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#34-algorithm-development","title":"3.4. Algorithm Development","text":"<p>Teams will have to create their ROS 2 package(s) or meta-package(s) for autonomous racing within the devkit container separate from the provided <code>autodrive_f1tenth</code> package (i.e., without making any modifications to the <code>autodrive_f1tenth</code> package itself).</p> <p>Please make a note of the data streams mentioned above (along with their access restrictions) to help with the algorithm development process.</p> <p>Tip</p> <p>If working with containers is overwhelming, you can download and run the devkit locally while developing and testing your autonomous racing algorithms. You can then containerize the refined algorithms, test them one last time, and push them to the container registry.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#35-container-submission","title":"3.5. Container Submission","text":"<p>Note</p> <p>We expect that upon running your submitted container, all the necessary nodes should start up (the <code>autodrive_devkit</code> API we have included as well as your team's racing stack). Once we hit the <code>Connection Button</code> on the <code>Menu Panel</code> of AutoDRIVE Simulator, the simulated vehicle should start running. Please refer to the competition rules, where it talks about the submission guidelines. Please make sure that you include all the necessary commands (for sourcing workspaces, setting environment variables, launching nodes, etc.) within the <code>entrypoint</code> script (<code>autodrive_devkit.sh</code> file) provided within the <code>autodrive_f1tenth_api</code> container. Please do NOT use <code>~/.bashrc</code> or other means to automate the algorithm execution! Competition organizers should be able to start additional bash session(s) within your submitted container (without your codebase executing every time a new bash session is initialized) for data recording and inspection purposes.</p> <ol> <li>Run the image you created in the previous step inside a container: <pre><code>xhost local:root\ndocker run --name autodrive_f1tenth_api --rm -it --entrypoint /bin/bash --network=host --ipc=host -v /tmp/.X11-unix:/tmp.X11-umix:rw --env DISPLAY --privileged --gpus all autodriveecosystem/autodrive_f1tenth_api:&lt;TAG&gt;\n</code></pre></li> <li>In a new terminal window, list all containers and make a note of the desired <code>CONTAINER ID</code>: <pre><code>docker ps -a\n</code></pre></li> <li>Commit changes to DockerHub: <pre><code>docker commit -m \"&lt;Sample commit message&gt;\" -a \"&lt;USERNAME&gt;\" &lt;CONTAINER ID&gt; &lt;username&gt;/&lt;image_name&gt;:&lt;TAG&gt;\n</code></pre></li> <li>Login to DockerHub: <pre><code>docker login\n</code></pre></li> <li>Push the container to DockerHub, once done, you should be able to see your repository on DockerHub: <pre><code>docker push &lt;username&gt;/&lt;image_name&gt;:&lt;TAG&gt;\n</code></pre></li> <li>Submit the link to your team's DockerHub repository via a secure Google Form.</li> </ol>"},{"location":"competitions/f1tenth-sim-racing-guide/#4-citation","title":"4. Citation","text":"<p>We encourage you to read and cite the following papers if you use any part of the competition framework for your research:</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#autodrive-a-comprehensive-flexible-and-integrated-digital-twin-ecosystem-for-enhancing-autonomous-driving-research-and-education","title":"AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Enhancing Autonomous Driving Research and Education","text":"<p><pre><code>@article{AutoDRIVE-Ecosystem-2023,\nauthor = {Samak, Tanmay and Samak, Chinmay and Kandhasamy, Sivanathan and Krovi, Venkat and Xie, Ming},\ntitle = {AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Autonomous Driving Research &amp; Education},\njournal = {Robotics},\nvolume = {12},\nyear = {2023},\nnumber = {3},\narticle-number = {77},\nurl = {https://www.mdpi.com/2218-6581/12/3/77},\nissn = {2218-6581},\ndoi = {10.3390/robotics12030077}\n}\n</code></pre> This work has been published in MDPI Robotics. The open-access publication can be found on MDPI.</p>"},{"location":"competitions/f1tenth-sim-racing-guide/#autodrive-simulator-a-simulator-for-scaled-autonomous-vehicle-research-and-education","title":"AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education","text":"<p><pre><code>@inproceedings{AutoDRIVE-Simulator-2021,\nauthor = {Samak, Tanmay Vilas and Samak, Chinmay Vilas and Xie, Ming},\ntitle = {AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education},\nyear = {2021},\nisbn = {9781450390453},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3483845.3483846},\ndoi = {10.1145/3483845.3483846},\nbooktitle = {2021 2nd International Conference on Control, Robotics and Intelligent System},\npages = {1\u20135},\nnumpages = {5},\nlocation = {Qingdao, China},\nseries = {CCRIS'21}\n}\n</code></pre> This work has been published at 2021 International Conference on Control, Robotics and Intelligent System (CCRIS). The publication can be found on ACM Digital Library.</p>"},{"location":"competitions/f1tenth-sim-racing-iros-2024/","title":"F1TENTH Sim Racing League @ IROS 2024","text":""},{"location":"competitions/f1tenth-sim-racing-iros-2024/#about","title":"About","text":"<p> F1TENTH Autonomous Racing is a semi-regular competition organized by an international community of researchers, engineers, and autonomous systems enthusiasts. The teams participating in the 21st F1TENTH Autonomous Grand Prix at IROS 2024 will write software for a 1:10 scaled autonomous race car to fulfill the objectives for the competition: drive fast but don\u2019t crash! </p> <p> This time, we are organizing the first ever F1TENTH Sim Racing League, which leverages AutoDRIVE Ecosystem to model and simulate the digital twin of an F1TENTH racecar within a virtual racetrack. Please see the accompanying video for a glimpse of the F1TENTH digital twins in action. </p> <p> The main focus of the Sim Racing League is a virtual competition with simulated cars and environments, which is accessible to everyone across the globe. For the IROS 2024 competition, each team will be provided with a standardized simulation setup (in the form of a digital twin of the F1TENTH vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. Additionally, teams will also be provided with a working implementation of the AutoDRIVE Devkit to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. </p> <p> The competition will take place in 2 stages: </p> <ul> <li>Qualification Race: Teams will demonstrate their ability to complete multiple laps around the practice track without colliding with the track bounds at run time.</li> <li>Time-Attack Race: Teams will compete against the clock, on a previously unseen racetrack, to secure a position on the leaderboard.</li> </ul> <p> Since the vehicle, the sensors, the simulator, and the devkit are standardized, teams must develop robust racing algorithms that can deal with the uncertainties of an unseen racetrack. </p> <p>Tip</p> <p>If you are interested in autonomously racing physical F1TENTH vehicles, please check out the website for 21<sup>st</sup> F1TENTH Autonomous Grand Prix, which will be held in person at IROS 2024. You can always register and compete in both physical and virtual competitions!</p>"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#organizers","title":"Organizers","text":"Dr. Rahul Mangharam Dr. Venkat Krovi Dr. Johannes Betz Chinmay Samak Tanmay Samak Ahmad Amine Hongrui Zheng Dr. Fabio Bonsignorio Dr. Enrica Zereik Dr. Bilal Hassan Bushra Alshehhi Dr. Fady Alnajjar Dr. Majid Khonji Dr. Hamad Karki Dr. Pedro Lima"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#timeline","title":"Timeline","text":"<p>Warning</p> <p>Timeline is subject to change. Please keep checking this page for any updates.</p> DATE EVENT Jul 22, 2024 Registration Opens Aug 31, 2024 Registration Closes Sep 02, 2024 (5:30 \u2013 6:30 PM EDT) Online Orientation 1 Sep 22, 2024 (5:30 \u2013 6:30 PM EDT) Online Orientation 2 Sep 28 \u2013 Sep 29, 2024 Qualification Round Sep 30, 2024 Qualification Results Declared Oct 03, 2024 Competition Track Released Oct 05 \u2013 Oct 06, 2024 Final Race Oct 07, 2024 Competition Results Declared <p> Following is a brief summary of each event: </p> <ul> <li>Registration: Interested teams will register for the Sim Racing League.</li> <li>Online Orientation 1: Organizers will explain the competition rules and guidelines, and demonstrate how to use the simulation framework.</li> <li>Online Orientation 2: Organizers will check progress of the participating teams and help with any technical difficulties.</li> <li>Qualification Round: Teams will demonstrate successful completion of 10 laps around the practice track provided ahead of time.</li> <li>Qualification Results Declared: Standings of all the qualified teams will be released.</li> <li>Competition Track Released: Organizers will release the actual \"competition track\", which will be used for the final race. This track may be replicated in the physical race as well.</li> <li>Final Race: Organizers will collect containerized algorithms from each team and connect them with the containerized simulator. Performance metrics of each team will be recorded.</li> <li>Competition Results Declared: Standings of all the teams for the final race will be released.</li> </ul> <p>Info</p> <p>The F1TENTH Sim Racing League will be held approximately 1 week ahead of IROS 2024 and the performance metrics will be made available to the teams. Discussions are underway with the IROS organizing team to allow teams to analyze and present their approach/results in a short (~10 min) presentation in a special session at IROS 2024.</p>"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#resources","title":"Resources","text":"<p> AutoDRIVE is envisioned to be an open, comprehensive, flexible and integrated cyber-physical ecosystem for enhancing autonomous driving research and education. It bridges the gap between software simulation and hardware deployment by providing the AutoDRIVE Simulator and AutoDRIVE Testbed, a well-suited duo for real2sim and sim2real transfer targeting vehicles and environments of varying scales and operational design domains. It also offers AutoDRIVE Devkit, a developer's kit for rapid and flexible development of autonomy algorithms using a variety of programming languages and software frameworks. For the Sim Racing League, teams will develop their autonomous racing algorithms using the AutoDRIVE Devkit to interface with the AutoDRIVE Simulator in real-time. </p> <p></p> <p> F1TENTH is an international community of researchers, engineers, and autonomous systems enthusiasts. It is centered around the idea of converting a 1:10 scale RC car into an autonomous vehicle for research and education; check out the documentation to build your own F1TENTH autonomous racecar. Additionally, if you are new to the field of autonomous racing, you can refer to the complete course material, which is open sourced. If you already have some experience with autonomous racing, feel free to delve deeper into the research enabled by F1TENTH. Lastly, you can also check out the physical F1TENTH races that are being organized all around the world. For the Sim Racing League, teams will not require a physical F1TENTH vehicle; however, the learning resources can certainly be useful to get your autonomous racing fundamentals right! </p> <p> We recommend all the teams interested in participating in the F1TENTH Sim Racing League to get accustomed with the competition. Following are a few resources to get you started: </p> <ul> <li> <p> Competition Documents</p> <p>Learn about the competition rules and technical aspects of the framework.</p> <p> Competition Rules</p> <p> Technical Guide</p> </li> <li> <p> Docker Containers</p> <p>Download base container images for the competition and start developing your algorithms.</p> <p> AutoDRIVE Simulator: <code>explore</code> | <code>practice</code> | <code>compete</code></p> <p> AutoDRIVE Devkit: <code>explore</code> | <code>practice</code> | <code>compete</code></p> </li> <li> <p> Local Resources</p> <p>Get started with the competition framework locally, and worry about containerization later. </p> <p>AutoDRIVE Simulator:</p> <p><code>explore</code>  Linux |  Windows |  macOS</p> <p><code>practice</code>  Linux |  Windows |  macOS</p> <p><code>compete</code>  Linux |  Windows |  macOS</p> <p>AutoDRIVE Devkit:</p> <p> ROS 2</p> </li> <li> <p> Orientation Resources</p> <p>Join the online orientation sessions or review what we covered there.</p> <p>Orientation 1:</p> <p>Meeting Link:  Zoom</p> <p>Review Links:  Recording |  Slides</p> <p>Orientation 2:</p> <p>Meeting Link:  Zoom</p> <p>Review Links:  Recording |  Slides</p> </li> </ul> <p>Question</p> <p>You can post general questions on the  AutoDRIVE Slack workspace; this is the preferred modality. Technical questions can be also posted as  GitHub Issues or  GitHub Discussions. For any other questions or concerns that cannot be posted publicly, please contact  Chinmay Samak or  Tanmay Samak.</p>"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#registration","title":"Registration","text":"<p> This competition is open to everyone around the world - students, researchers, hobbyists, professionals, or anyone else who is interested. A team can consist of multiple teammates. Teams with only one person are also allowed. </p>  Registration Form <p> Registration for the Sim Racing League is free of cost and separate from the Physical Racing League and the conference registrations themselves. The above form signs you up only for the Sim Racing League, and for its orientation and information sessions. Although you can participate in the Sim Racing League without attending the conference, we strongly encourage all competition participants to attend the conference in person. This will help you connect with the broader AutoDRIVE and F1TENTH communities, and you can also witness/participate in the physical F1TENTH autonomous racing competition! </p> <p> Registered teams are added to the following table: </p> SR. NO. TEAM NAME TEAM MEMBERS ORGANIZATION 01 SAGOL JoonCheol Park Personal 02 Solo Abdul Rahman Khader Khalifa University 03 OptimusPrime Sahruday Patti University of Maryland, College Park 04 Velizar Zlatev Velizar Zlatev University of Bristol 05 Beryllium Ronnie Romman Personal 06 Cornell Electric Vehicles Jason KleinEric MarchettiZach ChosedUtku MelemetciSidharth RaoMyles PasetskyZephan SanghaniSia ChitnisNicole Sin Cornell University 07 Robotisim Dev Muhammad LuqmanYusuf Butt Robotisim 08 Log Robotics Logesh G Bannari Amman Institute of Technology 09 Lone Rider Akshay Laddha Indian Institute of Technology, Bombay 10 Atlas 2.0 Manav Gagvani Purdue University 11 The Buttowskis Kalash Jain Pandit Deendayal Energy University 12 Hanuman Parakram Dheeraj BhurewarVaibhav WanereAkash SundarSuryaprakash Senthil Kumar Personal 13 Pallas Haris Khan Skoltech 14 Gopher Speedsters Sujeendra Ramesh University of Minnesota, Twin Cities 15 Autopilots Nouf AljaberiAmna MuhammadHajar AlnaqbiShouq ZankiSara Almessabie United Arab Emirates University 16 i3 Pranav Kallem Personal 17 RobotX &amp; More Oussama ErroujiImad-Eddine NACIRI Euro Mediterranean University of Fez 18 IEEE Zagazig SB Abdulrahman OmarHossam ElsherbinyEssam ShenhabEman AbdelhamedAbdullah ElmasrySalma SwailemMerna AtefAmr YasserMahmoud SamyMostafa AsaadMenna GamalAhmed Medhat Zagazig University 19 AMUGAE Kim Amugae Personal 20 TURTLEBOT Jit Ern Lim Personal 21 Byte Benders Bhajneet Singh Bedi Personal 22 KGX Hareesh RRaja Rajan KRamesh Patel DMarudhu Paandian KBhuvaneshwari Kanagaraj KGISL Institute of technology 23 NaN Hariharan RavichandranSiva Vignesh Krishnan Chidambaram Personal 24 Vortex Chinmay K National Institute of Technology, Karnataka 25 bracaai Luis Bracamontes Braca Vision 26 ASU Racing Team Abdallah IsmailMahmoud OmarHussien AlgendySerag AbdelmohsenAmmar AhmedAhmed SallamMalk Hany Ain Shams University 27 TurboX Dheeraj Bhogisetty Personal 28 TractionX Ameya BagalAnanya DasAmizhthni PRKAayush Ranawat Indian Institute of Technology, Madras 29 Urban AI Adham FayadAbdulrahman AhmedNabil FoudaGeorge WelsonMuhab MuhammedMostafa Samy Ain Shams University 30 fstMINI Jos\u00e9 MateusDuarte Domingues Instituto Superior T\u00e9cnico 31 Buggy Coders Cody Uehara Personal 32 AutoVision Luis Bracamontes Personal 33 Autobots Shubham BargeAnshuman Jena Personal 34 Kyber-Kabs Aditya Jambhale SRM Institute of Science and Technology 35 SUST AutoDrive Abul Bashar RazAd-Deen MahbubShafi AbdullahFardeen MosharrafRedwan HassanTaj Ahmed Shahjalal University of Science and Technology 36 VersusAI Junior JesusAlisson KollingPedro PinheiroVictor Kich Universidade Federal do Rio Grande 37 vijAYAM Adarsh Baburaj Manipal University (MU), Dubai 38 OutRunner Nihad JifriArif SidhiequMidhun Manoharan Personal 39 simracer Vinura Wanniarachchi Personal 40 Phoenix Aman Kumar SinghLakshmikanth NageswarKandregula AbhinavSuchi Sharma Personal 41 KU F1TENTH Riley AndersonJackson YanekMohammed Misbah Zarrar The University of Kansas 42 Void Gonna YaswanthPrajyot Jadhav Personal 43 Aztec Autonomous Racing Team (AART) Hyunjong ChoiPascal ReichHyunhee Kwak San Diego State University 44 IDEA_LAB Myeongjun KimJi-hong ParkJuyoung KimSunwoong MoonGyuhyeok LeeSujin Park Gyeongsang National University 45 Aumechtron Siddhant DiwakerAryan Iyer SRM Institute of Science and Technology 46 UJI Enric Cervera Universitat Jaume-I 47 TurboTrack AI Swapneel Dhananjay Wagholikar Personal 48 InDIGo Nikolaos Sarantinoudis Technical University of Crete 49 Shelby S SrikaanthS A Gogulnath Sastra Deemed University 50 Noyma Roni EmadYoussef KaramAhmed KhalifaJohn MagedMina SamehAndrew BahaaMarise NachaatMark Medhat Personal 51 BREATH Wonbin LeeSechan ParkSunhwan Lee Handong Global University 52 SNAIL Minsu KimMinyoung SongSieun Park Handong Global University 53 Shoubra Racing Team Ahmed ElmasryMohamed AlaaHana AhmedHazem Abuelanin Benha University - Shoubra Faculty of Engineering 54 Kanka Goktug PoyrazogluVolkan IslerYukang CaoBurak Mert GonultasQingyuan JiangBurak SusamWilliam Chastek University of Minnesota 55 K\u0131lavuz-Mekatronom Mehmet Baha DursunMustafa KurbanH\u00fcseyin Ayvac\u0131Cihat Kurtulu\u015f Alt\u0131parmak Saha Robotik 56 AA Lab Taha Kocyigit Bogazici University 57 Cognitron Abhinav PillaiAbid AnsariMuhamed ShijasSafa NRazeen Rasheed Indian Institute of Technology, Kharagpur 58 VAUL Tommy Bouchard-LebrunWilliam FecteauNicolas Lauzon Laval University <p>Note</p> <p>The above table will be updated with newly registered teams within a few days of registration. Please contact  Chinmay Samak or  Tanmay Samak if you do not see your team entry for more than 7 days after registering.</p>"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#submission","title":"Submission","text":"<p> Use the secure form below to make your team's submission for Phase 1 (Qualification Round) of the F1TENTH Sim Racing League. Please fill in your team's name and add the link to your team's DockerHub repository containing the autonomous racing stack. If you are using a private repository, make sure to add autodriveecosystem as a collaborator to your repository. </p>  Phase 1 Submission Form <p>Warning</p> <p>Phase 1 submission window will close on Sep 28, 2024. Please contact  Chinmay Samak or  Tanmay Samak if you have any questions.</p> <p> Use the secure form below to make your team's submission for Phase 2 (Final Race) of the F1TENTH Sim Racing League. Please fill in your team's name and add the link to your team's DockerHub repository containing the autonomous racing stack. If you are using a private repository, make sure to add autodriveecosystem as a collaborator to your repository. </p>  Phase 2 Submission Form <p>Warning</p> <p>Phase 2 submission window will close on Oct 05, 2024. Please contact  Chinmay Samak or  Tanmay Samak if you have any questions.</p>"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#results","title":"Results","text":"<p>Phase 1: Qualification</p> <p> The following teams have qualified for the final time-attack race. Here are the official standings: </p> RANK TEAM NAME RACE TIME COLLISION COUNT ADJUSTED RACE TIME BEST LAP TIME VIDEO 01 \ud83d\udc4f KU F1TENTH 117.05 s 0 117.05 s 11.67 s  YouTube 02 \ud83d\udc4f IDEA_LAB 145.89 s 1 155.89 s 14.43 s  YouTube 03 \ud83d\udc4f Shoubra Racing Team 179.57 s 0 179.57 s 17.84 s  YouTube 04 \ud83d\udc4f bracaai 181.04 s 0 181.04 s 17.87 s  YouTube 05 \ud83d\udc4f TURTLEBOT 181.33 s 0 181.33 s 17.98 s  YouTube 06 \ud83d\udc4f Kanka 177.08 s 7 247.08 s 17.37 s  YouTube 07 \ud83d\udc4f Log Robotics 265.59 s 1 275.59 s 26.47 s  YouTube 08 \ud83d\udc4f Phoenix 411.03 s 0 411.03 s 41.05 s  YouTube 09 \ud83d\udc4f Urban AI 1284.26 s 0 1284.26 s 128.00 s  YouTube <p>Phase 2: Competition</p> <p> The following teams successfully finished the final time-attack race. Here are the official standings: </p> RANK TEAM NAME RACE TIME COLLISION COUNT ADJUSTED RACE TIME BEST LAP TIME VIDEO 01 \ud83e\udd47 TURTLEBOT 141.59 s 0 141.59 s 13.90 s  YouTube 02 \ud83e\udd48 IDEA_LAB 186.58 s 0 186.58 s 17.79 s  YouTube 03 \ud83e\udd49 KU F1TENTH 244.88 s 0 244.88 s 24.12 s  YouTube 04 \ud83d\udc4f Shoubra Racing Team 201.84 s 6 261.84 s 19.00 s  YouTube 05 \ud83d\udc4f Phoenix 282.16 s 0 282.16 s 27.97 s  YouTube"},{"location":"competitions/f1tenth-sim-racing-iros-2024/#summary","title":"Summary","text":""},{"location":"competitions/f1tenth-sim-racing-rules/","title":"Competition Rules","text":"<p> This document describes the rules and regulations for the F1TENTH Sim Racing League. It goes over the definitions, requirements and evaluation criteria as well as general dos and don'ts for the competition. </p> <p>Warning</p> <p>Rules are subject to change. Organizers reserve the right to amend existing rules and, if situation demands, create new rules on the go.</p>"},{"location":"competitions/f1tenth-sim-racing-rules/#1-general-guidelines","title":"1. General Guidelines","text":"<p> F1TENTH Sim Racing League is a virtual competition, which accompanies the physical F1TENTH Autonomous Racing Competition. It leverages AutoDRIVE Ecosystem to model and simulate the digital twin of an F1TENTH racecar within a virtual racetrack. The main goal of this competition is to make autonomous racing accessible to everyone across the globe. </p>"},{"location":"competitions/f1tenth-sim-racing-rules/#11-eligibility-criteria","title":"1.1. Eligibility Criteria","text":"<p> This competition is open to everyone around the world - students, researchers, hobbyists, professionals, or anyone else who is interested. There are no restrictions on age, sex, nationality, profession, etc. A team can consist of single or multiple participants. Multiple teams from the same organization are also allowed. However, each participant can be a member of strictly one team. </p> <p> Registration for the Sim Racing League is free of cost and separate from the Physical Racing League and the conference registrations themselves. Although teams can participate in the Sim Racing League without attending the conference, we strongly encourage all competition participants to attend the conference in person. This will allow the teams to participate in competition-related events at the conference and connect with the broader community! </p>"},{"location":"competitions/f1tenth-sim-racing-rules/#12-competition-structure","title":"1.2. Competition Structure","text":"<p> Each team will be provided with a standardized simulation setup (in the form of a digital twin of the F1TENTH vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. Additionally, teams will also be provided with a working implementation of the AutoDRIVE Devkit to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. </p>"},{"location":"competitions/f1tenth-sim-racing-rules/#13-competition-timeline","title":"1.3. Competition Timeline","text":"<p> The competition will take place in 2 stages: </p> <ul> <li>Qualification Race: Teams will demonstrate their ability to complete multiple laps around the practice track without colliding with the track bounds at run time.</li> <li>Time-Attack Race: Teams will compete against the clock, on a previously unseen racetrack, to secure a position on the leaderboard.</li> </ul> <p> Following is a summary of the main events of the competition: </p> <ul> <li>Registration: Interested teams will register for the Sim Racing League.</li> <li>Online Orientation 1: Organizers will explain the competition rules and guidelines, and demonstrate how to use the simulation framework.</li> <li>Online Orientation 2: Organizers will check progress of the participating teams and help with any technical difficulties.</li> <li>Qualification Round: Teams will demonstrate successful completion of 10 laps around the practice track provided ahead of time.</li> <li>Qualification Results Declared: Standings of all the qualified teams will be released.</li> <li>Competition Track Released: Organizers will release the actual \"competition track\", which will be used for the final race. This track may be replicated in the physical race as well.</li> <li>Final Race: Organizers will collect containerized algorithms from each team and connect them with the containerized simulator. Performance metrics of each team will be recorded.</li> <li>Competition Results Declared: Standings of all the teams for the final race will be released.</li> </ul>"},{"location":"competitions/f1tenth-sim-racing-rules/#2-competition-guidelines","title":"2. Competition Guidelines","text":"<p> This competition will adhere to the time-attack racing format, wherein each team will compete against the clock independently, on the same racetrack. Each race will comprise a total of 12 laps: the vehicles will start with a warm-up lap, followed by 10 race laps, and finally a cool-down lap. </p>"},{"location":"competitions/f1tenth-sim-racing-rules/#21-competition-requirements","title":"2.1. Competition Requirements","text":"<p> Following are the requirements to progress along each phase of the competition: </p> <ul> <li>Registration: Interested teams must register for the competition before the deadline. Organizers may extend registration deadlines in certain cases; however, direct requests for deadline extension from any team(s) will not be entertained. It is recommended to register your team well in advance to avoid last-minute rush.</li> <li>Orientations: It is highly recommended for all teams to attend the online orientation sessions to understand the competition code-of-conduct and get familiar with the simulation framework. These events can also be used to get some of your doubts clarified!</li> <li>Qualification: Teams will have to demonstrate successful completion of 10 autonomous laps around the practice track provided ahead of time. During this phase, speed is not very important, but failure to complete 10 consecutive autonomous laps without exceeding the collision count tolerance will result in disqualification of that team. Passing the qualification session entitles a team for the final race.</li> <li>Competition: During this phase, the clock will be ticking, and the objective would be to complete 10 consecutive autonomous laps as fast as possible without exceeding the collision count tolerance. Failure to respect the collision count tolerance will result in disqualification of that team. Teams will be ranked on a leaderboard in the ascending order of their time to completion (10 autonomous racing laps).</li> </ul>"},{"location":"competitions/f1tenth-sim-racing-rules/#22-competition-terminology","title":"2.2. Competition Terminology","text":"<p> Following are the definitions of some competition terminologies: </p> <ul> <li>Collision: Any contact between the colliders of the simulated vehicle and the racetrack bounds (except the wheels touching the ground) is considered a collision. A collision will incur a penalty of 10 seconds (i.e., 10 seconds after first collision, 20 seconds after the second, 30 seconds after the third, and so on). Colliding more than 10 times in a single racing event will lead to disqualification. Each collision will automatically reset the vehicle to the last checkpoint (your localization algorithm will have to be robust against this re-setting action). Lap timer will not reset upon collision.</li> <li>Warm-Up Lap: This is the first lap of a race. The time or collisions during the warm-up lap will not be considered. This lap acts as a buffer since your algorithms may take time to launch and connect with the simulator, while the lap timer is on.</li> <li>Race Laps: These are a set of 10 laps immediately following the warm-up lap. The race laps start as soon as the vehicle crosses the finish line in the warm-up lap. The time and collisions of the race laps will be considered.</li> <li>Cool-Down Lap: This is the last lap of a race. The time or collisions during the cool-down lap will not be considered. Completing this lap is not required for the competition, but this can be a good time to \"show-off\" your skills without worrying about collisions!</li> <li>Checkpoints: The racetrack has several \"virtual\" checkpoints, spaced approximately equally along the track. These checkpoints cover the entire width of the racetrack and are triggered as the vehicle passes through them. The start/finish line is the final \"special\" checkpoint. The exact location of the checkpoints will not be revealed to the participants.</li> <li>Lap Time: This is the amount of time that the vehicle takes to complete one full lap around the racetrack. The timer starts as soon as the previous lap ends and stops after the current lap ends. Failing to pass all the checkpoints before crossing the finish line (e.g., driving in opposite direction) will not stop the lap timer.</li> <li>Race Time: This is the cumulative time that the vehicle takes to complete 10 race laps around the racetrack. The timer starts as soon as the warm-up lap ends and stops after the 10th race lap ends. Collision penalties are added separately.</li> <li>Best Lap Time: This is the amount of time that the vehicle took to complete the fastest race lap around the racetrack. This is the minimum lap time across all the 10 race laps.</li> <li>Average Lap Time: This is the average time that the vehicle took to complete a race laps (out of 10 race laps) around the racetrack. This is the statistical mean of all the 10 race lap times.</li> </ul>"},{"location":"competitions/f1tenth-sim-racing-rules/#23-competition-execution","title":"2.3. Competition Execution","text":"<p> Following is a summary of a typical racing event: </p> <ul> <li>Inspection: Race stewards will examine the team's submission according to race standards.</li> <li>Simulator: Containerized AutoDRIVE Simulator will be launched. Communication bridge parameters will be set (communication channel will not be opened yet). Vehicle will be engaged in autonomous mode. Graphics quality will be set to \"Ultra\". </li> <li>Devkit: Containerized AutoDRIVE Devkit with the team's autonomous racing algorithm submission will be launched. A new Bash session will be opened within the container to start recording a ROS 2 bag of all the available topics.</li> <li>Recording: A screen recorder application as well as the ROS 2 bag recording will run in the background.</li> <li>Communication: The bi-directional communication channel between simulator container and devkit container will be established. This should make all the data available on the relevant ROS 2 topics and automatically start the race.</li> <li>Race: Each race will comprise a total of 12 laps: the vehicles will start with a warm-up lap, followed by 10 race laps, and finally a cool-down lap. The lap times or collisions during the warm-up and cool-down laps will not be considered, only those during the 10 race laps will be considered.</li> <li>Data: Performance metrics of the team will be recorded and stored along with the screen recording of the simulator as well as the comprehensive ROS 2 bag.</li> </ul>"},{"location":"competitions/f1tenth-sim-racing-rules/#24-inspection-rules","title":"2.4. Inspection Rules","text":"<p>Warning</p> <p>Organizers reserve the right to reject any submission that they deem illegal due to unethical exploitation of the competition framework. All submissions will be examined by the race stewards prior to the race.</p> <p>Warning</p> <p>Teams breaching the code of conduct will face direct disqualification with a publicly visible \"malpractice\" citation on the competition website.</p> <p> This competition is intended to be a battle of algorithms, and hence any modifications to the competition framework including (but not limited to) the simulator executable, vehicle (chassis, powertrain, sensors, etc.), environment (track, layout, ground, weather, time, etc.), communication interface (use of protocols other than WebSocket), devkit (use of APIs other than ROS 2) or the containerization approach (use of tools besides Docker, Dockerfile configuration, etc.) are strictly prohibited. Any modification to the competition framework shall result in direct disqualification of the responsible team without admission to the qualification/competition session. </p> <p> Any kind of autonomous racing algorithm that makes use of raw perception data to generate control commands for the simulated vehicle is permissible - including (but not limited to) reactive planning, map-based localization, raceline optimization, deep learning, reinforcement learning as well as hybrid algorithms. </p> <p> However, utilizing simulation ground truth data or controlling aspects other than the vehicle actuators is not allowed. Furthermore, exploiting the competition framework unethically (e.g., tapping into the back-end, frame-grabbing the front-end, finding loop-holes in the framework, tampering with data streaming/logging, etc.) is considered a serious malpractice. </p> <p>Info</p> <p>Please refer to the Technical Guide for more information about permissible and restricted data streams.</p> <p> Since this is a global event held at some of the world's premier conferences, we ask all teams to observe ethical integrity and abide by the code of conduct of this competition. Any malpractice or plagiarism in terms of submission code or other material shall be considered a serious breach of the code of conduct. Depending upon the situation, organizers reserve the right to issue a warning, public citation, and/or disqualification of the responsible team(s) from the competition. </p>"},{"location":"competitions/f1tenth-sim-racing-rules/#25-evaluation-criteria","title":"2.5. Evaluation Criteria","text":"<p> Following are the evaluation criteria for the competition: </p> <ul> <li>The ultimate evaluation criterion for the race is total race time. However, best lap time and/or other metrics may be used in case of a tie.</li> <li>A collision will incur a penalty of 10 seconds (i.e., 10 seconds after first collision, 20 seconds after the second, 30 seconds after the third, and so on).</li> <li>The maximum number of collisions permissible for a race (qualification/competition) is 10, beyond which the team will be disqualified.</li> <li>Lap times or collisions during the warm-up and cool-down laps will not be considered, only those during the 10 race laps will be considered.</li> </ul> <p>Note</p> <p>Race referee's decision is final! In extreme cases, rebuttals with supporting evidence may be entertained at the organizers' discretion.</p>"},{"location":"competitions/f1tenth-sim-racing-rules/#3-submission-guidelines","title":"3. Submission Guidelines","text":"<p> Each team is expected to submit a containerized version of their autonomous racing software stack. Submissions for each phase of the competition will be done separately. </p> <p>Note</p> <p>We expect that upon running your submitted container, all the necessary nodes should start up (the <code>autodrive_devkit</code> API we have included as well as your team's racing stack). Once we hit the <code>Connection Button</code> on the <code>Menu Panel</code> of AutoDRIVE Simulator, the simulated vehicle should start running. Please make sure that you include all the necessary commands (for sourcing workspaces, setting environment variables, launching nodes, etc.) within the <code>entrypoint</code> script (<code>autodrive_devkit.sh</code> file) provided within the <code>autodrive_f1tenth_api</code> container. Please do NOT use <code>~/.bashrc</code> or other means to automate the algorithm execution! Competition organizers should be able to start additional bash session(s) within your submitted container (without your codebase executing every time a new bash session is initialized) for data recording and inspection purposes.</p>"},{"location":"competitions/f1tenth-sim-racing-rules/#31-submission-requirements","title":"3.1. Submission Requirements","text":"<p> Following are the requirements for submitting an entry to the competition: </p> <ul> <li>Each team is expected to submit a Docker container image of their autonomous racing software stack.</li> <li>The submitted container should be self-sustainable in terms of all the dependencies and should be configured to run all the necessary commands automatically when launched.</li> <li>The submitted container must be based off of the official AutoDRIVE Devkit container released for the competition.</li> <li>Teams are permitted to add/modify ROS 2 package(s) within the provided AutoDRIVE Devkit container for implementing their autonomous racing algorithm(s). However, any modifications to the existing container elements are strictly off the limits.</li> <li>Teams do not need to submit the simulator container.</li> </ul> <p>Tip</p> <p>Teams can test their algorithms locally before containerizing them. However, don't forget to test your containers before pushing them upstream and submitting them!</p>"},{"location":"competitions/f1tenth-sim-racing-rules/#32-submission-process","title":"3.2. Submission Process","text":"<p> Following are the key milestones for submitting an entry to the competition: </p> <ul> <li>Teams will containerize their autonomous racing software stack using Docker.</li> <li>Teams will push their self-sustainable Docker container image to DockerHub.</li> <li>Teams will share the link of the upstream repository with the organizers via a secure submission form (separate forms for each stage of the competition).</li> </ul>"},{"location":"competitions/f1tenth-sim-racing-rules/#33-submission-privacy","title":"3.3. Submission Privacy","text":"<p> This is a competition, and all teams have the right to keep their source code hidden from their competitors. Here are a few strategies to keep in mind: </p> <ul> <li>Source Code: Teams can host their source code in a private GitHub repository for collaboration and version control. GitHub now allows hosting unlimited private repositories for personal accounts and organizations.</li> <li>Containers: Teams can push their Docker container images to a private DockerHub repository. As of now, DockerHub allows hosting one free private repository for each user account.</li> <li>Data: Teams can store their data in an encrypted and secure cloud storage platform with link-sharing disabled. Alternatively, storing data locally (with a hard-drive backup) is also an option.</li> </ul> <p> However, after the competition, we encourage teams to publish their source code on GitHub under an open-source license. We also encourage teams to make their Docker containers public on DockerHub. Teams can also choose to make other race data (e.g., videos, logs, reports, etc.) publicly available. This will increase the visibility of their work and increase the quality of the future competitions. </p>"},{"location":"competitions/f1tenth-sim-racing-rules/#4-citation","title":"4. Citation","text":"<p>We encourage you to read and cite the following papers if you use any part of the competition framework for your research:</p>"},{"location":"competitions/f1tenth-sim-racing-rules/#autodrive-a-comprehensive-flexible-and-integrated-digital-twin-ecosystem-for-enhancing-autonomous-driving-research-and-education","title":"AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Enhancing Autonomous Driving Research and Education","text":"<p><pre><code>@article{AutoDRIVE-Ecosystem-2023,\nauthor = {Samak, Tanmay and Samak, Chinmay and Kandhasamy, Sivanathan and Krovi, Venkat and Xie, Ming},\ntitle = {AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Autonomous Driving Research &amp; Education},\njournal = {Robotics},\nvolume = {12},\nyear = {2023},\nnumber = {3},\narticle-number = {77},\nurl = {https://www.mdpi.com/2218-6581/12/3/77},\nissn = {2218-6581},\ndoi = {10.3390/robotics12030077}\n}\n</code></pre> This work has been published in MDPI Robotics. The open-access publication can be found on MDPI.</p>"},{"location":"competitions/f1tenth-sim-racing-rules/#autodrive-simulator-a-simulator-for-scaled-autonomous-vehicle-research-and-education","title":"AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education","text":"<p><pre><code>@inproceedings{AutoDRIVE-Simulator-2021,\nauthor = {Samak, Tanmay Vilas and Samak, Chinmay Vilas and Xie, Ming},\ntitle = {AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education},\nyear = {2021},\nisbn = {9781450390453},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3483845.3483846},\ndoi = {10.1145/3483845.3483846},\nbooktitle = {2021 2nd International Conference on Control, Robotics and Intelligent System},\npages = {1\u20135},\nnumpages = {5},\nlocation = {Qingdao, China},\nseries = {CCRIS'21}\n}\n</code></pre> This work has been published at 2021 International Conference on Control, Robotics and Intelligent System (CCRIS). The publication can be found on ACM Digital Library.</p>"},{"location":"competitions/roboracer-sim-racing-guide/","title":"Technical Guide","text":"<p> This document describes the technical details of the competition framework for the RoboRacer Sim Racing League. It goes over the details pertaining to the simulator and devkit, as well as some important aspects of the submission system, process, and evaluation. </p> <p>Warning</p> <p>It expected that teams have sufficient background knowledge pertaining to autonomous racing (concepts, methods, and algorithms), programming languages (Python, C++, etc.) and frameworks (ROS 2), containerization (Docker) and version control (Git), etc. In order to be fair to all teams and keep the competition on schedule, extensive technical support/help cannot be provided by the organizers. However, legitimate requests may be entertained at the discretion of the organizers.</p> <p>Note</p> <p>Although AutoDRIVE Ecosystem supports various vehicles across different scales, configurations, and operational design domains (ODDs), the only vehicle allowed for this competition is the RoboRacer. Similarly, although AutoDRIVE Ecosystem supports multiple application programming interfaces (APIs), the only API allowed for this competition is ROS 2.</p> <p>Please see the accompanying video for a step-by-step tutorial of setting up and using the competition framework.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#1-autodrive-simulator","title":"1. AutoDRIVE Simulator","text":"<p> AutoDRIVE Simulator (part of the larger AutoDRIVE Ecosystem) is an autonomy oriented tool designed to model and simulate vehicle and environment digital twins. It equally prioritizes backend physics and frontend graphics to achieve high-fidelity simulation in real-time. From a computing perspective, the simulation framework is completely modular owing to its object-oriented programming (OOP) constructs. Additionally, the simulator can take advantage of CPU multi-threading as well as GPU instancing (if available) to efficiently parallelize various simulation objects and processes, with cross-platform support. </p> <p> For the RoboRacer Sim Racing League, each team will be provided with a standardized simulation setup (in the form of a digital twin of the RoboRacer vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. This would democratize autonomous racing and make this competition accessible to everyone across the globe. </p>"},{"location":"competitions/roboracer-sim-racing-guide/#11-system-requirements","title":"1.1. System Requirements","text":"<p> Minimum Requirements: </p> <ul> <li>Platform: Ubuntu 20.04+, Windows 10+, macOS 10.14+ (simulator has cross-platform compatibility)</li> <li>Processor: Quad-core CPU (e.g., Intel Core i5 or AMD Ryzen 5)</li> <li>Memory: 8 GB RAM</li> <li>Graphics: Integrated graphics (e.g., Intel HD Graphics) or a low-end discrete GPU (e.g., NVIDIA GeForce GTX 1050) with at least 2 GB of VRAM</li> <li>Storage: 10 GB of free disk space (for storing Docker images, simulator application and data)</li> <li>Display: 1280x720 px resolution with 60 Hz refresh rate</li> <li>Network: Stable internet connection (1 Mbps) for pulling/pushing Docker images, and downloading updates on demand</li> </ul> <p> Recommended Requirements: </p> <ul> <li>Platform: Ubuntu 20.04/22.04, Windows 10/11 (simulator has been extensively tested on these platforms)</li> <li>Processor: Octa-core CPU (e.g., Intel Core i7 or AMD Ryzen 7)</li> <li>Memory: 16 GB RAM</li> <li>Graphics: Mid-range discrete GPU (e.g., NVIDIA GeForce GTX 1660 or RTX 2060) with 4+ GB of VRAM</li> <li>Storage: 20 GB of free disk space (to accommodate multiple Docker images, additional data, and logs)</li> <li>Display: 1920x1080 px resolution with 144 Hz refresh rate</li> <li>Network: Fast internet connection (10 Mbps) for pulling/pushing Docker images, and downloading updates on the fly</li> </ul> <p>Info</p> <p>Note that the organizers will execute the competition framework on a workstation incorporating Intel Core i9 14<sup>th</sup> Gen 14900K CPU, NVIDIA GeForce RTX 4090 GPU, and 64 GB RAM (or a similar configuration). This machine will be simultaneously running the simulator container, devkit container, screen recorder and data logger. Kindly develop your algorithms while considering these computational requirements.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#12-user-interface","title":"1.2. User Interface","text":"<p> AutoDRIVE Simulator's graphical user interface (GUI) consists of a toolbar encompassing two panels for observing and interacting with key aspects of the simulator in real-time, namely Menu and Heads-Up Display (HUD). Both the panels can be enabled or disabled using the burger icons provided on the toolbar; the figure above illustrates both the GUI panels being enabled. The menu panel on the left-hand side helps configure and control some important aspects of the simulation with just a few clicks. The HUD panel on the right-hand side helps visualize prominent simulation parameters along with vehicle status and sensory data, while hosting a time-synchronized data recording functionality that can be used to export simulation data for a specific run. </p>"},{"location":"competitions/roboracer-sim-racing-guide/#121-menu-panel","title":"1.2.1. Menu Panel","text":"<ul> <li>IP Address Field: Input field to specify IP address for the machine running the devkit (default is 127.0.0.1, i.e., standard address for IPv4 loopback traffic).   <li>Port Number Field: Input field to specify port number for the machine running the devkit (default is 4567, observed to be usually unoccupied).   <li>Connection Button: Button to establish connection with the devkit, which acts as the server with the simulator being the client (the button is disabled once the connection is established). The status of bridge connection (i.e., Connected or Disconnected) is displayed besides this button.   <li>Driving Mode Button: Button to toggle the driving mode of the vehicle between Manual and Autonomous (default is Manual). The selected driving mode is displayed besides this button.   <li>Camera View Button: Button to toggle the scene camera view between Driver\u2019s Eye, Bird\u2019s Eye and God\u2019s Eye (default is Driver\u2019s Eye). The selected view is displayed besides this button.   <li>Graphics Quality Button: Button to toggle the graphics quality view between Low, High, and Ultra (default is Low). The selected quality is displayed besides this button.   <li>Scene Light Button: Button to enable/disable the environmental lighting (default is enabled).   <li>Reset Button: Button to reset the simulator to initial conditions.   <li>Quit Button: Button to quit the simulator application."},{"location":"competitions/roboracer-sim-racing-guide/#122-hud-panel","title":"1.2.2. HUD Panel","text":"<ul> <li>Simulation Time: The time (HH:MM:SS) since start of the simulation. Reset button resets the simulation time.   <li>Frame Rate: Running average of the FPS value (Hz).   <li>Driving Mode: Driving mode of the ego-vehicle (Manual or Autonomous).   <li>Gear: Driving gear of the vehicle, either Drive (D) or Reverse (R).   <li>Speed: Magnitude of forward velocity of the vehicle (m/s).   <li>Throttle: Instantaneous throttle input of the vehicle (%).   <li>Steering: Instantaneous steering angle of the vehicle (rad).   <li>Encoder Ticks: Ticks (counts) of the rear-left and rear-right incremental encoders of the vehicle represented using a 1D array of 2 elements [left_ticks, right_ticks].   <li>IPS Data: Position (m) of the vehicle within the environment represented using a 1D vector [x, y, z].   <li>IMU Data: Orientation [x, y, z] rad, angular velocity [x, y, z] rad/s, and linear acceleration [x, y, z] m/s<sup>2</sup> of the ego-vehicle w.r.t. body frame of reference.   <li>LIDAR Measurement: Instantaneous ranging measurement (m) of the 270\u00b0 FOV 2D LIDAR on the vehicle.   <li>Camera Preview: Instantaneous raw image from the front camera of the vehicle.   <li>Race Telemetry: Current elapsed lap time (s), last lap time (s), overall best lap time (s) as well as total lap count data.   <li>Data Recorder: Save time-synchronized simulation data for a specific simulation run."},{"location":"competitions/roboracer-sim-racing-guide/#123-data-recorder","title":"1.2.3. Data Recorder","text":"<p>AutoDRIVE Simulator hosts a time-synchronized data recording functionality that can be used to export simulation data at 30 Hz. The data is saved in <code>CSV</code> format and the raw camera frames are exported as timestamped <code>JPG</code> files. The <code>CSV</code> file hosts the following data entries per timestamp:</p> DATA timestamp throttle steering leftTicks rightTicks posX posY posZ roll pitch yaw speed angX angY angZ accX accY accZ camera lidar UNIT yyyy_MM_dd_HH_mm_ss_fff norm% rad count count m m m rad rad rad m/s rad/s rad/s rad/s m/s^2 m/s^2 m/s^2 img_path array(float) <p>The data recorder can be triggered by clicking on the red <code>Record Data</code> button in the HUD panel, or using the <code>R</code> hotkey. The first time, the data recorder will prompt the user to specify the directory path to store the data. The second trigger will start recording the data, which can be verified by checking the status of the red button change from <code>Record Data</code> to <code>Recording Data</code>. Finally, the third trigger will stop data recording, which can be verified by checking the status of the red button change from <code>Recording Data</code> to <code>Saving Data</code> with the save percentage being displayed.</p> <p>Info</p> <p>When specifying the directory path to store the data, just select the directory where you want the data to be saved with a single click, do not enter that directory by double-clicking onto it.</p> <p>Warning</p> <p>Although the data is meant to be recorded at 30 Hz, the actual rate depends on the compute power and the OS schedular, and may therefore fluctuate a bit. However, the data will still be time-synchronized.</p> <p>Note</p> <p>If you try to record data two (or more) times in a row, without resetting or restarting the simulator, the new data will be appended to the same <code>CSV</code> file and the new camera frames will be added to the same <code>Camera Frames</code> directory. The old data will not be overwritten for user convenience and one can differentiate between the old and new datasets using the <code>timestamp</code> variable. However, if this is not intended, please consider resetting or restarting the simulator and specifying a different directory to store the new data.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#13-vehicle","title":"1.3. Vehicle","text":"<p>Simulated vehicles can be developed using AutoDRIVE's modular scripts, or imported from third-party tools and open standards. Specifically, the RoboRacer vehicle was reverse-engineered and visually recreated using a third-party 3D modeling software, and was imported and post-processed within AutoDRIVE Simulator to make it physically and graphically \"sim-ready\".</p> <p>These vehicles are simulated as a combination of rigid body and sprung mass representations with adequate attention to rigid body dynamics, suspension dynamics, actuator dynamics, and tire dynamics. Additionally, the simulator detects mesh-mesh interference and computes contact forces, frictional forces, momentum transfer, as well as linear and angular drag acting on the vehicle. Finally, being an autonomy-oriented digital twin, the simulator offers physically-based sensor simulation for proprioceptive as well as exteroceptive sensors on-board the virtual vehicle.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#131-transforms","title":"1.3.1. Transforms","text":"<p>Note</p> <p>All right-handed coordinate frames depicted above are defined such that red represents x-axis, green represents y-axis, and blue represents z-axis.</p>  FRAME x y z R P Y <code>left_encoder</code> 0.0 0.118 0.0 0.0 0.0 <code>right_encoder</code> 0.0 -0.118 0.0 0.0 0.0 <code>ips</code> 0.08 0.0 0.055 0.0 0.0 0.0 <code>imu</code> 0.08 0.0 0.055 0.0 0.0 0.0 <code>lidar</code> 0.2733 0.0 0.096 0.0 0.0 0.0 <code>front_camera</code> -0.015 0.0 0.15 0.0 10.0 0.0 <code>front_left_wheel</code> 0.33 0.118 0.0 0.0 0.0 <code>front_right_wheel</code> 0.33 -0.118 0.0 0.0 0.0 <code>rear_left_wheel</code> 0.0 0.118 0.0 0.0 0.0 <code>rear_right_wheel</code> 0.0 -0.118 0.0 0.0 0.0 <p>Note</p> <p>All frame transforms mentioned above are defined w.r.t. the vehicle (local) frame of reference  <code>roboracer_1</code> located at the center of rear axle with x-axis pointing forward, y-axis pointing left, and z-axis pointing upwards. Columns x, y, and z denote translations in meters (m), while R, P, and Y denote rotations in degrees (deg).  denotes variable quantities.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#132-vehicle-dynamics","title":"1.3.2. Vehicle Dynamics","text":"<p>The vehicle model is a combination of a rigid body and a collection of sprung masses \\(^iM\\), where the total mass of the rigid body is defined as \\(M=\\sum{^iM}\\). The rigid body's center of mass, \\(X_{COM} = \\frac{\\sum{{^iM}*{^iX}}}{\\sum{^iM}}\\), connects these representations, with \\(^iX\\) representing the coordinates of the sprung masses.</p> <p>The suspension force acting on each sprung mass is computed as \\({^iM} * {^i{\\ddot{Z}}} + {^iB} * ({^i{\\dot{Z}}}-{^i{\\dot{z}}}) + {^iK} * ({^i{Z}}-{^i{z}})\\), where \\(^iZ\\) and \\(^iz\\) are the displacements of sprung and unsprung masses, and \\(^iB\\) and \\(^iK\\) are the damping and spring coefficients of the \\(i\\)-th suspension, respectively. The unsprung mass \\(m\\) is also subject to gravitational and suspension forces: \\({^im} * {^i{\\ddot{z}}} + {^iB} * ({^i{\\dot{z}}}-{^i{\\dot{Z}}}) + {^iK} * ({^i{z}}-{^i{Z}})\\).</p> <p>Tire forces are computed based on the friction curve for each tire, represented as \\(\\left\\{\\begin{matrix} {^iF_{t_x}} = F(^iS_x) \\\\{^iF_{t_y}} = F(^iS_y) \\\\ \\end{matrix}\\right.\\), where \\(^iS_x\\) and \\(^iS_y\\) are the longitudinal and lateral slips of the \\(i\\)-th tire, respectively. The friction curve is approximated using a two-piece cubic spline, defined as \\(F(S) = \\left\\{\\begin{matrix} f_0(S); \\;\\; S_0 \\leq S &lt; S_e \\\\ f_1(S); \\;\\; S_e \\leq S &lt; S_a \\\\ \\end{matrix}\\right.\\), where \\(f_k(S) = a_k*S^3+b_k*S^2+c_k*S+d_k\\) is a cubic polynomial function. The first segment of the spline ranges from zero \\((S_0,F_0)\\) to an extremum point \\((S_e,F_e)\\), while the second segment ranges from the extremum point \\((S_e, F_e)\\) to an asymptote point \\((S_a, F_a)\\).</p> <p>The tire slip is influenced by factors including tire stiffness \\(^iC_\\alpha\\), steering angle \\(\\delta\\), wheel speeds \\(^i\\omega\\), suspension forces \\(^iF_s\\), and rigid-body momentum \\(^iP\\). These factors impact the longitudinal and lateral components of the vehicle's linear velocity. The longitudinal slip \\(^iS_x\\) of \\(i\\)-th tire is calculated by comparing the longitudinal components of the surface velocity of the \\(i\\)-th wheel \\(v_x\\) with the angular velocity \\(^i\\omega\\) of the \\(i\\)-th wheel: \\({^iS_x} = \\frac{{^ir}*{^i\\omega}-v_x}{v_x}\\). The lateral slip \\(^iS_y\\) depends on the tire's slip angle \\(\\alpha\\) and is determined by comparing the longitudinal \\(v_x\\) and lateral \\(v_y\\) components of the vehicle's linear velocity: \\({^iS_y} = \\tan(\\alpha) = \\frac{v_y}{\\left| v_x \\right|}\\).</p>  VEHICLE PARAMETERS Car Length 0.5000 m Car Width 0.2700 m Wheelbase 0.3240 m Track Width 0.2360 m Front Overhang 0.0900 m Rear Overhang 0.0800 m Wheel Radius 0.0590 m Wheel Width 0.0450 m Total Mass 3.906 kg Sprung Mass 3.470 kg Unsprung Mass 0.436 kg Center of Mass X: 0.15532 mY: 0.00000 mZ: 0.01434 m Suspension Spring 500 N/m Suspension Damper 100 Ns/m Longitudinal Tire Limits (Slip, Force) Extremum: (0.15, 0.72)Asymptote: (0.25, 0.464) Lateral Tire Limits (Slip, Force) Extremum: (0.01, 1.00)Asymptote: (0.10, 0.500)"},{"location":"competitions/roboracer-sim-racing-guide/#133-actuator-dynamics","title":"1.3.3. Actuator Dynamics","text":"<p>The driving actuators apply torque to the wheels: \\({^i\\tau_{drive}} = {^iI_w}*{^i\\dot{\\omega}_w}\\), where \\({^iI_w} = \\frac{1}{2}*{^im_w}*{^i{r_w}^2}\\) represents the moment of inertia, \\(^i\\dot{\\omega}_w\\) is the angular acceleration, \\(^im_w\\) is the mass, and \\(^ir_w\\) is the radius of the \\(i\\)-th wheel. Additionally, the driving actuators simulate idle torque by applying an equivalent braking torque, i.e., \\({^i\\tau_{idle}} = {^i\\tau_{brake}}\\).</p>  DRIVING ACTUATOR Drive Type All wheel drive Throttle Limits [-1,1] Motor Torque 428 Nm Vehicle Top Speed 22.88 m/s <p>The front wheels are steered at the commanded steering angle \\(\\delta\\) using a steering actuator. The individual turning angles, \\(\\delta_l\\) and \\(\\delta_r\\), for the left and right wheels, respectively, are computed based on the Ackermann steering geometry defined by the wheelbase \\(l\\) and track width \\(w\\), as follows: \\(\\left\\{\\begin{matrix} \\delta_l = \\textup{tan}^{-1}\\left(\\frac{2*l*\\textup{tan}(\\delta)}{2*l+w*\\textup{tan}(\\delta)}\\right) \\\\ \\delta_r = \\textup{tan}^{-1}\\left(\\frac{2*l*\\textup{tan}(\\delta)}{2*l-w*\\textup{tan}(\\delta)}\\right) \\end{matrix}\\right.\\)</p>  STEERING ACTUATOR Steer Type Ackermann steering Steering Limits [-1,1] Steering Angle Limits [-0.5236,0.5236] rad Steering Rate 3.2 rad/s"},{"location":"competitions/roboracer-sim-racing-guide/#134-sensor-physics","title":"1.3.4. Sensor Physics","text":"<p>Throttle (\\(\\tau\\)) and steering (\\(\\delta\\)) sensors are simulated using an instantaneous feedback loop. Incremental encoders are simulated by measuring the rotation of the rear wheels: \\(^iN_{ticks} = {^iPPR} * {^iCR} * {^iN_{rev}}\\), where \\(^iN_{ticks}\\) and \\(^iPPR\\) respectively represent the measured ticks and base resolution (pulses per revolution) of the \\(i\\)-th encoder, while \\(^iCR\\) and \\(^iN_{rev}\\) respectively represent the conversion ratio and output shaft revolutions of the \\(i\\)-th motor.</p>  THROTTLE SENSOR Type Virtual Sensor Class Actuator Feedback Supported Outputs [-1, 1]  STEERING SENSOR Type Virtual Sensor Class Actuator Feedback Supported Outputs [-1, 1]  ENCODERS Type Simulated Sensor Class Proprioceptive Pulses Per Revolution 16 Conversion Ratio 120 Supported Outputs TicksAngles <p>The indoor positioning system (IPS) and inertial measurement unit (IMU) are simulated based on temporally-coherent rigid-body transform updates of the vehicle \\(\\{v\\}\\) w.r.t. the world \\(\\{w\\}\\): \\({^w\\mathbf{T}_v} = \\left[\\begin{array}{c | c} \\mathbf{R}_{3 \\times 3} &amp; \\mathbf{t}_{3 \\times 1} \\\\ \\hline \\mathbf{0}_{1 \\times 3} &amp; 1 \\end{array}\\right] \\in SE(3)\\). IPS provides 3-DOF positional coordinates \\(\\{x,y,z\\}\\) of the vehicle, while IMU supplies linear accelerations \\(\\{a_x,a_y,a_z\\}\\), angular velocities \\(\\{\\omega_x,\\omega_y,\\omega_z\\}\\), and 3-DOF orientation of the vehicle as Euler angles \\(\\{\\phi_x,\\theta_y,\\psi_z\\}\\) or quaternion \\(\\{q_0,q_1,q_2,q_3\\}\\).</p>  IPS Type Simulated Sensor Class Proprioceptive Supported Outputs Position Vector [x, y, z] m  IMU Type Simulated Sensor Class Proprioceptive Supported Outputs Orientation Quaternion [x, y, z, w]Orientation Euler Angles [x, y, z] radAngular Velocity Vector [x, y, z] rad/sLinear Acceleration Vector [x, y, z] m/s2 <p>LIDAR simulation employs iterative ray-casting \\(\\texttt{raycast}\\){\\(^w\\mathbf{T}_l\\), \\(\\vec{\\mathbf{R}}\\), \\(r_{max}\\)} for each angle \\(\\theta \\in \\left [ \\theta_{min}:\\theta_{res}:\\theta_{max} \\right ]\\) at a specified update rate. Here, \\({^w\\mathbf{T}_l} = {^w\\mathbf{T}_v} \\times {^v\\mathbf{T}_l} \\in SE(3)\\) represents the relative transformation of the LIDAR {\\(l\\)} w.r.t the vehicle {\\(v\\)} and the world {\\(w\\)}, \\(\\vec{\\mathbf{R}} = \\left [\\cos(\\theta) \\;\\; \\sin(\\theta) \\;\\; 0 \\right ]^T\\) defines the direction vector of each ray-cast, \\(r_{min}\\), \\(r_{max}\\), \\(\\theta_{min}\\) and \\(\\theta_{max}\\) denote the minimum and maximum linear and angular ranges, and \\(\\theta_{res}\\) represents the angular resolution of the LIDAR. The laser scan ranges are determined by checking ray-cast hits and then applying a threshold to the minimum linear range of the LIDAR, calculated as \\(\\texttt{ranges[i]}=\\begin{cases} d_\\text{hit} &amp; \\text{ if } \\texttt{ray[i].hit} \\text{ and } d_\\text{hit} \\geq r_{\\text{min}} \\\\ \\infty &amp; \\text{ otherwise} \\end{cases}\\), where \\(\\texttt{ray.hit}\\) is a Boolean flag indicating whether a ray-cast hits any colliders in the scene, and \\(d_\\text{hit}=\\sqrt{(x_{\\text{hit}}-x_{\\text{ray}})^2 + (y_{\\text{hit}}-y_{\\text{ray}})^2 + (z_{\\text{hit}}-z_{\\text{ray}})^2}\\) calculates the Euclidean distance from the ray-cast source \\(\\{x_{ray}, y_{ray}, z_{ray}\\}\\) to the hit point \\(\\{x_{hit}, y_{hit}, z_{hit}\\}\\).</p>  LIDAR Type Simulated Sensor Class Exteroceptive Scan Rate 40 Hz Angular Resolution 0.25 deg Measurements Per Scan 1080 Minimum Linear Range 0.06 m Maximum Linear Range 10.0 m Minimum Angular Range -135 deg Maximum Angular Range +135 deg Supported Outputs Range Array (m)Intensity Array <p>Simulated cameras are parameterized by their focal length \\(f\\), sensor size \\(\\{s_x, s_y\\}\\), target resolution, as well as the distances to the near \\(N\\) and far \\(F\\) clipping planes. The viewport rendering pipeline for the simulated cameras operates in three stages. First, the camera view matrix \\(\\mathbf{V} \\in SE(3)\\) is computed by obtaining the relative homogeneous transform of the camera \\(\\{c\\}\\) with respect to the world \\(\\{w\\}\\): \\(\\mathbf{V} = \\begin{bmatrix} r_{00} &amp; r_{01} &amp; r_{02} &amp; t_{0} \\\\ r_{10} &amp; r_{11} &amp; r_{12} &amp; t_{1} \\\\ r_{20} &amp; r_{21} &amp; r_{22} &amp; t_{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix}\\), where \\(r_{ij}\\) and \\(t_i\\) denote the rotational and translational components, respectively. Next, the camera projection matrix \\(\\mathbf{P} \\in \\mathbb{R}^{4 \\times 4}\\) is calculated to project world coordinates into image space coordinates: \\(\\mathbf{P} = \\begin{bmatrix} \\frac{2*N}{R-L} &amp; 0 &amp; \\frac{R+L}{R-L} &amp; 0 \\\\ 0 &amp; \\frac{2*N}{T-B} &amp; \\frac{T+B}{T-B} &amp; 0 \\\\ 0 &amp; 0 &amp; -\\frac{F+N}{F-N} &amp; -\\frac{2*F*N}{F-N} \\\\ 0 &amp; 0 &amp; -1 &amp; 0 \\\\ \\end{bmatrix}\\), where \\(L\\), \\(R\\), \\(T\\), and \\(B\\) denote the left, right, top, and bottom offsets of the sensor. The camera parameters \\(\\{f,s_x,s_y\\}\\) are related to the terms of the projection matrix as follows: \\(f = \\frac{2*N}{R-L}\\), \\(a = \\frac{s_y}{s_x}\\), and \\(\\frac{f}{a} = \\frac{2*N}{T-B}\\). The perspective projection from the simulated camera's viewport is given as \\(\\mathbf{C} = \\mathbf{P}*\\mathbf{V}*\\mathbf{W}\\), where \\(\\mathbf{C} = \\left [x_c\\;\\;y_c\\;\\;z_c\\;\\;w_c \\right ]^T\\) represents image space coordinates, and \\(\\mathbf{W} = \\left [x_w\\;\\;y_w\\;\\;z_w\\;\\;w_w \\right ]^T\\) represents world coordinates. Finally, this camera projection is transformed into normalized device coordinates (NDC) by performing perspective division (i.e., dividing throughout by \\(w_c\\)), leading to a viewport projection achieved by scaling and shifting the result and then utilizing the rasterization process of the graphics API (e.g., DirectX for Windows, Metal for macOS, and Vulkan for Linux). Additionally, a post-processing step simulates non-linear lens and film effects, such as lens distortion, depth of field, exposure, ambient occlusion, contact shadows, bloom, motion blur, film grain, chromatic aberration, etc.</p>  CAMERA Type Simulated Sensor Class Exteroceptive Field of View 48.8311 deg Sensor Size X: 3.68 mmY: 2.76 mm Shutter Speed 0.005 s Focal Length 3.04 m Aperture f/16 Target Image 16:9 (75% JPG Compression) Supported Outputs RGB Image"},{"location":"competitions/roboracer-sim-racing-guide/#14-environment","title":"1.4. Environment","text":"<p>Simulated environments can be developed using AutoDRIVE's modular infrastructure development kit (IDK), or imported from third-party tools and open standards. Specifically, the autonomous racing scenario was created based on the binary occupancy grid map of a real-world RoboRacer racetrack, called \"Porto\", using a third-party 3D modeling software, and was imported and post-processed within AutoDRIVE Simulator to make it physically and graphically \"sim-ready\".</p> <p>These environments are simulated by conducting mesh-mesh interference detection and computing contact forces, frictional forces, momentum transfer, as well as linear and angular drag acting on all rigid bodies in the scenario.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#141-transforms","title":"1.4.1. Transforms","text":"<p>Note</p> <p>All right-handed coordinate frames depicted above are defined such that red represents x-axis, green represents y-axis, and blue represents z-axis.</p>  FRAME x y z R P Y <code>world</code> 0.0 0.0 0.0 0.0 0.0 0.0 <code>roboracer_1</code> <p>Note</p> <p>All frame transforms mentioned above are defined w.r.t. the global frame of reference  <code>world</code>, which serves as a static frame of reference for the simulation environment. Columns x, y, and z denote translations in meters (m), while R, P, and Y denote rotations in degrees (deg).  denotes variable quantities, which in this case define the ground-truth pose of the vehicle within the simulated racetrack.</p> <p>Warning</p> <p>Since the racetrack is subject to change during different phases and iterations of the competition, the location of the fixed environmental frame of reference may be different depending on the racetrack.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#142-size-and-structure","title":"1.4.2. Size and Structure","text":"<ul> <li> <p>The simulated racetrack will be designed in accordance with the physical RoboRacer racetracks, using similar materials and spanning similar dimensions.</p> </li> <li> <p>The entire racetrack will be designed to fit within an area of around 30\\(\\times\\)10 m<sup>2</sup>, much like the physical RoboRacer racetracks.</p> </li> <li> <p>The racetrack border will be constructed from air ducts of about 33 cm in diameter, making sure that it is perceivable to exteroceptive sensors.</p> </li> <li> <p>The racetrack will be at least 3 car widths (90 cm) wide throughout to allow safe vehicle traversal, while giving an opportunity to optimize the raceline.</p> </li> </ul>"},{"location":"competitions/roboracer-sim-racing-guide/#143-design-and-features","title":"1.4.3. Design and Features","text":"<ul> <li> <p>The road surface will be simulated with properties of polished concrete, which is flat and reflective. Therefore, exteroceptive perception may become challenging at times, much like in the real world.</p> </li> <li> <p>There may be a gap(s) between the ducts through which the LiDAR beams can pass, making it appear as an obstacle-free space. Therefore, motion planning may become challenging at times, much like in the real world.</p> </li> <li> <p>The racetrack may consist of variabilities such as straight stretch, chicane, bifurcation, obstacles, etc. to make the course challenging.</p> </li> </ul> <p>Warning</p> <p>The racetrack is subject to change across different phases (e.g., practice, qualification, race, etc.) and iterations (e.g., IROS 2024, CDC 2024, etc.) of the competition. Participants will be informed about any track changes in advance.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#2-autodrive-devkit","title":"2. AutoDRIVE Devkit","text":"<p> AutoDRIVE Devkit (part of the larger AutoDRIVE Ecosystem) is a collection of application programming interfaces (APIs), human-machine interfaces (HMIs), programming languages, libraries, frameworks, packages and tools, which enables the flexible development of on-road and off-road autonomous driving algorithms, as well as smart city traffic management algorithms. It allows targeting the devised algorithms to the simulator as well as the testbed, seamlessly. It supports both local as well as distributed computing, thereby facilitating the development of both centralized and decentralized autonomy algorithms. </p> <p> For the RoboRacer Sim Racing League, each team will be provided with a standardized working implementation of the AutoDRIVE Devkit (in the form of ROS 2 API for the RoboRacer digital twin within AutoDRIVE Simulator) to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. Since the vehicle, the sensors, the simulator, and the devkit are standardized, teams must develop robust racing algorithms that can deal with the uncertainties of an unseen racetrack. </p>"},{"location":"competitions/roboracer-sim-racing-guide/#21-system-requirements","title":"2.1. System Requirements","text":"<p> Minimum Requirements: </p> <ul> <li>Platform: Ubuntu 20.04, Windows 10 (VS 2019), macOS 10.14</li> <li>Processor: Dual-core CPU (e.g., Intel Core i3 or AMD Ryzen 3)</li> <li>Memory: 4 GB RAM</li> <li>Graphics: Integrated graphics (e.g., Intel HD Graphics)</li> <li>Storage: 5 GB free disk space (for storing Docker images, API files, and temporary data)</li> <li>Display: 1280x720 px resolution with 60 Hz refresh rate</li> <li>Network: Stable internet connection (1 Mbps) for pulling/pushing Docker images, and downloading updates on demand</li> </ul> <p> Recommended Requirements: </p> <ul> <li>Platform: Ubuntu 20.04 (devkit has been extensively tested on this platform)</li> <li>Processor: Quad-core CPU (e.g., Intel Core i5 or AMD Ryzen 5)</li> <li>Memory: 8 GB RAM</li> <li>Graphics: Low-end discrete GPU (e.g., NVIDIA GeForce GT 1030)</li> <li>Storage: 10 GB free disk space (to accommodate multiple Docker images, additional data, and logs)</li> <li>Display: 1920x1080 px resolution with 60 Hz refresh rate</li> <li>Network: Fast internet connection (10 Mbps) for pulling/pushing Docker images, and downloading updates on the fly</li> </ul> <p>Info</p> <p>Note that the organizers will execute the competition framework on a workstation incorporating Intel Core i9 14<sup>th</sup> Gen 14900K CPU, NVIDIA GeForce RTX 4090 GPU, and 64 GB RAM (or a similar configuration). This machine will be simultaneously running the simulator container, devkit container, screen recorder and data logger. Kindly develop your algorithms while considering these computational requirements.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#22-package-structure","title":"2.2. Package Structure","text":"<p> The following tree describes the ROS 2 package structure of the AutoDRIVE Devkit used for the competition framework. </p> <pre><code>autodrive_devkit\n\u251c\u2500\u2500\u2500README.md\n\u251c\u2500\u2500\u2500package.xml\n\u251c\u2500\u2500\u2500setup.cfg\n\u251c\u2500\u2500\u2500setup.py\n\u251c\u2500\u2500\u2500requirements_python_3.8.txt\n\u251c\u2500\u2500\u2500requirements_python_3.9.txt\n\u251c\u2500\u2500\u2500requirements_python_3.10.txt\n\u2502\n\u251c\u2500\u2500\u2500autodrive_roboracer\n\u2502   \u2514\u2500\u2500\u2500autodrive_bridge.py\n\u2502   \u2514\u2500\u2500\u2500config.py\n\u2502   \u2514\u2500\u2500\u2500teleop_keyboard.py\n\u2502   \u2514\u2500\u2500\u2500__init__.py\n\u2502\n\u251c\u2500\u2500\u2500launch\n\u2502   \u2514\u2500\u2500\u2500bringup_headless.launch.py\n\u2502   \u2514\u2500\u2500\u2500bringup_graphics.launch.py\n\u2502\n\u251c\u2500\u2500\u2500resource\n\u2502   \u2514\u2500\u2500\u2500autodrive_roboracer\n\u2502\n\u251c\u2500\u2500\u2500\n\u2502   \u2514\u2500\u2500\u2500autodrive_roboracer.\n\u2502\n\u2514\u2500\u2500\u2500test\n\u2502   \u2514\u2500\u2500\u2500test_copyright.py\n\u2502   \u2514\u2500\u2500\u2500test_flake8.py\n\u2502   \u2514\u2500\u2500\u2500test_pep257.py\n</code></pre> <p>Warning</p> <p>Modifying the <code>autodrive_roboracer</code> package is not permitted. Participants will have to create their own separate package(s) to implement their autonomous racing algorithms.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#23-data-streams","title":"2.3. Data Streams","text":"<p> The following table describes various data streams of the competition framework. These data streams are exposed as ROS 2 topics using AutoDRIVE Devkit. </p> TOPIC TYPE MESSAGE ACCESS <code>/autodrive/roboracer_1/best_lap_time</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/roboracer_1/collision_count</code>  Debugging <code>std_msgs/msg/Int32</code>  Restricted <code>/autodrive/roboracer_1/front_camera</code>  Sensor <code>sensor_msgs/msg/Image</code>  Input <code>/autodrive/roboracer_1/imu</code>  Sensor <code>sensor_msgs/msg/Imu</code>  Input <code>/autodrive/roboracer_1/ips</code>  Sensor <code>geometry_msgs/msg/Point</code>  Restricted <code>/autodrive/roboracer_1/lap_count</code>  Debugging <code>std_msgs/msg/Int32</code>  Restricted <code>/autodrive/roboracer_1/lap_time</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/roboracer_1/last_lap_time</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/roboracer_1/left_encoder</code>  Sensor <code>sensor_msgs/msg/JointState</code>  Input <code>/autodrive/roboracer_1/lidar</code>  Sensor <code>sensor_msgs/msg/LaserScan</code>  Input <code>/autodrive/roboracer_1/right_encoder</code>  Sensor <code>sensor_msgs/msg/JointState</code>  Input <code>/autodrive/roboracer_1/speed</code>  Debugging <code>std_msgs/msg/Float32</code>  Restricted <code>/autodrive/roboracer_1/steering</code>  Sensor <code>std_msgs/msg/Float32</code>  Input <code>/autodrive/roboracer_1/steering_command</code>  Actuator <code>std_msgs/msg/Float32</code>  Output <code>/autodrive/roboracer_1/throttle</code>  Sensor <code>std_msgs/msg/Float32</code>  Input <code>/autodrive/roboracer_1/throttle_command</code>  Actuator <code>std_msgs/msg/Float32</code>  Output <code>/autodrive/reset_command</code>  Debugging <code>std_msgs/msg/Bool</code>  Restricted <code>/tf</code>  Debugging <code>tf2_msgs/msg/TFMessage</code>  Restricted <p>Warning</p> <p>You may use the restricted topics for debugging, training AI models, etc. However, these topics should not be used while autonomously racing at run-time (e.g., during the deployment/inference stage of the algorithm).</p> <p>Info</p> <p>Warning</p> <p>You can reset the simulation by publishing a <code>std_msgs/msg/Bool</code> message with <code>True</code> value on the <code>/autodrive/reset_command</code> topic. However, do not forget to set it to <code>False</code> again, or else the simulation will keep resetting!</p> <p>Please check out the video below to see the functionality of resetting the simulator via API in action, using the <code>teleop_keyboard</code> node. This would be a good way of understanding the working and implementation of this functionality for writing your custom nodes that can exploit this feature.</p> <p> </p>"},{"location":"competitions/roboracer-sim-racing-guide/#3-competition-submission","title":"3. Competition Submission","text":"<p> RoboRacer Sim Racing League is a virtual competition, which aims to make autonomous racing accessible to everyone across the globe. This competition adopts a containerization workflow to evaluate the submissions in a reproducible manner. Containerization provides a lightweight and portable environment, allowing applications to be easily packaged along with their dependencies, configurations, and libraries. </p> <p> Particularly, each team is expected to submit a containerized version of their autonomous racing software stack. Submissions for each phase of the competition will be done separately. </p>"},{"location":"competitions/roboracer-sim-racing-guide/#31-container-setup","title":"3.1. Container Setup","text":"<ol> <li>Install Docker.</li> <li>Since the Docker container is to take advantage of an NVIDIA GPU, the host machine has to be properly configured by installing the necessary NVIDIA GPU Drivers and the NVIDIA Container Toolkit.</li> <li>Pull AutoDRIVE Simulator docker image from DockerHub.    <pre><code>docker pull autodriveecosystem/autodrive_roboracer_sim:&lt;TAG&gt;\n</code></pre></li> <li>Pull AutoDRIVE Devkit docker image from DockerHub.    <pre><code>docker pull autodriveecosystem/autodrive_roboracer_api:&lt;TAG&gt;\n</code></pre></li> </ol> <p>Note</p> <p>Pay close attention to the <code>&lt;TAG&gt;</code> (i.e., tag name) of the container image you are pulling. This could be <code>explore</code> for exploring the framework, <code>practice</code> for practicing and qualification, or <code>compete</code> for competing in the final race. The tag naming convention is set to <code>&lt;YEAR&gt;-&lt;EVENT&gt;-&lt;PHASE&gt;</code> for convenience and avoiding any repetition.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#32-container-execution","title":"3.2. Container Execution","text":"<ol> <li>Enable display forwarding for simulator:     <pre><code>xhost local:root\n</code></pre></li> <li>Run the simulator container at <code>entrypoint</code>:     <pre><code>docker run --name autodrive_roboracer_sim --rm -it --entrypoint /bin/bash --network=host --ipc=host -v /tmp/.X11-unix:/tmp.X11-umix:rw --env DISPLAY --privileged --gpus all autodriveecosystem/autodrive_roboracer_sim:&lt;TAG&gt;\n</code></pre></li> <li>[OPTIONAL] Start additional bash session(s) within the simulator container (each in a new terminal window):     <pre><code>docker exec -it autodrive_roboracer_sim bash\n</code></pre></li> <li>Enable display forwarding for devkit:     <pre><code>xhost local:root\n</code></pre></li> <li>Run the devkit container at <code>entrypoint</code>:     <pre><code>docker run --name autodrive_roboracer_api --rm -it --entrypoint /bin/bash --network=host --ipc=host -v /tmp/.X11-unix:/tmp.X11-umix:rw --env DISPLAY --privileged --gpus all autodriveecosystem/autodrive_roboracer_api:&lt;TAG&gt;\n</code></pre></li> <li>[OPTIONAL] Start additional bash session(s) within the devkit container (each in a new terminal window):     <pre><code>docker exec -it autodrive_roboracer_api bash\n</code></pre></li> </ol>"},{"location":"competitions/roboracer-sim-racing-guide/#321-gui-mode-operations","title":"3.2.1. GUI Mode Operations:","text":"<ol> <li>Launch AutoDRIVE Simulator in <code>graphics</code> mode (camera rendering will be enabled):     <pre><code>./AutoDRIVE\\ Simulator.x86_64\n</code></pre></li> <li>Launch AutoDRIVE Devkit in <code>graphics</code> mode (RViz rendering will be enabled):     <pre><code>ros2 launch autodrive_roboracer simulator_bringup_graphics.launch.py\n</code></pre></li> <li> <p>Using the simulator GUI menu panel, configure the following:</p> <p>3.1. Enter the IP address of the machine running the devkit. If both containers are running on the same machine, leave the default loopback IP.</p> <p>3.2. Hit the <code>Connection</code> button and note the status next to it (also note that the devkit echoes <code>Connected!</code> message).</p> <p>3.3. Once the connection has been established, hit the <code>Driving Mode</code> to toggle the vehicle between <code>Manual</code> and <code>Autonomous</code> driving modes.</p> </li> </ol>"},{"location":"competitions/roboracer-sim-racing-guide/#322-headless-mode-operations","title":"3.2.2. Headless Mode Operations:","text":"<ol> <li>Launch AutoDRIVE Simulator in <code>no-graphics</code> mode (all rendering including vehicle camera will be disabled) by passing the IP address of the machine running the devkit as AutoDRIVE CLI arguments:     <pre><code>./AutoDRIVE\\ Simulator.x86_64 -batchmode -nographics -ip 127.0.0.1 -port 4567\n</code></pre></li> <li>Launch AutoDRIVE Simulator in <code>headless</code> mode (all rendering except vehicle camera rendering will be disabled) by passing the IP address of the machine running the devkit as AutoDRIVE CLI arguments:     <pre><code>xvfb-run ./AutoDRIVE\\ Simulator.x86_64 -ip 127.0.0.1 -port 4567\n</code></pre></li> <li>Launch AutoDRIVE Devkit in <code>headless</code> mode (RViz rendering will be disabled):     <pre><code>ros2 launch autodrive_roboracer simulator_bringup_headless.launch.py\n</code></pre></li> </ol> <p>Info</p> <p>It is possible to run either the simulator, devkit, or both selectively in either <code>graphics</code> or <code>headless/no-graphics</code> mode.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#323-distributed-computing-mode","title":"3.2.3. Distributed Computing Mode:","text":"<p> It is possible to run the simulator and devkit on two separate computing nodes (e.g. two different PCs) connected via a common network. The benefit of this approach is workload distribution by isolating the two computing processes, thereby gaining higher performance. It is further possible to run the devkit on a physical RoboRacer vehicle (using the Jetson SBC onboard) and connect it to the PC running AutoDRIVE Simulator as a hardware-in-the-loop (HIL) setup. </p> <p>Tip</p> <p>In certain cases, GPUs and Docker do not work very well and can cause problems in running the simulator container. In such cases, you can download and run the simulator locally (it should be easier to access the GPU this way). You can then run only the devkit within a container. Everything else will work just fine, only that the simulator will not be running inside a container. This shouldn not matter, since you will have to submit only the container for your algorithms (i.e., devkit) and not the simulator. We will run the containerized simulator on our side for the evaluation of all submissions.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#33-container-troubleshooting","title":"3.3. Container Troubleshooting","text":"<ol> <li>To access the container while it is running, execute the following command in a new terminal window to start a new bash session inside the container: <pre><code>docker exec -it &lt;CONTAINER NAME&gt; bash\n</code></pre></li> <li>To exit the bash session(s), simply execute: <pre><code>exit\n</code></pre></li> <li>To kill the container, execute the following command: <pre><code>docker kill &lt;CONTAINER NAME&gt;\n</code></pre></li> <li>To remove the container, simply execute: <pre><code>docker rm &lt;CONTAINER NAME&gt;\n</code></pre></li> <li>Running or caching multiple docker images, containers, volumes, and networks can quickly consume a lot of disk space. Hence, it is always a good idea to frequently check Docker disk utilization: <pre><code>docker system df\n</code></pre></li> <li>To avoid utilizing a lot of disk space, it is a good idea to frequently purge docker resources such as images, containers, volumes, and networks that are unused or dangling (i.e. not tagged or associated with a container). There are several ways with many options to achieve this, please refer to appropriate documentation. The easiest way (but a potentially dangerous one) is to use a single command to clean up all the docker resources (dangling or otherwise): <pre><code>docker system prune -a\n</code></pre></li> <li>After Docker Desktop is installed, Docker CLI commands are by default forwarded to Docker Desktop instead of Docker Engine, and hence you cannot connect to the Docker daemon without running Docker Desktop. In order to avoid this, just switch to the <code>default</code> Docker context: <pre><code>docker context ls\ndocker context use default\n</code></pre></li> </ol> <p>Warning</p> <p>It is not recommended to use Docker Desktop on the Linux operating system. This is because Docker Desktop creates a virtual machine based on Linux, which is first of all not needed for native (host) Linux OS, and secondly, it sometimes does not expose the necessary access ports for the containers (e.g., trouble with GPU access).</p> <p>Info</p> <p>For additional help on containerization, visit docker.com. Specifically, the documentation and get started pages would be of significant help for the beginners. Also, this cheatsheet could be a very handy reference for all important Docker CLI commands.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#34-algorithm-development","title":"3.4. Algorithm Development","text":"<p>Teams will have to create their ROS 2 package(s) or meta-package(s) for autonomous racing within the devkit container separate from the provided <code>autodrive_roboracer</code> package (i.e., without making any modifications to the <code>autodrive_roboracer</code> package itself).</p> <p>Please make a note of the data streams mentioned above (along with their access restrictions) to help with the algorithm development process.</p> <p>Tip</p> <p>If working with containers is overwhelming, you can download and run the devkit locally while developing and testing your autonomous racing algorithms. You can then containerize the refined algorithms, test them one last time, and push them to the container registry.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#35-container-submission","title":"3.5. Container Submission","text":"<p>Note</p> <p>We expect that upon running your submitted container, all the necessary nodes should start up (the <code>autodrive_devkit</code> API we have included as well as your team's racing stack). Once we hit the <code>Connection Button</code> on the <code>Menu Panel</code> of AutoDRIVE Simulator, the simulated vehicle should start running. Please refer to the competition rules, where it talks about the submission guidelines. Please make sure that you include all the necessary commands (for sourcing workspaces, setting environment variables, launching nodes, etc.) within the <code>entrypoint</code> script (<code>autodrive_devkit.sh</code> file) provided within the <code>autodrive_roboracer_api</code> container. Please do NOT use <code>~/.bashrc</code> or other means to automate the algorithm execution! Competition organizers should be able to start additional bash session(s) within your submitted container (without your codebase executing every time a new bash session is initialized) for data recording and inspection purposes.</p> <ol> <li>Run the image you created in the previous step inside a container: <pre><code>xhost local:root\ndocker run --name autodrive_roboracer_api --rm -it --entrypoint /bin/bash --network=host --ipc=host -v /tmp/.X11-unix:/tmp.X11-umix:rw --env DISPLAY --privileged --gpus all autodriveecosystem/autodrive_roboracer_api:&lt;TAG&gt;\n</code></pre></li> <li>In a new terminal window, list all containers and make a note of the desired <code>CONTAINER ID</code>: <pre><code>docker ps -a\n</code></pre></li> <li>Commit changes to DockerHub: <pre><code>docker commit -m \"&lt;Sample commit message&gt;\" -a \"&lt;USERNAME&gt;\" &lt;CONTAINER ID&gt; &lt;username&gt;/&lt;image_name&gt;:&lt;TAG&gt;\n</code></pre></li> <li>Login to DockerHub: <pre><code>docker login\n</code></pre></li> <li>Push the container to DockerHub, once done, you should be able to see your repository on DockerHub: <pre><code>docker push &lt;username&gt;/&lt;image_name&gt;:&lt;TAG&gt;\n</code></pre></li> <li>Submit the link to your team's DockerHub repository via a secure Google Form.</li> </ol>"},{"location":"competitions/roboracer-sim-racing-guide/#4-citation","title":"4. Citation","text":"<p>We encourage you to read and cite the following papers if you use any part of the competition framework for your research:</p>"},{"location":"competitions/roboracer-sim-racing-guide/#autodrive-a-comprehensive-flexible-and-integrated-digital-twin-ecosystem-for-enhancing-autonomous-driving-research-and-education","title":"AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Enhancing Autonomous Driving Research and Education","text":"<p><pre><code>@article{AutoDRIVE-Ecosystem-2023,\nauthor = {Samak, Tanmay and Samak, Chinmay and Kandhasamy, Sivanathan and Krovi, Venkat and Xie, Ming},\ntitle = {AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Autonomous Driving Research &amp; Education},\njournal = {Robotics},\nvolume = {12},\nyear = {2023},\nnumber = {3},\narticle-number = {77},\nurl = {https://www.mdpi.com/2218-6581/12/3/77},\nissn = {2218-6581},\ndoi = {10.3390/robotics12030077}\n}\n</code></pre> This work has been published in MDPI Robotics. The open-access publication can be found on MDPI.</p>"},{"location":"competitions/roboracer-sim-racing-guide/#autodrive-simulator-a-simulator-for-scaled-autonomous-vehicle-research-and-education","title":"AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education","text":"<p><pre><code>@inproceedings{AutoDRIVE-Simulator-2021,\nauthor = {Samak, Tanmay Vilas and Samak, Chinmay Vilas and Xie, Ming},\ntitle = {AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education},\nyear = {2021},\nisbn = {9781450390453},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3483845.3483846},\ndoi = {10.1145/3483845.3483846},\nbooktitle = {2021 2nd International Conference on Control, Robotics and Intelligent System},\npages = {1\u20135},\nnumpages = {5},\nlocation = {Qingdao, China},\nseries = {CCRIS'21}\n}\n</code></pre> This work has been published at 2021 International Conference on Control, Robotics and Intelligent System (CCRIS). The publication can be found on ACM Digital Library.</p>"},{"location":"competitions/roboracer-sim-racing-icra-2025/","title":"RoboRacer Sim Racing League @ ICRA 2025","text":""},{"location":"competitions/roboracer-sim-racing-icra-2025/#about","title":"About","text":"<p> RoboRacer Autonomous Racing is a semi-regular competition organized by an international community of researchers, engineers, and autonomous systems enthusiasts. The teams participating in the 24th RoboRacer Autonomous Racing Competition at ICRA 2025 will write software for a 1:10 scaled autonomous racecar to fulfill the objectives of the competition: drive fast but don\u2019t crash! </p> <p> This time, we are organizing the third RoboRacer Sim Racing League, which leverages AutoDRIVE Ecosystem to model and simulate the digital twin of an RoboRacer racecar within a virtual racetrack. Please see the accompanying video for a glimpse of the RoboRacer digital twins in action. </p> <p> The main focus of the Sim Racing League is a virtual competition with simulated cars and environments, which is accessible to everyone across the globe. For the ICRA 2025 competition, each team will be provided with a standardized simulation setup (in the form of a digital twin of the RoboRacer vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. Additionally, teams will also be provided with a working implementation of the AutoDRIVE Devkit to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. </p> <p> The competition will take place in 2 stages: </p> <ul> <li>Qualification Race: Teams will demonstrate their ability to complete multiple laps around the practice track without colliding with the track bounds at run time.</li> <li>Time-Attack Race: Teams will compete against the clock, on a previously unseen racetrack, to secure a position on the leaderboard.</li> </ul> <p> Since the vehicle, the sensors, the simulator, and the devkit are standardized, teams must develop robust racing algorithms that can deal with the uncertainties of an unseen racetrack. </p> <p>Tip</p> <p>If you are interested in autonomously racing physical RoboRacer vehicles, please check out the website for 24<sup>th</sup> RoboRacer Autonomous Racing Competition, which will be held in person at ICRA 2025. You can always register and compete in both physical and virtual competitions!</p>"},{"location":"competitions/roboracer-sim-racing-icra-2025/#organizers","title":"Organizers","text":"Dr. Rahul Mangharam Dr. Venkat Krovi Dr. Johannes Betz Chinmay Samak Tanmay Samak Ahmad Amine"},{"location":"competitions/roboracer-sim-racing-icra-2025/#timeline","title":"Timeline","text":"<p>Warning</p> <p>Timeline is subject to change. Please keep checking this page for any updates.</p> DATE EVENT Feb 20, 2025 Registration Opens Apr 15, 2025 Registration Closes Apr 16, 2025 (5:30 \u2013 6:30 PM EDT) Online Orientation May 03 \u2013 May 04, 2025 Qualification Round May 05, 2025 Qualification Results Declared May 08, 2025 Competition Track Released May 10 \u2013 May 11, 2025 Final Race May 12, 2025 Competition Results Declared <p> Following is a brief summary of each event: </p> <ul> <li>Registration: Interested teams will register for the Sim Racing League.</li> <li>Online Orientation: Organizers will explain the competition rules and guidelines, and demonstrate how to use the simulation framework.</li> <li>Qualification Round: Teams will demonstrate successful completion of 10 laps around the practice track provided ahead of time.</li> <li>Qualification Results Declared: Standings of all the qualified teams will be released.</li> <li>Competition Track Released: Organizers will release the actual \"competition track\", which will be used for the final race. This track may be replicated in the physical race as well.</li> <li>Final Race: Organizers will collect containerized algorithms from each team and connect them with the containerized simulator. Performance metrics of each team will be recorded.</li> <li>Competition Results Declared: Standings of all the teams for the final race will be released.</li> </ul> <p>Info</p> <p>The RoboRacer Sim Racing League will be held approximately 1 week ahead of ICRA 2025 and the performance metrics will be made available to the teams. Discussions are underway with the ICRA organizing team to allow teams to analyze and present their approach/results in a short (~10 min) presentation in a special session at ICRA 2025.</p>"},{"location":"competitions/roboracer-sim-racing-icra-2025/#resources","title":"Resources","text":"<p> AutoDRIVE is envisioned to be an open, comprehensive, flexible and integrated cyber-physical ecosystem for enhancing autonomous driving research and education. It bridges the gap between software simulation and hardware deployment by providing the AutoDRIVE Simulator and AutoDRIVE Testbed, a well-suited duo for real2sim and sim2real transfer targeting vehicles and environments of varying scales and operational design domains. It also offers AutoDRIVE Devkit, a developer's kit for rapid and flexible development of autonomy algorithms using a variety of programming languages and software frameworks. For the Sim Racing League, teams will develop their autonomous racing algorithms using the AutoDRIVE Devkit to interface with the AutoDRIVE Simulator in real-time. </p> <p></p> <p> RoboRacer is an international community of researchers, engineers, and autonomous systems enthusiasts. It is centered around the idea of converting a 1:10 scale RC car into an autonomous vehicle for research and education; check out the documentation to build your own RoboRacer autonomous racecar. Additionally, if you are new to the field of autonomous racing, you can refer to the complete course material, which is open sourced. If you already have some experience with autonomous racing, feel free to delve deeper into the research enabled by RoboRacer. Lastly, you can also check out the physical RoboRacer races that are being organized all around the world. For the Sim Racing League, teams will not require a physical RoboRacer vehicle; however, the learning resources can certainly be useful to get your autonomous racing fundamentals right! </p> <p> We recommend all the teams interested in participating in the RoboRacer Sim Racing League to get accustomed with the competition. Following are a few resources to get you started: </p> <ul> <li> <p> Competition Documents</p> <p>Learn about the competition rules and technical aspects of the framework.</p> <p> Competition Rules</p> <p> Technical Guide</p> </li> <li> <p> Docker Containers</p> <p>Download base container images for the competition and start developing your algorithms.</p> <p> AutoDRIVE Simulator: <code>explore</code> | <code>practice</code> | <code>compete</code></p> <p> AutoDRIVE Devkit: <code>explore</code> | <code>practice</code> | <code>compete</code></p> </li> <li> <p> Local Resources</p> <p>Get started with the competition framework locally, and worry about containerization later. </p> <p>AutoDRIVE Simulator:</p> <p><code>explore</code>  Linux |  Windows |  macOS</p> <p><code>practice</code>  Linux |  Windows |  macOS</p> <p><code>compete</code>  Linux |  Windows |  macOS</p> <p>AutoDRIVE Devkit:</p> <p> ROS 2</p> </li> <li> <p> Quick Links</p> <p>Links to be kept at your fingertips, for a smooth ride throughout the competition.</p> <p>Schedule:  Timeline</p> <p>Registration:  Form</p> <p>Orientation:  Zoom |  Recording |  Slides</p> <p>Communication:  Slack</p> <p>Submission:  Phase 1 |  Phase 2</p> <p>Results:  Phase 1 |  Phase 2</p> </li> </ul> <p>Question</p> <p>You can post general questions on the  AutoDRIVE Slack workspace; this is the preferred modality. Technical questions can be also posted as  GitHub Issues or  GitHub Discussions. For any other questions or concerns that cannot be posted publicly, please contact  Chinmay Samak or  Tanmay Samak.</p>"},{"location":"competitions/roboracer-sim-racing-icra-2025/#registration","title":"Registration","text":"<p> This competition is open to everyone around the world - students, researchers, hobbyists, professionals, or anyone else who is interested. A team can consist of multiple teammates. Teams with only one person are also allowed. </p>  Registration Form <p> Registration for the Sim Racing League is free of cost and separate from the Physical Racing League and the conference registrations themselves. The above form signs you up only for the Sim Racing League, and for its orientation and information sessions. Although you can participate in the Sim Racing League without attending the conference, we strongly encourage all competition participants to attend the conference in person. This will help you connect with the broader AutoDRIVE and RoboRacer communities, and you can also witness/participate in the physical RoboRacer autonomous racing competition! </p> <p> Registered teams are added to the following table: </p> SR. NO. TEAM NAME TEAM MEMBERS ORGANIZATION COUNTRY 01 fsociety Ritesh GoleKartikeya GuptaRaj ShahGoutham Jyothilal Personal India 02 Chasing Cop Car Jaihind JAditya Ravichander Personal India 03 Alp Autonomous Ble Auriol Alpha Space Robotics C\u00f4te d'Ivoire 04 Bushra AlShehhi Bushra AlShehhi Khalifa University United Arab Emirates (UAE) 05 Technion F1TENTH Team Andr\u00e9s Kaminker Technion Israel 06 bracavisionai Luis Bracamontes Personal Mexico 07 Finding Theta Michael Kudlaty Personal United States of America (USA) 08 Team Rajdeep Singh Personal India 09 Mostafa Ahmed Sayed Mostafa Hassan Personal Egypt 10 Invincibles Elyas SaeedAhmad AljallafAli Asaad Al-BehadiliAbdelrahman Zidan Khalifa University United Arab Emirates (UAE) 11 FuzzyGreenBlurs Akhil Sankar Rutgers University United States of America (USA) 12 CarGoesVroom WenYang Lim Personal Malaysia 13 Autobots Shubham BargeAnshuman JenaSaivamshi Jilla Personal India 14 Baby Driver Mason NotzPallavi Kulkarni Personal United States of America (USA) 15 TURTLEBOT Jit Ern LimDustin Lim Personal Malaysia &amp; Indonesia 16 Cair's Siddhant DiwakerChirag Makwana Personal India 17 BONG_RACERS Srinjoy GangulyPritish SahaSrijit Das Personal India 18 AA Lab Taha KocyigitOmer Geyikci Bogazici University Turkiye 19 SUST Autodrive Abul Bashar Raz Shahjalal University of Science and Technology Bangladesh 20 Beep Beep Jeremy Seyssaud Personal France 21 Circuit Breakers Thanushraam Suresh KumarDhruv PathakAtharva Patil University of Colorado, Boulder United States of America (USA) 22 Mamba Hariharan Ravichandran Personal United States of America (USA) 23 Racer X Jonathan NixonRoberto Ligeralde Autonomous Racing at Penn United States of America (USA) 24 IDEA_LAB Ji-Hong ParkKim Ju-YoungChanki KimSujin ParkSe Yeon Lee Gyeongsang National University South Korea 25 Abdulrahman Mahmoud Abdulrahman Mahmoud Personal Egypt 26 ESL Christopher FloodNico MartinJC Schoeman Stellenbosch University South Africa 27 VAUL William FecteauNicolas LauzonTommy Bouchard-Lebrun Laval University Canada 28 Wall-E Vinura Wanniarachchi Personal Sri Lanka 29 SoloDriver Hana Nabhan Personal Egypt 30 Robotikusu Ananay Shiv Indian Institute of Technology, Kharagpur India 31 Shelby S. SrikaanthS. VigneshS. A. Gogulnath Personal India 32 MMS Autonomous Osama HelalAhmed MwafyAbdelrahman ArafaKirellos YoussefKareem El Zahaby Mansoura University Egypt 33 Escuderia Poliposition Fernando Zolubas PretoAntonio Colombini NetoCarlos Alberto Arronte DelgadoGabriel Stephano SantosLuccas BarsottiFrancisco Rodrigues MaraziaAmanda Spagolla Polytechnic School of the University of S\u00e3o Paulo Brazil 34 Raptor Ji Su Lee Personal South Korea 35 Humble-CV Ayush DavidBasil ShajiCyril Jacob Karunya Institute of Technology and Sciences India 36 Zancle E-Drive Gaetano Pio PispisaGiovanni LombardoSimone CastorinoGabriele RinaldiAndrea Ferdinando Longoni University of Messina Italy 37 Riverside Racers Alexander TotahMarcus HsiehAmber LinJames LiuHang Qiu University of California, Riverside United States of America (USA) 38 IslandDriver Eunhye Lee Stony Brook University United States of America (USA) 39 ICPS Juan TiqueDonovan HoAndrew Mitchell iCPS Lab, University of Central Florida United States of America (USA) 40 Kanka Yukang CaoGoktug Poyrazoglu University of Minnesota United States of America (USA) 41 Ctrl+Drift Aditya JambhaleChaitanya BhatiaKaustubh KrishnaAkshat TambiPrerna SharmaYashowardhan Singh SRM Institute of Science and Technology India 42 Overtechnologia Aditya Paul Personal India 43 Autonomous Ground Vehicle Swaminathan S KShreyansh KansalDaksh YadavNinaad DesaiRohan SinghSandip DasUtsab KaranVarun ThirupathyAditya SrivastavaSreyas Venkataraman Indian Institute of Technology, Kharagpur India 44 CAVREL-UCF Israel CharlesBabak SoorchaeiDevin HunterYaser Fallah University of Central Florida United States of America (USA) 45 Autoware Aces Po-Jen WangTran Huu Nhat HuyAlexander Kalmykov Autoware Foundation Japan &amp; United States of America (USA) 46 Ashesi ARCLab Emmanuel KorankyeWilliam AkuffoJoshua NtiReginald Andrew Sai-ObadaiBaron AfutuJoel Osei-AsamoahKobena EnyamSamuel AkwensivieAppenteng AdjepongDesmond Hammond Ashesi University Ghana 47 QuillKraft Aryan Iyer Indian Institute of Technology, Bombay India 48 PowerZero Ramana BottaVenkat Prasad Personal India 49 WARRacing Dominik SchneiderDanit NiwattanananParham Rahimi Personal Germany 50 The Impressionists Tanay Shah Personal India 51 WATonomous Rodney DongMark DoHarsharan RakhraManjot Dola University of Waterloo WATonomous Design Team Canada 52 UO Autonomous Drive David MirandaLuc\u00eda S\u00e1nchezMiguel Santamar\u00eda University of Oviedo Spain 53 Smirnov Racing Kirill Smirnov K. Smirnov Robotics Ltd. Cyprus 54 RUN-RUN-ChuraTaro Soya Aoki Chura DATA Inc. Japan 55 Arcanine Shreyas Raorane University of Pennslvania United States of America (USA) 56 orangetongue Vittorio CataffoFrancesca CataffoFederica Cataffo Personal Italy 57 AsTenth Martin Ajay Shankar Sriram Chura DATA Inc. United States of America (USA) 58 PITT Aragya GoyalRobert Exley University of Pittsburgh United States of America (USA) <p>Note</p> <p>The above table will be updated with newly registered teams within a few days of registration. Please contact  Chinmay Samak or  Tanmay Samak if you do not see your team entry for more than 7 days after registering.</p>"},{"location":"competitions/roboracer-sim-racing-icra-2025/#submission","title":"Submission","text":"<p> Use the secure form below to make your team's submission for Phase 1 (Qualification Round) of the RoboRacer Sim Racing League. Please fill in your team's name and add the link to your team's DockerHub repository containing the autonomous racing stack. If you are using a private repository, make sure to add autodriveecosystem as a collaborator to your repository. </p>  Phase 1 Submission Form <p>Warning</p> <p>Phase 1 submission window will close on May 03, 2025 (anywhere on earth). Please contact  Chinmay Samak or  Tanmay Samak if you have any questions.</p> <p> Use the secure form below to make your team's submission for Phase 2 (Final Race) of the RoboRacer Sim Racing League. Please fill in your team's name and add the link to your team's DockerHub repository containing the autonomous racing stack. If you are using a private repository, make sure to add autodriveecosystem as a collaborator to your repository. </p>  Phase 2 Submission Form <p>Warning</p> <p>Phase 2 submission window will close on May 10, 2025 (anywhere on earth). Please contact  Chinmay Samak or  Tanmay Samak if you have any questions.</p>"},{"location":"competitions/roboracer-sim-racing-icra-2025/#results","title":"Results","text":"<p>Phase 1: Qualification</p> <p> To be announced on May 05, 2025. </p> <p>Phase 2: Competition</p> <p> To be announced on May 12, 2025. </p>"},{"location":"competitions/roboracer-sim-racing-rules/","title":"Competition Rules","text":"<p> This document describes the rules and regulations for the RoboRacer Sim Racing League. It goes over the definitions, requirements and evaluation criteria as well as general dos and don'ts for the competition. </p> <p>Warning</p> <p>Rules are subject to change. Organizers reserve the right to amend existing rules and, if situation demands, create new rules on the go.</p>"},{"location":"competitions/roboracer-sim-racing-rules/#1-general-guidelines","title":"1. General Guidelines","text":"<p> RoboRacer Sim Racing League is a virtual competition, which accompanies the physical RoboRacer Autonomous Racing Competition. It leverages AutoDRIVE Ecosystem to model and simulate the digital twin of an RoboRacer racecar within a virtual racetrack. The main goal of this competition is to make autonomous racing accessible to everyone across the globe. </p>"},{"location":"competitions/roboracer-sim-racing-rules/#11-eligibility-criteria","title":"1.1. Eligibility Criteria","text":"<p> This competition is open to everyone around the world - students, researchers, hobbyists, professionals, or anyone else who is interested. There are no restrictions on age, sex, nationality, profession, etc. A team can consist of single or multiple participants. Multiple teams from the same organization are also allowed. However, each participant can be a member of strictly one team. </p> <p> Registration for the Sim Racing League is free of cost and separate from the Physical Racing League and the conference registrations themselves. Although teams can participate in the Sim Racing League without attending the conference, we strongly encourage all competition participants to attend the conference in person. This will allow the teams to participate in competition-related events at the conference and connect with the broader community! </p>"},{"location":"competitions/roboracer-sim-racing-rules/#12-competition-structure","title":"1.2. Competition Structure","text":"<p> Each team will be provided with a standardized simulation setup (in the form of a digital twin of the RoboRacer vehicle, and a digital twin of the Porto racetrack) within the high-fidelity AutoDRIVE Simulator. Additionally, teams will also be provided with a working implementation of the AutoDRIVE Devkit to get started with developing their autonomy algorithms. Teams will have to develop perception, planning, and control algorithms to parse the real-time sensor data streamed from the simulator and generate control commands to be fed back to the simulated vehicle. </p>"},{"location":"competitions/roboracer-sim-racing-rules/#13-competition-timeline","title":"1.3. Competition Timeline","text":"<p> The competition will take place in 2 stages: </p> <ul> <li>Qualification Race: Teams will demonstrate their ability to complete multiple laps around the practice track without colliding with the track bounds at run time.</li> <li>Time-Attack Race: Teams will compete against the clock, on a previously unseen racetrack, to secure a position on the leaderboard.</li> </ul> <p> Following is a summary of the main events of the competition: </p> <ul> <li>Registration: Interested teams will register for the Sim Racing League.</li> <li>Online Orientation 1: Organizers will explain the competition rules and guidelines, and demonstrate how to use the simulation framework.</li> <li>Online Orientation 2: Organizers will check progress of the participating teams and help with any technical difficulties.</li> <li>Qualification Round: Teams will demonstrate successful completion of 10 laps around the practice track provided ahead of time.</li> <li>Qualification Results Declared: Standings of all the qualified teams will be released.</li> <li>Competition Track Released: Organizers will release the actual \"competition track\", which will be used for the final race. This track may be replicated in the physical race as well.</li> <li>Final Race: Organizers will collect containerized algorithms from each team and connect them with the containerized simulator. Performance metrics of each team will be recorded.</li> <li>Competition Results Declared: Standings of all the teams for the final race will be released.</li> </ul>"},{"location":"competitions/roboracer-sim-racing-rules/#2-competition-guidelines","title":"2. Competition Guidelines","text":"<p> This competition will adhere to the time-attack racing format, wherein each team will compete against the clock independently, on the same racetrack. Each race will comprise a total of 12 laps: the vehicles will start with a warm-up lap, followed by 10 race laps, and finally a cool-down lap. </p>"},{"location":"competitions/roboracer-sim-racing-rules/#21-competition-requirements","title":"2.1. Competition Requirements","text":"<p> Following are the requirements to progress along each phase of the competition: </p> <ul> <li>Registration: Interested teams must register for the competition before the deadline. Organizers may extend registration deadlines in certain cases; however, direct requests for deadline extension from any team(s) will not be entertained. It is recommended to register your team well in advance to avoid last-minute rush.</li> <li>Orientations: It is highly recommended for all teams to attend the online orientation sessions to understand the competition code-of-conduct and get familiar with the simulation framework. These events can also be used to get some of your doubts clarified!</li> <li>Qualification: Teams will have to demonstrate successful completion of 10 autonomous laps around the practice track provided ahead of time. During this phase, speed is not very important, but failure to complete 10 consecutive autonomous laps without exceeding the collision count tolerance will result in disqualification of that team. Passing the qualification session entitles a team for the final race.</li> <li>Competition: During this phase, the clock will be ticking, and the objective would be to complete 10 consecutive autonomous laps as fast as possible without exceeding the collision count tolerance. Failure to respect the collision count tolerance will result in disqualification of that team. Teams will be ranked on a leaderboard in the ascending order of their time to completion (10 autonomous racing laps).</li> </ul>"},{"location":"competitions/roboracer-sim-racing-rules/#22-competition-terminology","title":"2.2. Competition Terminology","text":"<p> Following are the definitions of some competition terminologies: </p> <ul> <li>Collision: Any contact between the colliders of the simulated vehicle and the racetrack bounds (except the wheels touching the ground) is considered a collision. A collision will incur a penalty of 10 seconds (i.e., 10 seconds after first collision, 20 seconds after the second, 30 seconds after the third, and so on). Colliding more than 10 times in a single racing event will lead to disqualification. Each collision will automatically reset the vehicle to the last checkpoint (your localization algorithm will have to be robust against this re-setting action). Lap timer will not reset upon collision.</li> <li>Warm-Up Lap: This is the first lap of a race. The time or collisions during the warm-up lap will not be considered. This lap acts as a buffer since your algorithms may take time to launch and connect with the simulator, while the lap timer is on.</li> <li>Race Laps: These are a set of 10 laps immediately following the warm-up lap. The race laps start as soon as the vehicle crosses the finish line in the warm-up lap. The time and collisions of the race laps will be considered.</li> <li>Cool-Down Lap: This is the last lap of a race. The time or collisions during the cool-down lap will not be considered. Completing this lap is not required for the competition, but this can be a good time to \"show-off\" your skills without worrying about collisions!</li> <li>Checkpoints: The racetrack has several \"virtual\" checkpoints, spaced approximately equally along the track. These checkpoints cover the entire width of the racetrack and are triggered as the vehicle passes through them. The start/finish line is the final \"special\" checkpoint. The exact location of the checkpoints will not be revealed to the participants.</li> <li>Lap Time: This is the amount of time that the vehicle takes to complete one full lap around the racetrack. The timer starts as soon as the previous lap ends and stops after the current lap ends. Failing to pass all the checkpoints before crossing the finish line (e.g., driving in opposite direction) will not stop the lap timer.</li> <li>Race Time: This is the cumulative time that the vehicle takes to complete 10 race laps around the racetrack. The timer starts as soon as the warm-up lap ends and stops after the 10th race lap ends. Collision penalties are added separately.</li> <li>Best Lap Time: This is the amount of time that the vehicle took to complete the fastest race lap around the racetrack. This is the minimum lap time across all the 10 race laps.</li> <li>Average Lap Time: This is the average time that the vehicle took to complete a race laps (out of 10 race laps) around the racetrack. This is the statistical mean of all the 10 race lap times.</li> </ul>"},{"location":"competitions/roboracer-sim-racing-rules/#23-competition-execution","title":"2.3. Competition Execution","text":"<p> Following is a summary of a typical racing event: </p> <ul> <li>Inspection: Race stewards will examine the team's submission according to race standards.</li> <li>Simulator: Containerized AutoDRIVE Simulator will be launched. Communication bridge parameters will be set (communication channel will not be opened yet). Vehicle will be engaged in autonomous mode. Graphics quality will be set to \"Ultra\". </li> <li>Devkit: Containerized AutoDRIVE Devkit with the team's autonomous racing algorithm submission will be launched. A new Bash session will be opened within the container to start recording a ROS 2 bag of all the available topics.</li> <li>Recording: A screen recorder application as well as the ROS 2 bag recording will run in the background.</li> <li>Communication: The bi-directional communication channel between simulator container and devkit container will be established. This should make all the data available on the relevant ROS 2 topics and automatically start the race.</li> <li>Race: Each race will comprise a total of 12 laps: the vehicles will start with a warm-up lap, followed by 10 race laps, and finally a cool-down lap. The lap times or collisions during the warm-up and cool-down laps will not be considered, only those during the 10 race laps will be considered.</li> <li>Data: Performance metrics of the team will be recorded and stored along with the screen recording of the simulator as well as the comprehensive ROS 2 bag.</li> </ul>"},{"location":"competitions/roboracer-sim-racing-rules/#24-inspection-rules","title":"2.4. Inspection Rules","text":"<p>Warning</p> <p>Organizers reserve the right to reject any submission that they deem illegal due to unethical exploitation of the competition framework. All submissions will be examined by the race stewards prior to the race.</p> <p>Warning</p> <p>Teams breaching the code of conduct will face direct disqualification with a publicly visible \"malpractice\" citation on the competition website.</p> <p> This competition is intended to be a battle of algorithms, and hence any modifications to the competition framework including (but not limited to) the simulator executable, vehicle (chassis, powertrain, sensors, etc.), environment (track, layout, ground, weather, time, etc.), communication interface (use of protocols other than WebSocket), devkit (use of APIs other than ROS 2) or the containerization approach (use of tools besides Docker, Dockerfile configuration, etc.) are strictly prohibited. Any modification to the competition framework shall result in direct disqualification of the responsible team without admission to the qualification/competition session. </p> <p> Any kind of autonomous racing algorithm that makes use of raw perception data to generate control commands for the simulated vehicle is permissible - including (but not limited to) reactive planning, map-based localization, raceline optimization, deep learning, reinforcement learning as well as hybrid algorithms. </p> <p> However, utilizing simulation ground truth data or controlling aspects other than the vehicle actuators is not allowed. Furthermore, exploiting the competition framework unethically (e.g., tapping into the back-end, frame-grabbing the front-end, finding loop-holes in the framework, tampering with data streaming/logging, etc.) is considered a serious malpractice. </p> <p>Info</p> <p>Please refer to the Technical Guide for more information about permissible and restricted data streams.</p> <p> Since this is a global event held at some of the world's premier conferences, we ask all teams to observe ethical integrity and abide by the code of conduct of this competition. Any malpractice or plagiarism in terms of submission code or other material shall be considered a serious breach of the code of conduct. Depending upon the situation, organizers reserve the right to issue a warning, public citation, and/or disqualification of the responsible team(s) from the competition. </p>"},{"location":"competitions/roboracer-sim-racing-rules/#25-evaluation-criteria","title":"2.5. Evaluation Criteria","text":"<p> Following are the evaluation criteria for the competition: </p> <ul> <li>The ultimate evaluation criterion for the race is total race time. However, best lap time and/or other metrics may be used in case of a tie.</li> <li>A collision will incur a penalty of 10 seconds (i.e., 10 seconds after first collision, 20 seconds after the second, 30 seconds after the third, and so on).</li> <li>The maximum number of collisions permissible for a race (qualification/competition) is 10, beyond which the team will be disqualified.</li> <li>Lap times or collisions during the warm-up and cool-down laps will not be considered, only those during the 10 race laps will be considered.</li> </ul> <p>Note</p> <p>Race referee's decision is final! In extreme cases, rebuttals with supporting evidence may be entertained at the organizers' discretion.</p>"},{"location":"competitions/roboracer-sim-racing-rules/#3-submission-guidelines","title":"3. Submission Guidelines","text":"<p> Each team is expected to submit a containerized version of their autonomous racing software stack. Submissions for each phase of the competition will be done separately. </p> <p>Note</p> <p>We expect that upon running your submitted container, all the necessary nodes should start up (the <code>autodrive_devkit</code> API we have included as well as your team's racing stack). Once we hit the <code>Connection Button</code> on the <code>Menu Panel</code> of AutoDRIVE Simulator, the simulated vehicle should start running. Please make sure that you include all the necessary commands (for sourcing workspaces, setting environment variables, launching nodes, etc.) within the <code>entrypoint</code> script (<code>autodrive_devkit.sh</code> file) provided within the <code>autodrive_roboracer_api</code> container. Please do NOT use <code>~/.bashrc</code> or other means to automate the algorithm execution! Competition organizers should be able to start additional bash session(s) within your submitted container (without your codebase executing every time a new bash session is initialized) for data recording and inspection purposes.</p>"},{"location":"competitions/roboracer-sim-racing-rules/#31-submission-requirements","title":"3.1. Submission Requirements","text":"<p> Following are the requirements for submitting an entry to the competition: </p> <ul> <li>Each team is expected to submit a Docker container image of their autonomous racing software stack.</li> <li>The submitted container should be self-sustainable in terms of all the dependencies and should be configured to run all the necessary commands automatically when launched.</li> <li>The submitted container must be based off of the official AutoDRIVE Devkit container released for the competition.</li> <li>Teams are permitted to add/modify ROS 2 package(s) within the provided AutoDRIVE Devkit container for implementing their autonomous racing algorithm(s). However, any modifications to the existing container elements are strictly off the limits.</li> <li>Teams do not need to submit the simulator container.</li> </ul> <p>Tip</p> <p>Teams can test their algorithms locally before containerizing them. However, don't forget to test your containers before pushing them upstream and submitting them!</p>"},{"location":"competitions/roboracer-sim-racing-rules/#32-submission-process","title":"3.2. Submission Process","text":"<p> Following are the key milestones for submitting an entry to the competition: </p> <ul> <li>Teams will containerize their autonomous racing software stack using Docker.</li> <li>Teams will push their self-sustainable Docker container image to DockerHub.</li> <li>Teams will share the link of the upstream repository with the organizers via a secure submission form (separate forms for each stage of the competition).</li> </ul>"},{"location":"competitions/roboracer-sim-racing-rules/#33-submission-privacy","title":"3.3. Submission Privacy","text":"<p> This is a competition, and all teams have the right to keep their source code hidden from their competitors. Here are a few strategies to keep in mind: </p> <ul> <li>Source Code: Teams can host their source code in a private GitHub repository for collaboration and version control. GitHub now allows hosting unlimited private repositories for personal accounts and organizations.</li> <li>Containers: Teams can push their Docker container images to a private DockerHub repository. As of now, DockerHub allows hosting one free private repository for each user account.</li> <li>Data: Teams can store their data in an encrypted and secure cloud storage platform with link-sharing disabled. Alternatively, storing data locally (with a hard-drive backup) is also an option.</li> </ul> <p> However, after the competition, we encourage teams to publish their source code on GitHub under an open-source license. We also encourage teams to make their Docker containers public on DockerHub. Teams can also choose to make other race data (e.g., videos, logs, reports, etc.) publicly available. This will increase the visibility of their work and increase the quality of the future competitions. </p>"},{"location":"competitions/roboracer-sim-racing-rules/#4-citation","title":"4. Citation","text":"<p>We encourage you to read and cite the following papers if you use any part of the competition framework for your research:</p>"},{"location":"competitions/roboracer-sim-racing-rules/#autodrive-a-comprehensive-flexible-and-integrated-digital-twin-ecosystem-for-enhancing-autonomous-driving-research-and-education","title":"AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Enhancing Autonomous Driving Research and Education","text":"<p><pre><code>@article{AutoDRIVE-Ecosystem-2023,\nauthor = {Samak, Tanmay and Samak, Chinmay and Kandhasamy, Sivanathan and Krovi, Venkat and Xie, Ming},\ntitle = {AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Autonomous Driving Research &amp; Education},\njournal = {Robotics},\nvolume = {12},\nyear = {2023},\nnumber = {3},\narticle-number = {77},\nurl = {https://www.mdpi.com/2218-6581/12/3/77},\nissn = {2218-6581},\ndoi = {10.3390/robotics12030077}\n}\n</code></pre> This work has been published in MDPI Robotics. The open-access publication can be found on MDPI.</p>"},{"location":"competitions/roboracer-sim-racing-rules/#autodrive-simulator-a-simulator-for-scaled-autonomous-vehicle-research-and-education","title":"AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education","text":"<p><pre><code>@inproceedings{AutoDRIVE-Simulator-2021,\nauthor = {Samak, Tanmay Vilas and Samak, Chinmay Vilas and Xie, Ming},\ntitle = {AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education},\nyear = {2021},\nisbn = {9781450390453},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3483845.3483846},\ndoi = {10.1145/3483845.3483846},\nbooktitle = {2021 2nd International Conference on Control, Robotics and Intelligent System},\npages = {1\u20135},\nnumpages = {5},\nlocation = {Qingdao, China},\nseries = {CCRIS'21}\n}\n</code></pre> This work has been published at 2021 International Conference on Control, Robotics and Intelligent System (CCRIS). The publication can be found on ACM Digital Library.</p>"},{"location":"education/","title":"EDUCATION","text":""},{"location":"education/#workshops","title":"Workshops","text":""},{"location":"research/","title":"RESEARCH","text":"<p> This page hosts research outcomes that employ or contribute to the AutoDRIVE Ecosystem in the form of publications, reports and thesis. We encourage you to read and cite the relevant research artifacts if you use any part of this project for your research. </p> <p>Tip</p> <p>Do you use AutoDRIVE Ecosystem for your research? Please contact Chinmay Samak or Tanmay Samak if you would like to feature your research on AutoDRIVE's website.</p>"},{"location":"research/#publications","title":"Publications","text":"<p> AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education  Tanmay Vilas Samak, Chinmay Vilas Samak, and Ming Xie  ACM International Conference on Control, Robotics and Intelligent System (CCRIS) 2021</p> Citation <pre><code>@inproceedings{AutoDRIVE-Simulator-2021,\nauthor = {Samak, Tanmay Vilas and Samak, Chinmay Vilas and Xie, Ming},\ntitle = {AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education},\nyear = {2021},\nisbn = {9781450390453},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3483845.3483846},\ndoi = {10.1145/3483845.3483846},\nbooktitle = {2021 2nd International Conference on Control, Robotics and Intelligent System},\npages = {1-5},\nnumpages = {5},\nlocation = {Qingdao, China},\nseries = {CCRIS'21}\n}\n</code></pre> <p> AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Enhancing Autonomous Driving Research and Education  Tanmay Vilas Samak, Chinmay Vilas Samak, Sivanathan Kandhasamy, Venkat Narayan Krovi, and Ming Xie  MDPI Robotics 2023</p> Citation <pre><code>@article{AutoDRIVE-Ecosystem-2023,\nauthor = {Samak, Tanmay and Samak, Chinmay and Kandhasamy, Sivanathan and Krovi, Venkat and Xie, Ming},\ntitle = {AutoDRIVE: A Comprehensive, Flexible and Integrated Digital Twin Ecosystem for Autonomous Driving Research &amp; Education},\njournal = {Robotics},\nvolume = {12},\nyear = {2023},\nnumber = {3},\narticle-number = {77},\nurl = {https://www.mdpi.com/2218-6581/12/3/77},\nissn = {2218-6581},\ndoi = {10.3390/robotics12030077}\n}\n</code></pre> <p> Towards Mechatronics Approach of System Design, Verification and Validation for Autonomous Vehicles  Chinmay Vilas Samak, Tanmay Vilas Samak, and Venkat Narayan Krovi  IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM) 2023</p> Citation <pre><code>@inproceedings{Mechatronics-Approach-2023,\nauthor = {Samak, Chinmay and Samak, Tanmay and Krovi, Venkat},\nbooktitle = {2023 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)}, \ntitle = {Towards Mechatronics Approach of System Design, Verification and Validation for Autonomous Vehicles}, \nyear = {2023},\nvolume = {},\nnumber = {},\npages = {1208-1213},\ndoi = {10.1109/AIM46323.2023.10196233},\nurl = {https://doi.org/10.1109/AIM46323.2023.10196233}\n}\n</code></pre> <p> Towards Sim2Real Transfer of Autonomy Algorithms using AutoDRIVE Ecosystem  Chinmay Vilas Samak, Tanmay Vilas Samak, and Venkat Narayan Krovi  AACC/IFAC Modeling, Estimation and Control Conference (MECC) 2023</p> Citation <pre><code>@article{Sim2Real-Transfer-2023,\nauthor = {Chinmay Samak and Tanmay Samak and Venkat Krovi},\ntitle = {Towards Sim2Real Transfer of Autonomy Algorithms using AutoDRIVE Ecosystem},\njournal = {IFAC-PapersOnLine},\nvolume = {56},\nnumber = {3},\npages = {277-282},\nyear = {2023},\nnote = {3rd Modeling, Estimation and Control Conference MECC 2023},\nissn = {2405-8963},\ndoi = {https://doi.org/10.1016/j.ifacol.2023.12.037},\nurl = {https://www.sciencedirect.com/science/article/pii/S2405896323023704}\n}\n</code></pre> <p> Multi-Agent Deep Reinforcement Learning for Cooperative and Competitive Autonomous Vehicles using AutoDRIVE Ecosystem  Tanmay Vilas Samak, Chinmay Vilas Samak, and Venkat Narayan Krovi  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023</p> Citation <pre><code>@inproceedings{Coopertitive-MARL-2023,\nauthor = {Samak, Tanmay and Samak, Chinmay and Krovi, Venkat},\nbooktitle = {2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, \ntitle = {Multi-Agent Deep Reinforcement Learning for Cooperative and Competitive Autonomous Vehicles using AutoDRIVE Ecosystem}, \nyear = {2023},\nvolume = {MAD-Games Workshop},\nnumber = {},\npages = {},\ndoi = {10.48550/arXiv.2309.10007},\nurl = {https://iros2023-madgames.f1tenth.org/papers/samak.pdf}\n}\n</code></pre> <p> Nigel - Mechatronic Design and Robust Sim2Real Control of an Over-Actuated Autonomous Vehicle  Chinmay Vilas Samak, Tanmay Vilas Samak, Javad Mohammadpour Velni, and Venkat Narayan Krovi  IEEE/ASME Transactions on Mechatronics (Presented at AIM 2024) 2024</p> Citation <pre><code>@article{Nigel-Sim2Real-Control-2024,\nauthor = {Samak, Chinmay V. and Samak, Tanmay V. and Velni, Javad M. and Krovi, Venkat N.},\njournal = {IEEE/ASME Transactions on Mechatronics}, \ntitle = {Nigel\u2014Mechatronic Design and Robust Sim2Real Control of an Overactuated Autonomous Vehicle}, \nyear = {2024},\nvolume = {29},\nnumber = {4},\npages = {2785-2793},\ndoi = {10.1109/TMECH.2024.3401077},\nurl = {https://doi.org/10.1109/TMECH.2024.3401077}\n}\n</code></pre> <p> Towards Validation of Autonomous Vehicles Across Scales using an Integrated Digital Twin Framework  Tanmay Vilas Samak, Chinmay Vilas Samak, and Venkat Narayan Krovi  IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM) 2024</p> Citation <pre><code>@inproceedings{Autonomy-Across-Scales-2024,\nauthor = {Samak, Tanmay Vilas and Samak, Chinmay Vilas and Krovi, Venkat Narayan},\nbooktitle = {2024 IEEE International Conference on Advanced Intelligent Mechatronics (AIM)}, \ntitle = {Towards Validation of Autonomous Vehicles Across Scales using an Integrated Digital Twin Framework}, \nyear = {2024},\nvolume = {},\nnumber = {},\npages = {1068-1075},\ndoi = {10.1109/AIM55361.2024.10637205},\nurl = {https://doi.org/10.1109/AIM55361.2024.10637205}\n}\n</code></pre> <p> Off-Road Autonomy Validation Using Scalable Digital Twin Simulations Within High-Performance Computing Clusters  Tanmay Vilas Samak, Chinmay Vilas Samak, Joey Binz, Jonathon Smereka, Mark Brudnak, David Gorsich, Feng Luo, and Venkat Narayan Krovi  NDIA Ground Vehicle Systems Engineering and Technology Symposium (GVSETS) 2024</p> Citation <pre><code>@inproceedings{DT-HPC-VnV-2024,\nauthor = {{Samak, Tanmay} and {Samak, Chinmay} and {Krovi, Venkat} and {Binz, Joey} and {Luo, Feng} and {Smereka, Jonathon} and {Brudnak, Mark} and {Gorsich, David}},\ntitle = {Off-Road Autonomy Validation Using Scalable Digital Twin Simulations Within High-Performance Computing Clusters},\nbooktitle = {2024 NDIA Michigan Chapter Ground Vehicle Systems Engineering and Technology Symposium},\npublisher = {National Defense Industrial Association},\nmonth = {sep},\nyear = {2024},\ndoi = {10.4271/2024-01-4111},\nurl = {https://doi.org/10.4271/2024-01-4111}\n}\n</code></pre> <p> Metaverse for Safer Roadways: An Immersive Digital Twin Framework for Exploring Human-Autonomy Coexistence in Urban Transportation Systems  Tanmay Vilas Samak, Chinmay Vilas Samak, and Venkat Narayan Krovi  IEEE Conference on Telepresence 2024</p> Citation <pre><code>@inproceedings{Metaverse-for-Safer-Roadways-2024,\nauthor = {Samak, Tanmay V. and Samak, Chinmay V. and Krovi, Venkat N.},\nbooktitle = {2024 IEEE Conference on Telepresence}, \ntitle = {Metaverse for Safer Roadways: An Immersive Digital Twin Framework for Exploring Human-Autonomy Coexistence in Urban Transportation Systems}, \nyear = {2024},\nvolume = {},\nnumber = {},\npages = {160-165},\ndoi = {10.1109/Telepresence63209.2024.10841549},\nurl = {https://doi.org/10.1109/Telepresence63209.2024.10841549}\n}\n</code></pre> <p> A Scalable and Parallelizable Digital Twin Framework for Sustainable Sim2Real Transition of Multi-Agent Reinforcement Learning Systems  Chinmay Vilas Samak, Tanmay Vilas Samak, and Venkat Narayan Krovi  arXiv Preprint 2024</p> Citation <pre><code>@misc{Sim2Real-MARL-2024,\nauthor = {Chinmay Vilas Samak and Tanmay Vilas Samak and Venkat Krovi},\ntitle = {A Scalable and Parallelizable Digital Twin Framework for Sustainable Sim2Real Transition of Multi-Agent Reinforcement Learning Systems}, \nyear = {2024},\neprint = {2403.10996},\narchivePrefix = {arXiv},\nprimaryClass = {cs.RO},\nurl = {https://arxiv.org/abs/2403.10996}\n}\n</code></pre>"},{"location":"research/#reports","title":"Reports","text":"<p> AutoDRIVE Simulator: A Simulator for Scaled Autonomous Vehicle Research and Education  Tanmay Vilas Samak and Chinmay Vilas Samak  India Connect @ NTU (IC@N) Research Internship Program 2020</p> Citation <pre><code>@misc{AutoDRIVE-Simulator-2020,\nauthor = {Tanmay Vilas Samak and Chinmay Vilas Samak},\ntitle = {AutoDRIVE Simulator -- Technical Report}, \nyear = {2022},\neprint = {2211.07022},\narchivePrefix = {arXiv},\nprimaryClass = {cs.RO},\nurl = {https://arxiv.org/abs/2211.07022}\n}\n</code></pre> <p> Autonomy Oriented Digital Twins for Real2Sim2Real Autoware Deployment  Chinmay Vilas Samak and Tanmay Vilas Samak  AuE-8360 Scaled Autonomous Vehicles, CU-ICAR 2023</p> Citation <pre><code>@misc{AutoDRIVE-Autoware-2023,\nauthor = {Chinmay Vilas Samak and Tanmay Vilas Samak},\ntitle = {Autonomy Oriented Digital Twins for Real2Sim2Real Autoware Deployment},\nyear = {2024},\neprint = {2402.14739},\narchivePrefix = {arXiv},\nprimaryClass = {cs.RO},\nurl = {https://arxiv.org/abs/2402.14739}\n}\n</code></pre>"},{"location":"research/#theses","title":"Theses","text":"<p> AutoDRIVE \u2013 An Integrated Platform for Autonomous Driving Research and Education  Tanmay Vilas Samak and Chinmay Vilas Samak  Bachelor's Thesis, Mechatronics Engineering, SRMIST 2021</p> Citation <pre><code>@misc{AutoDRIVE-Ecosystem-2021,\nauthor={Tanmay Vilas Samak and Chinmay Vilas Samak},\ntitle={AutoDRIVE -- Technical Report},\nyear={2022},\neprint={2211.08475},\narchivePrefix={arXiv},\nprimaryClass={cs.RO},\nurl={https://arxiv.org/abs/2211.08475}\n}\n</code></pre>"}]}